{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7f4a29-02e0-4fbe-b644-06a8ec99626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 08:55:03.636991: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-09 08:55:03.637039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-09 08:55:03.637722: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 08:55:03.642669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a37904-3655-4272-b6cf-6c09bb0af7bf",
   "metadata": {},
   "source": [
    "# ðŸˆ Predicting Blitzes Using Pre-Snap Behavior\n",
    "\n",
    "**By:** Christopher Doyle, Hans Elasri, Thomas Garity, Rishi Hazra, and Christopher RuaÃ±o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bceb6a-32b1-48f5-8929-cf8ce6af3a2f",
   "metadata": {},
   "source": [
    "## Final Model Pipeline\n",
    "\n",
    "**Here is a high-level overview of the pipeline. Continue scrolling to see a basic implementation with more detail on assumptions and design choices.**\n",
    "\n",
    "--\n",
    "\n",
    "For our final model, we will adopt an RNN architecture. While some elements (like the hyperparameters, specific architecture, and feature selection) will be determined as we iterate, we will begin with a baseline model and then iteratively improve it.\n",
    "\n",
    "We will iterate through the following approaches:\n",
    "1. **Baseline RNN**: Feed through sequences of N rows of data. Each row corresponds to one play, and sequence is made up of N consecutive plays. The final play is the target -- the model must predict whether or not a blitz occurred in the final play.\n",
    "2. **Frame-by-Frame RNN:** Feed through sequences of N rows of data. Each row corresponds to one frame of a single play. The final frame is the target -- the model must predict whether or not a blitz occurred within this play. \n",
    "3. **Mixture of Both:** Run both types of RNN. Combine the hidden states before a MLP head predicts the final blitz / no blitz output.\n",
    "\n",
    "Our Pipeline will be as follows:\n",
    "\n",
    "1. **PREPROCESSING**\n",
    "   1. One hot encode categorical variables (teams, positions, formations)\n",
    "   2. Drop columns that are un-usable.\n",
    "   3. Create sequences, using a sliding window. Write a function for creating sequences -- we want the sliding window size to be flexible (we may want to change this later)\n",
    "2. **MODELING**\n",
    "   1. Define the architecture; the input should be N * (sequence length) * (number of features)\n",
    "   2. Work with some sort of RNN units -- either RNN, GRU, or LSTM\n",
    "   3. Output of final dense layer should be one logits with sigmoid activation for binary classification.\n",
    "   4. We will minimize the binary cross-entropy loss -- this is the most logical approach, as we have chosen to have 1 logit.\n",
    "3. **TRAINING**\n",
    "   1. Train the model on the training data. Log loss, accuracy, and validation accuracy\n",
    "   2. Plot training results over each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969500f5-3e83-467b-a205-2135d5b6d2e8",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "Using similar logic to the logistic regression, we:\n",
    "- one-hot encode categorical variables (teams, positions, formations)\n",
    "- cast boolean variables to integers\n",
    "- drop columns that are un-usable\n",
    "- fill Nans with 0 -- these mainly correspond to boolean variables for players whose positions do not apply (i.e. defensive stats for an offensive player), so zeroes are appropriate\n",
    "\n",
    "To obtain our target label, we merge in from the `blitz_outcome` df. In our next imeplementation, we would save those blitz labels to the .csv file itself.\n",
    "\n",
    "The next step is creating sequences. This is the format ready for the model. We have begun with a sequence length of 5, as this allows us to summarize any trends in the current drive, while also peeking at the previous drive as well. In the future we might experiment with:\n",
    "- very large (30+) sequence lengths to capture multiple possessions from both teams\n",
    "- recreate this logic at the frame-level; so we are looking more at real-time decisions (this is closer to our problem statement)\n",
    "\n",
    "\n",
    "NOTE: We have cut off our dataset at only 2 games here. Change the `cutoff` argument to `None` to use the full dataset.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b572fd95-27bb-40a7-860c-dc79538c80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10228/4249411861.py:2: DtypeWarning: Columns (420,421,422,423,424,425,426,427,428,429,430,431,432,435,436,437,438,440,441) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('nontime_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import dataframe\n",
    "df = pd.read_csv('nontime_data.csv')\n",
    "blitz_outcome = pd.read_csv('blitz_outcome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e63cd78-df9e-4fe1-b680-ed7a6ade90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing mapping of plays --> blitzes to add the target column\n",
    "df = df.merge(blitz_outcome[['gameId', 'playId', 'blitzOutcome']], \n",
    "              on=['gameId', 'playId'], \n",
    "              how='left'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc12c4d9-f77c-4f58-b25e-8ee0163d8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all missing categorical fields\n",
    "categorical_cols = []\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col not in ['gameId', 'playId', 'nflId']:\n",
    "        categorical_cols.append(col)\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# one-hot encode categorical cols\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# drop any remaining object-type columns from X\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df = df.drop(columns=[col])\n",
    "\n",
    "# Convert boolean columns to integers (0/1) first\n",
    "bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Drop remaining rows with any NaN\n",
    "df = df.dropna(subset=['blitzOutcome', 'quarter', 'down', 'yardsToGo', 'yardlineNumber', 'gameClock', 'preSnapHomeScore', 'preSnapVisitorScore', 'absoluteYardlineNumber', 'preSnapHomeTeamWinProbability', 'preSnapVisitorTeamWinProbability', 'expectedPoints'])\n",
    "\n",
    "# Fill remaining NaNs with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d72385c-06ca-4998-82fc-5482c6139156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, n=5, target_col='blitzOutcome', step=1, cutoff=2):\n",
    "    \"\"\"\n",
    "    Create sequences of n consecutive plays for RNN input with overlapping windows.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with last frame of each play\n",
    "    n : Sequence length (number of plays to include in each sequence)\n",
    "    target_col : Column name for the target variable (blitz indicator)\n",
    "    step : Step size for sliding window (1 = maximum overlap, n = no overlap)\n",
    "    cutoff : how many games to repeat this process for (for prototyping)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy array of shape (num_sequences, n, num_features)\n",
    "        Sequences of n plays with features\n",
    "    y : numpy array of shape (num_sequences,)\n",
    "        Target values indicating whether the n+1th play was a blitz\n",
    "    play_ids : list of tuples\n",
    "        Identifiers for the play following each sequence (for reference)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    play_ids = []\n",
    "    \n",
    "    # list of unique games\n",
    "    games = df['gameId'].unique()\n",
    "    \n",
    "    # Handle cutoff=None\n",
    "    if cutoff is None:\n",
    "        cutoff = len(games)\n",
    "\n",
    "    # Print number of games you are sampling from\n",
    "    print(f'Sampling from {cutoff} games')\n",
    "\n",
    "    for game_id in games[:cutoff]:\n",
    "        # Get plays for this game and sort chronologically\n",
    "        game_plays = df[df['gameId'] == game_id].sort_values(['quarter', 'gameClock'], ascending=[True, False])\n",
    "        \n",
    "        # Get the length of this game in plays\n",
    "        game_length = len(game_plays)\n",
    "        \n",
    "        # Skip games that are too short for our sequence length\n",
    "        if game_length <= n:\n",
    "            continue\n",
    "            \n",
    "        # Specify which features to use\n",
    "        feature_cols = [col for col in df.columns if col not in ['gameId', 'playId', 'blitzOutcome']]\n",
    "        \n",
    "        # Convert to numpy for faster operations\n",
    "        plays_array = game_plays[feature_cols].values\n",
    "        targets_array = game_plays[target_col].values if target_col in game_plays.columns else None\n",
    "        play_ids_array = game_plays['playId'].values\n",
    "\n",
    "        # Create overlapping windows\n",
    "        for i in range(0, game_length - n, step):\n",
    "            # Get n consecutive plays for X\n",
    "            sequence = plays_array[i:i+n]\n",
    "            \n",
    "            # Skip sequences with NaN values if needed\n",
    "            # Although we should not have any at this point\n",
    "            if np.isnan(sequence).any():\n",
    "                # Flag it so we can debug\n",
    "                print('skipping')\n",
    "                continue\n",
    "                \n",
    "            # Add the sequence to our dataset\n",
    "            X.append(sequence)\n",
    "            \n",
    "            # Get target from the n+1th play (if target column exists)\n",
    "            if targets_array is not None:\n",
    "                y.append(targets_array[i+n])\n",
    "                \n",
    "            # Keep track of which play this prediction is for\n",
    "            # This is mainly for interpretability\n",
    "            play_ids.append((game_id,play_ids_array[i+n]))\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y) if targets_array is not None else None\n",
    "    \n",
    "    print(f\"Created {len(X)} sequences of length {n}\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    if y is not None:\n",
    "        print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    return X, y, play_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9097147-4b9b-4e4e-81ca-4d5b1f1318b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from 31 games\n",
      "Created 3519 sequences of length 5\n",
      "X shape: (3519, 5, 1968)\n",
      "y shape: (3519,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare sequences\n",
    "X, y, play_ids = create_sequences(df, n=5, target_col='blitzOutcome', step=1, cutoff=None)\n",
    "\n",
    "# Split into 80% training and 20% validation and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Take leftover 20% and split into 10% validation and 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f4c0ef-6598-4a26-a3aa-7ddadd69e354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count occurrences of each label\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "label_names = ['No blitz', 'Blitz']\n",
    "\n",
    "# Calculate percentages\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "# Plot\n",
    "plt.bar(label_names, counts)\n",
    "plt.title('Class imbalance in training data')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for i, (count, pct) in enumerate(zip(counts, percentages)):\n",
    "    plt.text(i, count + total * 0.01, f'{pct:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181474b-1b7a-400e-8415-fa937e5d2ebc",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "This is roughly in-line with our % of blitzes across all plays -- so we can suggest that we are sampling correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fdd00-0481-484d-b97a-d07464227510",
   "metadata": {},
   "source": [
    "### Define RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba896d-09ef-463a-b76c-5c88121d46ee",
   "metadata": {},
   "source": [
    "We have not put extreme thought into this model yet -- that will be work for Milestone 5. However, with this working scaffolding, we can begin to iterate. Some design decisions we have made already are:\n",
    "- **Tracking precision / recall** -- we know that blitzes are rare, so it is important that we know whether we are correctly identifying them (not just predicting the majority class)\n",
    "- **Bidirectional LSTM layers** -- we were impressed by LSTMs in psets so have chosen them as the starting point. We have chosen bidirectional thinking that football strategies are somewhat bidirectional as well ; a defensive coordinator both looks back and previous plays and plans for potential future plays to lead their decisions. We need to test this logic further through experiments with regular and bidirectional plays.\n",
    "- **Dropout** -- there is a risk of overfitting with this type of task (very noisy, small dataset), so we have added dropout to prevent overfitting.\n",
    "- **Early Stopping** -- we have added early stopping to prevent overfitting.\n",
    "- **Batch Normalization** -- same as above ; one more measure to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40946f4-e9dc-4b13-8b26-c32661f1ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blitz_rnn_model(n_timesteps, n_features, dropout_rate=0.3, lstm_units=256):\n",
    "    model = Sequential([\n",
    "        # Input layer\n",
    "        Input(shape=(n_timesteps, n_features)),\n",
    "        \n",
    "        # Bidirectional LSTM layer\n",
    "        Bidirectional(LSTM(256, return_sequences=True)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Second bidirectional LSTM layer\n",
    "        Bidirectional(LSTM(256)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Dense hidden layer\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        # Dense hidden layer\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Output layer with 2 neurons (probability of blitz and no blitz)\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model with binary cross-entropy loss\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8c2abc-7116-4e04-a066-78137d5dda81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 08:55:28.139351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20763 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:3e:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "RNN_model = create_blitz_rnn_model(n_timesteps=X.shape[1], n_features=X.shape[2], dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2008604-8fdf-4aaa-9e35-c4dcf1025e65",
   "metadata": {},
   "source": [
    "### Training Run\n",
    "\n",
    "Keep in mind, this is a demo -- we would run this for more epochs and tune our hyperparameters for our final model.\n",
    "\n",
    "Be sure to update the # of epochs to be greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884969af-5077-4f5c-94b3-8be6c29a75f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 08:55:39.160095: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-05-09 08:55:40.925812: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e49c115340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-09 08:55:40.925849: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2025-05-09 08:55:40.930831: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746795341.005919   22217 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/88 [===========================>..] - ETA: 0s - loss: 1.3015 - accuracy: 0.4835 - auc: 0.4935 - precision: 0.0779 - recall: 0.5468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 9s 25ms/step - loss: 1.2829 - accuracy: 0.4845 - auc: 0.4933 - precision: 0.0756 - recall: 0.5415 - val_loss: 0.5954 - val_accuracy: 0.9460 - val_auc: 0.5335 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9883 - accuracy: 0.5066 - auc: 0.5275 - precision: 0.0765 - recall: 0.5220 - val_loss: 0.5990 - val_accuracy: 0.8438 - val_auc: 0.5317 - val_precision: 0.0444 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.8306 - accuracy: 0.5460 - auc: 0.6104 - precision: 0.0920 - recall: 0.5902 - val_loss: 0.2806 - val_accuracy: 0.9517 - val_auc: 0.4928 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7010 - accuracy: 0.5783 - auc: 0.6926 - precision: 0.1152 - recall: 0.7171 - val_loss: 0.5094 - val_accuracy: 0.8409 - val_auc: 0.5472 - val_precision: 0.0435 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5930 - accuracy: 0.6352 - auc: 0.7638 - precision: 0.1376 - recall: 0.7610 - val_loss: 0.5234 - val_accuracy: 0.7756 - val_auc: 0.3388 - val_precision: 0.0290 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5798 - accuracy: 0.6490 - auc: 0.7772 - precision: 0.1444 - recall: 0.7756 - val_loss: 0.7839 - val_accuracy: 0.5114 - val_auc: 0.2797 - val_precision: 0.0183 - val_recall: 0.2143 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5744 - accuracy: 0.6753 - auc: 0.7703 - precision: 0.1416 - recall: 0.6829 - val_loss: 0.7169 - val_accuracy: 0.6989 - val_auc: 0.4466 - val_precision: 0.0400 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5194 - accuracy: 0.6710 - auc: 0.8174 - precision: 0.1544 - recall: 0.7854 - val_loss: 0.9319 - val_accuracy: 0.5256 - val_auc: 0.3415 - val_precision: 0.0189 - val_recall: 0.2143 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4692 - accuracy: 0.6664 - auc: 0.8617 - precision: 0.1645 - recall: 0.8780 - val_loss: 0.6160 - val_accuracy: 0.6705 - val_auc: 0.3455 - val_precision: 0.0189 - val_recall: 0.1429 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4230 - accuracy: 0.7218 - auc: 0.8932 - precision: 0.1932 - recall: 0.8878 - val_loss: 0.5763 - val_accuracy: 0.7273 - val_auc: 0.3299 - val_precision: 0.0233 - val_recall: 0.1429 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4133 - accuracy: 0.7364 - auc: 0.8955 - precision: 0.2000 - recall: 0.8732 - val_loss: 0.5861 - val_accuracy: 0.7131 - val_auc: 0.3228 - val_precision: 0.0220 - val_recall: 0.1429 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_recall', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001),\n",
    "    ModelCheckpoint('best_blitz_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Use class weighting to adjust for massive class imbalance:\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "history = RNN_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd59ce11-2a29-46e3-b4a9-72b586efd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_metrics(history):\n",
    "    metrics = ['accuracy', 'precision', 'recall']\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.plot(history.history[metric], label=f'Train {metric}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Val {metric}')\n",
    "        plt.title(metric.capitalize())\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73945170-de86-4805-8e32-34fd5ef4edab",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f2fafb5-a4d9-47d4-a164-58b10189547e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6db1415-3779-437c-900e-cf983986723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.9176 - auc: 0.5891 - precision: 0.2000 - recall: 0.0385\n",
      "Test Loss: 0.6012\n",
      "Test Accuracy: 0.9176\n",
      "Test AUC: 0.5891\n",
      "Test Precision: 0.2000\n",
      "Test Recall: 0.0385\n"
     ]
    }
   ],
   "source": [
    "# Inspect Logs\n",
    "loss, accuracy, auc, precision, recall = RNN_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea45042-eedf-4e1d-997e-fb1f950a9f20",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The model predicts with a test accuracy of 66%, and a test recall of 30%. This means that the model predicts 1 in 3 blitzes -- this could be useful after all!\n",
    "\n",
    "Some design decisions thus far are:\n",
    "- Class weights -- this was a game changer\n",
    "- LSTM layers -- bidirectional, since previous plays affect future ones, and potential future plays affect current ones (this may be too-flimsy logic)\n",
    "- Early stopping based on recall -- as accuracy climbs, the recall tends to drop off (in early epochs, the model predicts too many blitzes)\n",
    "\n",
    "However, there are a few design choices we can evaluate further:\n",
    "- Scaling the dataset in preprocessing -- right now, we do nothing\n",
    "- BinaryFocalCrossentropy loss did not help -- although maybe it could be worthwhile\n",
    "- We don't know what the ideal input data looks like: is it better to feed through loads of plays, and let the model draw long-term predictions, or should we draw in shorter sequences?\n",
    "- Same goes for step size in the sampling function\n",
    "- Are we sure we have the right level of dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a4d38-1e34-4a3e-9ba7-4379382f0243",
   "metadata": {},
   "source": [
    "## Input Feature Scaling\n",
    "\n",
    "We perform an experiment to test for the best approach to scaling:\n",
    "- Scale to [0, 1] -- many values are indicators on that interval anyways\n",
    "- Standard scaler -- this likely will not work, since our data does not assume a gaussian distribution\n",
    "- Scale to [-1, 1] -- the `tanh` activations in the LSTM layers may benefit from this\n",
    "- No scaling (control) -- this is what we have currently -- and results have been okay (30% test recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24dac03b-d8d2-449f-a503-b52c988933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def test_scaler(X, y, results=None, scaler='None', n_trials=5):\n",
    "    # Scale (or do not scale)\n",
    "\n",
    "    if scaler == 'None':\n",
    "        X_scaled = X\n",
    "\n",
    "    else:\n",
    "        # Manipulate data to be 2D (most scalers expect 2D data)\n",
    "        # Suppose X shape is (n_samples, n_timesteps, n_features)\n",
    "        n_samples, n_timesteps, n_features = X.shape\n",
    "        \n",
    "        # Reshape to 2D for scaling (merge samples and timesteps)\n",
    "        X_2d = X.reshape(-1, n_features)\n",
    "\n",
    "        if scaler == '[0,1]':\n",
    "            # Normalize features to [0, 1] (handles mixed scales safely)\n",
    "            scaler = MinMaxScaler()\n",
    "    \n",
    "        if scaler == '[-1,1]':\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))    \n",
    "    \n",
    "        if scaler == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "        # Fit and transform\n",
    "        X_scaled_2d = scaler.fit_transform(X_2d)\n",
    "                \n",
    "        # Reshape back to original 3D shape\n",
    "        X_scaled = X_scaled_2d.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "    # Split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        print(f'Scaler: {scaler}, Trial: {i}')\n",
    "        # Create model\n",
    "        RNN_model = create_blitz_rnn_model(n_timesteps=X.shape[1], n_features=X.shape[2], dropout_rate=0.2)\n",
    "    \n",
    "        # Train and evaluate\n",
    "        # Compute weights\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        \n",
    "        # Train\n",
    "        history = RNN_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "        )\n",
    "    \n",
    "        # Evaluate and save\n",
    "        results = evaluate_and_save(RNN_model, X_test, y_test, ['scaler', scaler], i, results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234cda89-323a-4e10-b0ec-bc108bea11a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: StandardScaler(), Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3419 - accuracy: 0.4948 - auc: 0.4827 - precision: 0.0724 - recall: 0.5024 - val_loss: 0.7758 - val_accuracy: 0.5384 - val_auc: 0.4587 - val_precision: 0.0615 - val_recall: 0.5000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8421 - accuracy: 0.5268 - auc: 0.5944 - precision: 0.0878 - recall: 0.5854 - val_loss: 0.7070 - val_accuracy: 0.5838 - val_auc: 0.4596 - val_precision: 0.0530 - val_recall: 0.3750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6778 - accuracy: 0.6078 - auc: 0.7048 - precision: 0.1220 - recall: 0.7073 - val_loss: 0.6305 - val_accuracy: 0.6705 - val_auc: 0.5439 - val_precision: 0.0636 - val_recall: 0.3500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5447 - accuracy: 0.6895 - auc: 0.8188 - precision: 0.1625 - recall: 0.7854 - val_loss: 0.6167 - val_accuracy: 0.7301 - val_auc: 0.5218 - val_precision: 0.0739 - val_recall: 0.3250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4723 - accuracy: 0.7414 - auc: 0.8631 - precision: 0.1984 - recall: 0.8390 - val_loss: 0.5747 - val_accuracy: 0.7670 - val_auc: 0.4658 - val_precision: 0.0507 - val_recall: 0.1750\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3575 - accuracy: 0.7979 - auc: 0.9259 - precision: 0.2507 - recall: 0.8927 - val_loss: 0.5444 - val_accuracy: 0.7884 - val_auc: 0.5177 - val_precision: 0.0569 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.8334 - auc: 0.9322 - precision: 0.2911 - recall: 0.8976 - val_loss: 0.6172 - val_accuracy: 0.7969 - val_auc: 0.5245 - val_precision: 0.0744 - val_recall: 0.2250\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2980 - accuracy: 0.8625 - auc: 0.9474 - precision: 0.3369 - recall: 0.9171 - val_loss: 0.5956 - val_accuracy: 0.8011 - val_auc: 0.5365 - val_precision: 0.0763 - val_recall: 0.2250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2896 - accuracy: 0.8565 - auc: 0.9487 - precision: 0.3270 - recall: 0.9171 - val_loss: 0.6389 - val_accuracy: 0.8054 - val_auc: 0.4444 - val_precision: 0.0550 - val_recall: 0.1500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1939 - accuracy: 0.9062 - auc: 0.9775 - precision: 0.4349 - recall: 0.9610 - val_loss: 0.4382 - val_accuracy: 0.8551 - val_auc: 0.5487 - val_precision: 0.0811 - val_recall: 0.1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8551 - auc: 0.5487 - precision: 0.0811 - recall: 0.1500\n",
      "Scaler: StandardScaler(), Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2216 - accuracy: 0.5311 - auc: 0.5434 - precision: 0.0843 - recall: 0.5512 - val_loss: 0.6757 - val_accuracy: 0.6207 - val_auc: 0.4651 - val_precision: 0.0442 - val_recall: 0.2750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8297 - accuracy: 0.5655 - auc: 0.6211 - precision: 0.1023 - recall: 0.6390 - val_loss: 0.8349 - val_accuracy: 0.5852 - val_auc: 0.4956 - val_precision: 0.0594 - val_recall: 0.4250\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6708 - accuracy: 0.6124 - auc: 0.7138 - precision: 0.1239 - recall: 0.7122 - val_loss: 0.7209 - val_accuracy: 0.6960 - val_auc: 0.5360 - val_precision: 0.0777 - val_recall: 0.4000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.6767 - auc: 0.8205 - precision: 0.1620 - recall: 0.8244 - val_loss: 0.5476 - val_accuracy: 0.7756 - val_auc: 0.4566 - val_precision: 0.0725 - val_recall: 0.2500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4318 - accuracy: 0.7680 - auc: 0.8873 - precision: 0.2228 - recall: 0.8780 - val_loss: 0.7634 - val_accuracy: 0.7031 - val_auc: 0.4395 - val_precision: 0.0529 - val_recall: 0.2500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3682 - accuracy: 0.7972 - auc: 0.9173 - precision: 0.2527 - recall: 0.9122 - val_loss: 0.6447 - val_accuracy: 0.7571 - val_auc: 0.4860 - val_precision: 0.0604 - val_recall: 0.2250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3264 - accuracy: 0.8302 - auc: 0.9367 - precision: 0.2877 - recall: 0.9024 - val_loss: 0.6547 - val_accuracy: 0.7770 - val_auc: 0.4808 - val_precision: 0.0534 - val_recall: 0.1750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2907 - accuracy: 0.8547 - auc: 0.9490 - precision: 0.3223 - recall: 0.9024 - val_loss: 0.7059 - val_accuracy: 0.7770 - val_auc: 0.4612 - val_precision: 0.0602 - val_recall: 0.2000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2271 - accuracy: 0.8874 - auc: 0.9677 - precision: 0.3898 - recall: 0.9659 - val_loss: 0.7238 - val_accuracy: 0.7812 - val_auc: 0.5134 - val_precision: 0.0476 - val_recall: 0.1500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1622 - accuracy: 0.9222 - auc: 0.9840 - precision: 0.4832 - recall: 0.9805 - val_loss: 0.5704 - val_accuracy: 0.8324 - val_auc: 0.5349 - val_precision: 0.0851 - val_recall: 0.2000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.8324 - auc: 0.5349 - precision: 0.0851 - recall: 0.2000\n",
      "Scaler: StandardScaler(), Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 25ms/step - loss: 1.3084 - accuracy: 0.4877 - auc: 0.5008 - precision: 0.0702 - recall: 0.4927 - val_loss: 0.8117 - val_accuracy: 0.4631 - val_auc: 0.4954 - val_precision: 0.0576 - val_recall: 0.5500\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8222 - accuracy: 0.5517 - auc: 0.6286 - precision: 0.0999 - recall: 0.6439 - val_loss: 0.7741 - val_accuracy: 0.5710 - val_auc: 0.4105 - val_precision: 0.0355 - val_recall: 0.2500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6910 - accuracy: 0.6263 - auc: 0.7087 - precision: 0.1229 - recall: 0.6732 - val_loss: 0.7580 - val_accuracy: 0.6037 - val_auc: 0.4470 - val_precision: 0.0524 - val_recall: 0.3500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5238 - accuracy: 0.6842 - auc: 0.8329 - precision: 0.1718 - recall: 0.8732 - val_loss: 0.5761 - val_accuracy: 0.7500 - val_auc: 0.4847 - val_precision: 0.0584 - val_recall: 0.2250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4302 - accuracy: 0.7567 - auc: 0.8874 - precision: 0.2150 - recall: 0.8829 - val_loss: 0.5808 - val_accuracy: 0.7784 - val_auc: 0.5035 - val_precision: 0.0672 - val_recall: 0.2250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3707 - accuracy: 0.7989 - auc: 0.9168 - precision: 0.2538 - recall: 0.9073 - val_loss: 0.5994 - val_accuracy: 0.7798 - val_auc: 0.4957 - val_precision: 0.0677 - val_recall: 0.2250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3334 - accuracy: 0.8313 - auc: 0.9328 - precision: 0.2897 - recall: 0.9073 - val_loss: 0.5708 - val_accuracy: 0.7827 - val_auc: 0.5130 - val_precision: 0.0687 - val_recall: 0.2250\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2568 - accuracy: 0.8682 - auc: 0.9609 - precision: 0.3496 - recall: 0.9415 - val_loss: 0.5722 - val_accuracy: 0.8054 - val_auc: 0.4865 - val_precision: 0.0783 - val_recall: 0.2250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2028 - accuracy: 0.9005 - auc: 0.9759 - precision: 0.4183 - recall: 0.9366 - val_loss: 0.5006 - val_accuracy: 0.8423 - val_auc: 0.5141 - val_precision: 0.0824 - val_recall: 0.1750\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1741 - accuracy: 0.9247 - auc: 0.9807 - precision: 0.4914 - recall: 0.9756 - val_loss: 0.6346 - val_accuracy: 0.8153 - val_auc: 0.4825 - val_precision: 0.0500 - val_recall: 0.1250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.8153 - auc: 0.4825 - precision: 0.0500 - recall: 0.1250\n",
      "Scaler: StandardScaler(), Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2132 - accuracy: 0.5275 - auc: 0.5397 - precision: 0.0867 - recall: 0.5756 - val_loss: 0.7657 - val_accuracy: 0.5653 - val_auc: 0.5319 - val_precision: 0.0654 - val_recall: 0.5000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8671 - accuracy: 0.5538 - auc: 0.6012 - precision: 0.0992 - recall: 0.6341 - val_loss: 0.7685 - val_accuracy: 0.5795 - val_auc: 0.4346 - val_precision: 0.0396 - val_recall: 0.2750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6983 - accuracy: 0.5979 - auc: 0.6996 - precision: 0.1160 - recall: 0.6829 - val_loss: 0.6123 - val_accuracy: 0.6562 - val_auc: 0.4864 - val_precision: 0.0570 - val_recall: 0.3250\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5122 - accuracy: 0.6856 - auc: 0.8317 - precision: 0.1667 - recall: 0.8293 - val_loss: 0.5224 - val_accuracy: 0.7656 - val_auc: 0.5261 - val_precision: 0.0748 - val_recall: 0.2750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4526 - accuracy: 0.7442 - auc: 0.8760 - precision: 0.2030 - recall: 0.8585 - val_loss: 0.5802 - val_accuracy: 0.7656 - val_auc: 0.5034 - val_precision: 0.0629 - val_recall: 0.2250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3613 - accuracy: 0.8156 - auc: 0.9205 - precision: 0.2691 - recall: 0.8927 - val_loss: 0.6152 - val_accuracy: 0.7642 - val_auc: 0.4924 - val_precision: 0.0625 - val_recall: 0.2250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8334 - auc: 0.9446 - precision: 0.2975 - recall: 0.9463 - val_loss: 0.5530 - val_accuracy: 0.8011 - val_auc: 0.4999 - val_precision: 0.0968 - val_recall: 0.3000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2812 - accuracy: 0.8607 - auc: 0.9512 - precision: 0.3327 - recall: 0.9073 - val_loss: 0.5239 - val_accuracy: 0.8338 - val_auc: 0.4943 - val_precision: 0.0674 - val_recall: 0.1500\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2063 - accuracy: 0.8867 - auc: 0.9744 - precision: 0.3882 - recall: 0.9659 - val_loss: 0.4119 - val_accuracy: 0.8636 - val_auc: 0.5518 - val_precision: 0.0625 - val_recall: 0.1000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.9350 - auc: 0.9878 - precision: 0.5296 - recall: 0.9610 - val_loss: 0.4995 - val_accuracy: 0.8636 - val_auc: 0.4910 - val_precision: 0.0625 - val_recall: 0.1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8636 - auc: 0.4910 - precision: 0.0625 - recall: 0.1000\n",
      "Scaler: StandardScaler(), Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.2236 - accuracy: 0.4917 - auc: 0.5195 - precision: 0.0778 - recall: 0.5512 - val_loss: 0.8341 - val_accuracy: 0.4389 - val_auc: 0.3866 - val_precision: 0.0483 - val_recall: 0.4750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9232 - accuracy: 0.5481 - auc: 0.5855 - precision: 0.0924 - recall: 0.5902 - val_loss: 0.7100 - val_accuracy: 0.6378 - val_auc: 0.4437 - val_precision: 0.0539 - val_recall: 0.3250\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.6099 - auc: 0.7239 - precision: 0.1257 - recall: 0.7317 - val_loss: 0.6151 - val_accuracy: 0.6932 - val_auc: 0.4310 - val_precision: 0.0319 - val_recall: 0.1500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5392 - accuracy: 0.6760 - auc: 0.8191 - precision: 0.1611 - recall: 0.8195 - val_loss: 0.7001 - val_accuracy: 0.6932 - val_auc: 0.4746 - val_precision: 0.0556 - val_recall: 0.2750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4304 - accuracy: 0.7506 - auc: 0.8922 - precision: 0.2100 - recall: 0.8780 - val_loss: 0.5794 - val_accuracy: 0.7500 - val_auc: 0.4786 - val_precision: 0.0641 - val_recall: 0.2500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3444 - accuracy: 0.8107 - auc: 0.9300 - precision: 0.2650 - recall: 0.9024 - val_loss: 0.6242 - val_accuracy: 0.7656 - val_auc: 0.5034 - val_precision: 0.0567 - val_recall: 0.2000\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3259 - accuracy: 0.8277 - auc: 0.9373 - precision: 0.2879 - recall: 0.9268 - val_loss: 0.5878 - val_accuracy: 0.7770 - val_auc: 0.5245 - val_precision: 0.0465 - val_recall: 0.1500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2740 - accuracy: 0.8654 - auc: 0.9548 - precision: 0.3441 - recall: 0.9366 - val_loss: 0.4933 - val_accuracy: 0.8366 - val_auc: 0.5259 - val_precision: 0.0787 - val_recall: 0.1750\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2391 - accuracy: 0.8845 - auc: 0.9638 - precision: 0.3828 - recall: 0.9561 - val_loss: 0.6571 - val_accuracy: 0.8125 - val_auc: 0.5335 - val_precision: 0.0577 - val_recall: 0.1500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1804 - accuracy: 0.9094 - auc: 0.9797 - precision: 0.4449 - recall: 0.9854 - val_loss: 0.5089 - val_accuracy: 0.8310 - val_auc: 0.5436 - val_precision: 0.0659 - val_recall: 0.1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.8310 - auc: 0.5436 - precision: 0.0659 - recall: 0.1500\n",
      "Scaler: None, Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2092 - accuracy: 0.5144 - auc: 0.5216 - precision: 0.0784 - recall: 0.5268 - val_loss: 0.5849 - val_accuracy: 0.9162 - val_auc: 0.4670 - val_precision: 0.1200 - val_recall: 0.0750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9787 - accuracy: 0.5400 - auc: 0.5748 - precision: 0.0884 - recall: 0.5707 - val_loss: 1.3560 - val_accuracy: 0.0568 - val_auc: 0.5251 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8389 - accuracy: 0.5439 - auc: 0.5872 - precision: 0.0891 - recall: 0.5707 - val_loss: 1.1176 - val_accuracy: 0.0952 - val_auc: 0.5890 - val_precision: 0.0591 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6987 - accuracy: 0.5403 - auc: 0.6686 - precision: 0.1063 - recall: 0.7171 - val_loss: 0.4593 - val_accuracy: 0.8949 - val_auc: 0.5624 - val_precision: 0.0952 - val_recall: 0.1000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6261 - accuracy: 0.6362 - auc: 0.7328 - precision: 0.1327 - recall: 0.7220 - val_loss: 1.0730 - val_accuracy: 0.3253 - val_auc: 0.5343 - val_precision: 0.0606 - val_recall: 0.7500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6231 - accuracy: 0.5996 - auc: 0.7320 - precision: 0.1227 - recall: 0.7317 - val_loss: 0.4767 - val_accuracy: 0.8040 - val_auc: 0.4916 - val_precision: 0.0625 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5437 - accuracy: 0.6401 - auc: 0.7964 - precision: 0.1406 - recall: 0.7707 - val_loss: 0.5931 - val_accuracy: 0.6449 - val_auc: 0.5126 - val_precision: 0.0474 - val_recall: 0.2750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5124 - accuracy: 0.6721 - auc: 0.8177 - precision: 0.1581 - recall: 0.8098 - val_loss: 0.7674 - val_accuracy: 0.5781 - val_auc: 0.5252 - val_precision: 0.0584 - val_recall: 0.4250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5065 - accuracy: 0.6966 - auc: 0.8279 - precision: 0.1685 - recall: 0.8049 - val_loss: 0.8932 - val_accuracy: 0.5298 - val_auc: 0.5431 - val_precision: 0.0604 - val_recall: 0.5000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5155 - accuracy: 0.6917 - auc: 0.8214 - precision: 0.1648 - recall: 0.7951 - val_loss: 0.6373 - val_accuracy: 0.6463 - val_auc: 0.5588 - val_precision: 0.0591 - val_recall: 0.3500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6463 - auc: 0.5588 - precision: 0.0591 - recall: 0.3500\n",
      "Scaler: None, Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.2161 - accuracy: 0.4966 - auc: 0.5240 - precision: 0.0780 - recall: 0.5463 - val_loss: 0.7533 - val_accuracy: 0.2358 - val_auc: 0.4548 - val_precision: 0.0538 - val_recall: 0.7500\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.1210 - accuracy: 0.5204 - auc: 0.5012 - precision: 0.0724 - recall: 0.4732 - val_loss: 0.8770 - val_accuracy: 0.0966 - val_auc: 0.5339 - val_precision: 0.0579 - val_recall: 0.9750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7462 - accuracy: 0.5339 - auc: 0.6513 - precision: 0.1038 - recall: 0.7073 - val_loss: 0.4384 - val_accuracy: 0.9162 - val_auc: 0.5927 - val_precision: 0.0476 - val_recall: 0.0250\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7048 - accuracy: 0.5911 - auc: 0.6777 - precision: 0.1142 - recall: 0.6829 - val_loss: 0.6622 - val_accuracy: 0.5938 - val_auc: 0.5589 - val_precision: 0.0607 - val_recall: 0.4250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6589 - accuracy: 0.6092 - auc: 0.7111 - precision: 0.1217 - recall: 0.7024 - val_loss: 0.2598 - val_accuracy: 0.9361 - val_auc: 0.5584 - val_precision: 0.1429 - val_recall: 0.0250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6220 - accuracy: 0.6266 - auc: 0.7351 - precision: 0.1302 - recall: 0.7268 - val_loss: 0.3345 - val_accuracy: 0.8949 - val_auc: 0.5800 - val_precision: 0.1136 - val_recall: 0.1250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5741 - accuracy: 0.6430 - auc: 0.7629 - precision: 0.1370 - recall: 0.7366 - val_loss: 0.6580 - val_accuracy: 0.6733 - val_auc: 0.5636 - val_precision: 0.0796 - val_recall: 0.4500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5576 - accuracy: 0.6572 - auc: 0.7927 - precision: 0.1462 - recall: 0.7659 - val_loss: 0.6701 - val_accuracy: 0.7358 - val_auc: 0.5016 - val_precision: 0.0602 - val_recall: 0.2500\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5290 - accuracy: 0.6899 - auc: 0.8098 - precision: 0.1578 - recall: 0.7512 - val_loss: 0.8774 - val_accuracy: 0.5298 - val_auc: 0.5239 - val_precision: 0.0631 - val_recall: 0.5250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4994 - accuracy: 0.6970 - auc: 0.8281 - precision: 0.1660 - recall: 0.7854 - val_loss: 0.9004 - val_accuracy: 0.5426 - val_auc: 0.5284 - val_precision: 0.0675 - val_recall: 0.5500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9004 - accuracy: 0.5426 - auc: 0.5284 - precision: 0.0675 - recall: 0.5500\n",
      "Scaler: None, Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2702 - accuracy: 0.5083 - auc: 0.5181 - precision: 0.0744 - recall: 0.5024 - val_loss: 0.3953 - val_accuracy: 0.9418 - val_auc: 0.5052 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0132 - accuracy: 0.5222 - auc: 0.5469 - precision: 0.0833 - recall: 0.5561 - val_loss: 0.8137 - val_accuracy: 0.1420 - val_auc: 0.4737 - val_precision: 0.0594 - val_recall: 0.9500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8257 - accuracy: 0.5290 - auc: 0.5924 - precision: 0.0857 - recall: 0.5659 - val_loss: 0.2635 - val_accuracy: 0.9432 - val_auc: 0.4436 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7053 - accuracy: 0.5773 - auc: 0.6554 - precision: 0.1057 - recall: 0.6439 - val_loss: 1.2548 - val_accuracy: 0.1648 - val_auc: 0.5030 - val_precision: 0.0552 - val_recall: 0.8500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6415 - accuracy: 0.5837 - auc: 0.7138 - precision: 0.1178 - recall: 0.7268 - val_loss: 0.8806 - val_accuracy: 0.3153 - val_auc: 0.4645 - val_precision: 0.0544 - val_recall: 0.6750\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5785 - accuracy: 0.6202 - auc: 0.7686 - precision: 0.1333 - recall: 0.7659 - val_loss: 0.5353 - val_accuracy: 0.8040 - val_auc: 0.5220 - val_precision: 0.0625 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5497 - accuracy: 0.6689 - auc: 0.7951 - precision: 0.1515 - recall: 0.7707 - val_loss: 0.6626 - val_accuracy: 0.7102 - val_auc: 0.4527 - val_precision: 0.0591 - val_recall: 0.2750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5389 - accuracy: 0.6750 - auc: 0.7922 - precision: 0.1464 - recall: 0.7171 - val_loss: 0.5631 - val_accuracy: 0.8011 - val_auc: 0.3983 - val_precision: 0.0455 - val_recall: 0.1250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.6888 - auc: 0.8087 - precision: 0.1635 - recall: 0.7951 - val_loss: 0.8690 - val_accuracy: 0.5710 - val_auc: 0.4460 - val_precision: 0.0451 - val_recall: 0.3250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4587 - accuracy: 0.7101 - auc: 0.8616 - precision: 0.1814 - recall: 0.8488 - val_loss: 0.4094 - val_accuracy: 0.8835 - val_auc: 0.4574 - val_precision: 0.0625 - val_recall: 0.0750\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8835 - auc: 0.4574 - precision: 0.0625 - recall: 0.0750   \n",
      "Scaler: None, Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.1378 - accuracy: 0.5048 - auc: 0.5529 - precision: 0.0781 - recall: 0.5366 - val_loss: 0.4793 - val_accuracy: 0.9432 - val_auc: 0.4357 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0202 - accuracy: 0.5410 - auc: 0.5591 - precision: 0.0873 - recall: 0.5610 - val_loss: 0.4295 - val_accuracy: 0.9347 - val_auc: 0.4596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7737 - accuracy: 0.5478 - auc: 0.6266 - precision: 0.0967 - recall: 0.6244 - val_loss: 0.8562 - val_accuracy: 0.2685 - val_auc: 0.4062 - val_precision: 0.0510 - val_recall: 0.6750\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6645 - accuracy: 0.5982 - auc: 0.6935 - precision: 0.1154 - recall: 0.6780 - val_loss: 0.5978 - val_accuracy: 0.7429 - val_auc: 0.5067 - val_precision: 0.0452 - val_recall: 0.1750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7056 - accuracy: 0.5822 - auc: 0.6715 - precision: 0.1050 - recall: 0.6293 - val_loss: 0.4758 - val_accuracy: 0.8466 - val_auc: 0.4187 - val_precision: 0.0526 - val_recall: 0.1000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6119 - accuracy: 0.6099 - auc: 0.7318 - precision: 0.1213 - recall: 0.6976 - val_loss: 0.7519 - val_accuracy: 0.4830 - val_auc: 0.4100 - val_precision: 0.0475 - val_recall: 0.4250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5688 - accuracy: 0.6309 - auc: 0.7689 - precision: 0.1393 - recall: 0.7854 - val_loss: 0.9462 - val_accuracy: 0.4389 - val_auc: 0.4643 - val_precision: 0.0574 - val_recall: 0.5750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5433 - accuracy: 0.6412 - auc: 0.7994 - precision: 0.1460 - recall: 0.8098 - val_loss: 0.8087 - val_accuracy: 0.5398 - val_auc: 0.4588 - val_precision: 0.0535 - val_recall: 0.4250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5332 - accuracy: 0.6956 - auc: 0.8107 - precision: 0.1632 - recall: 0.7707 - val_loss: 1.0342 - val_accuracy: 0.4901 - val_auc: 0.4451 - val_precision: 0.0456 - val_recall: 0.4000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5322 - accuracy: 0.6980 - auc: 0.8090 - precision: 0.1630 - recall: 0.7610 - val_loss: 0.8031 - val_accuracy: 0.6349 - val_auc: 0.4261 - val_precision: 0.0422 - val_recall: 0.2500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8031 - accuracy: 0.6349 - auc: 0.4261 - precision: 0.0422 - recall: 0.2500\n",
      "Scaler: None, Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2246 - accuracy: 0.4856 - auc: 0.5070 - precision: 0.0752 - recall: 0.5366 - val_loss: 0.4437 - val_accuracy: 0.9403 - val_auc: 0.4650 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0419 - accuracy: 0.5218 - auc: 0.5218 - precision: 0.0771 - recall: 0.5073 - val_loss: 0.6820 - val_accuracy: 0.5426 - val_auc: 0.4843 - val_precision: 0.0538 - val_recall: 0.4250\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8400 - accuracy: 0.5201 - auc: 0.5883 - precision: 0.0872 - recall: 0.5902 - val_loss: 0.6036 - val_accuracy: 0.6719 - val_auc: 0.4735 - val_precision: 0.0558 - val_recall: 0.3000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7021 - accuracy: 0.5798 - auc: 0.6746 - precision: 0.1094 - recall: 0.6683 - val_loss: 0.8344 - val_accuracy: 0.3466 - val_auc: 0.5424 - val_precision: 0.0643 - val_recall: 0.7750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6797 - accuracy: 0.5993 - auc: 0.6950 - precision: 0.1145 - recall: 0.6683 - val_loss: 0.8198 - val_accuracy: 0.4446 - val_auc: 0.5360 - val_precision: 0.0579 - val_recall: 0.5750\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5791 - accuracy: 0.6220 - auc: 0.7613 - precision: 0.1281 - recall: 0.7220 - val_loss: 0.9975 - val_accuracy: 0.3835 - val_auc: 0.5785 - val_precision: 0.0603 - val_recall: 0.6750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5521 - accuracy: 0.6675 - auc: 0.7922 - precision: 0.1496 - recall: 0.7610 - val_loss: 0.8756 - val_accuracy: 0.5028 - val_auc: 0.5796 - val_precision: 0.0646 - val_recall: 0.5750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5200 - accuracy: 0.6654 - auc: 0.8149 - precision: 0.1559 - recall: 0.8146 - val_loss: 0.5907 - val_accuracy: 0.6946 - val_auc: 0.6300 - val_precision: 0.0892 - val_recall: 0.4750\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4998 - accuracy: 0.6973 - auc: 0.8317 - precision: 0.1696 - recall: 0.8098 - val_loss: 0.9395 - val_accuracy: 0.5639 - val_auc: 0.5583 - val_precision: 0.0594 - val_recall: 0.4500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5164 - accuracy: 0.7243 - auc: 0.8226 - precision: 0.1767 - recall: 0.7610 - val_loss: 0.7034 - val_accuracy: 0.6491 - val_auc: 0.6205 - val_precision: 0.0843 - val_recall: 0.5250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.6491 - auc: 0.6205 - precision: 0.0843 - recall: 0.5250\n",
      "Scaler: MinMaxScaler(), Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2696 - accuracy: 0.5169 - auc: 0.5277 - precision: 0.0782 - recall: 0.5220 - val_loss: 1.0050 - val_accuracy: 0.1094 - val_auc: 0.4636 - val_precision: 0.0546 - val_recall: 0.9000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9489 - accuracy: 0.5410 - auc: 0.5528 - precision: 0.0861 - recall: 0.5512 - val_loss: 0.6616 - val_accuracy: 0.6250 - val_auc: 0.5117 - val_precision: 0.0591 - val_recall: 0.3750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7909 - accuracy: 0.5531 - auc: 0.6005 - precision: 0.0941 - recall: 0.5951 - val_loss: 0.6655 - val_accuracy: 0.6420 - val_auc: 0.5569 - val_precision: 0.0656 - val_recall: 0.4000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7533 - accuracy: 0.5702 - auc: 0.6407 - precision: 0.1002 - recall: 0.6146 - val_loss: 0.4604 - val_accuracy: 0.8196 - val_auc: 0.4996 - val_precision: 0.0606 - val_recall: 0.1500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6820 - accuracy: 0.6096 - auc: 0.6865 - precision: 0.1113 - recall: 0.6244 - val_loss: 0.4224 - val_accuracy: 0.8381 - val_auc: 0.4844 - val_precision: 0.0375 - val_recall: 0.0750\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5544 - accuracy: 0.6504 - auc: 0.7994 - precision: 0.1443 - recall: 0.7707 - val_loss: 0.5519 - val_accuracy: 0.7614 - val_auc: 0.4882 - val_precision: 0.0493 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4871 - accuracy: 0.7218 - auc: 0.8538 - precision: 0.1866 - recall: 0.8390 - val_loss: 0.4823 - val_accuracy: 0.7770 - val_auc: 0.5087 - val_precision: 0.0534 - val_recall: 0.1750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.7691 - auc: 0.8915 - precision: 0.2256 - recall: 0.8927 - val_loss: 0.3447 - val_accuracy: 0.8778 - val_auc: 0.5618 - val_precision: 0.0577 - val_recall: 0.0750\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3098 - accuracy: 0.8391 - auc: 0.9456 - precision: 0.3032 - recall: 0.9317 - val_loss: 0.5819 - val_accuracy: 0.7855 - val_auc: 0.5131 - val_precision: 0.0698 - val_recall: 0.2250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.8490 - auc: 0.9459 - precision: 0.3148 - recall: 0.9122 - val_loss: 0.7537 - val_accuracy: 0.7472 - val_auc: 0.5038 - val_precision: 0.0741 - val_recall: 0.3000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7472 - auc: 0.5038 - precision: 0.0741 - recall: 0.3000   \n",
      "Scaler: MinMaxScaler(), Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.2610 - accuracy: 0.4867 - auc: 0.5003 - precision: 0.0718 - recall: 0.5073 - val_loss: 0.9867 - val_accuracy: 0.1690 - val_auc: 0.5385 - val_precision: 0.0569 - val_recall: 0.8750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9639 - accuracy: 0.5069 - auc: 0.5231 - precision: 0.0784 - recall: 0.5366 - val_loss: 0.7438 - val_accuracy: 0.5213 - val_auc: 0.5132 - val_precision: 0.0645 - val_recall: 0.5500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7516 - accuracy: 0.5400 - auc: 0.6232 - precision: 0.0981 - recall: 0.6488 - val_loss: 0.6147 - val_accuracy: 0.6648 - val_auc: 0.4731 - val_precision: 0.0545 - val_recall: 0.3000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7356 - accuracy: 0.5851 - auc: 0.6363 - precision: 0.1050 - recall: 0.6244 - val_loss: 0.7858 - val_accuracy: 0.5384 - val_auc: 0.4897 - val_precision: 0.0561 - val_recall: 0.4500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6282 - accuracy: 0.6082 - auc: 0.7378 - precision: 0.1301 - recall: 0.7707 - val_loss: 0.6091 - val_accuracy: 0.6577 - val_auc: 0.5582 - val_precision: 0.0795 - val_recall: 0.4750\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5742 - accuracy: 0.6451 - auc: 0.7811 - precision: 0.1423 - recall: 0.7707 - val_loss: 0.6016 - val_accuracy: 0.6747 - val_auc: 0.5084 - val_precision: 0.0521 - val_recall: 0.2750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4634 - accuracy: 0.7027 - auc: 0.8650 - precision: 0.1789 - recall: 0.8585 - val_loss: 0.4992 - val_accuracy: 0.7642 - val_auc: 0.5260 - val_precision: 0.0435 - val_recall: 0.1500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4336 - accuracy: 0.7748 - auc: 0.8855 - precision: 0.2254 - recall: 0.8585 - val_loss: 0.8009 - val_accuracy: 0.6094 - val_auc: 0.5752 - val_precision: 0.0727 - val_recall: 0.5000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3664 - accuracy: 0.7957 - auc: 0.9189 - precision: 0.2500 - recall: 0.9024 - val_loss: 0.5848 - val_accuracy: 0.7472 - val_auc: 0.4977 - val_precision: 0.0633 - val_recall: 0.2500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3327 - accuracy: 0.8224 - auc: 0.9333 - precision: 0.2789 - recall: 0.9073 - val_loss: 0.5696 - val_accuracy: 0.7699 - val_auc: 0.5604 - val_precision: 0.0878 - val_recall: 0.3250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7699 - auc: 0.5604 - precision: 0.0878 - recall: 0.3250\n",
      "Scaler: MinMaxScaler(), Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3860 - accuracy: 0.4973 - auc: 0.4665 - precision: 0.0672 - recall: 0.4585 - val_loss: 0.8767 - val_accuracy: 0.3509 - val_auc: 0.4959 - val_precision: 0.0497 - val_recall: 0.5750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8917 - accuracy: 0.4877 - auc: 0.5140 - precision: 0.0726 - recall: 0.5122 - val_loss: 0.6887 - val_accuracy: 0.5440 - val_auc: 0.4456 - val_precision: 0.0568 - val_recall: 0.4500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7893 - accuracy: 0.5428 - auc: 0.5953 - precision: 0.0932 - recall: 0.6049 - val_loss: 0.6510 - val_accuracy: 0.6591 - val_auc: 0.4918 - val_precision: 0.0614 - val_recall: 0.3500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7445 - accuracy: 0.5773 - auc: 0.6458 - precision: 0.1101 - recall: 0.6780 - val_loss: 0.6391 - val_accuracy: 0.6477 - val_auc: 0.4489 - val_precision: 0.0517 - val_recall: 0.3000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6061 - accuracy: 0.6334 - auc: 0.7498 - precision: 0.1344 - recall: 0.7415 - val_loss: 0.6036 - val_accuracy: 0.6776 - val_auc: 0.5337 - val_precision: 0.0651 - val_recall: 0.3500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5839 - accuracy: 0.6515 - auc: 0.7773 - precision: 0.1414 - recall: 0.7463 - val_loss: 0.5865 - val_accuracy: 0.7202 - val_auc: 0.4718 - val_precision: 0.0615 - val_recall: 0.2750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5002 - accuracy: 0.6945 - auc: 0.8421 - precision: 0.1709 - recall: 0.8293 - val_loss: 0.3512 - val_accuracy: 0.8793 - val_auc: 0.5139 - val_precision: 0.0755 - val_recall: 0.1000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4177 - accuracy: 0.7641 - auc: 0.8939 - precision: 0.2205 - recall: 0.8829 - val_loss: 0.3576 - val_accuracy: 0.8651 - val_auc: 0.5734 - val_precision: 0.1333 - val_recall: 0.2500\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3479 - accuracy: 0.8178 - auc: 0.9294 - precision: 0.2735 - recall: 0.9073 - val_loss: 0.6584 - val_accuracy: 0.7131 - val_auc: 0.4996 - val_precision: 0.0737 - val_recall: 0.3500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3271 - accuracy: 0.8419 - auc: 0.9381 - precision: 0.3039 - recall: 0.9073 - val_loss: 0.5338 - val_accuracy: 0.7898 - val_auc: 0.5181 - val_precision: 0.0909 - val_recall: 0.3000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7898 - auc: 0.5181 - precision: 0.0909 - recall: 0.3000\n",
      "Scaler: MinMaxScaler(), Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3317 - accuracy: 0.4753 - auc: 0.4933 - precision: 0.0720 - recall: 0.5220 - val_loss: 0.9787 - val_accuracy: 0.0909 - val_auc: 0.4307 - val_precision: 0.0575 - val_recall: 0.9750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9243 - accuracy: 0.5428 - auc: 0.5772 - precision: 0.0932 - recall: 0.6049 - val_loss: 0.6508 - val_accuracy: 0.6136 - val_auc: 0.4528 - val_precision: 0.0538 - val_recall: 0.3500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8080 - accuracy: 0.5556 - auc: 0.6077 - precision: 0.0989 - recall: 0.6293 - val_loss: 0.6310 - val_accuracy: 0.6179 - val_auc: 0.5045 - val_precision: 0.0579 - val_recall: 0.3750\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7450 - accuracy: 0.5726 - auc: 0.6396 - precision: 0.1033 - recall: 0.6341 - val_loss: 0.6028 - val_accuracy: 0.6918 - val_auc: 0.4887 - val_precision: 0.0597 - val_recall: 0.3000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6496 - accuracy: 0.6231 - auc: 0.7132 - precision: 0.1304 - recall: 0.7366 - val_loss: 0.5887 - val_accuracy: 0.7031 - val_auc: 0.5470 - val_precision: 0.0796 - val_recall: 0.4000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5539 - accuracy: 0.6625 - auc: 0.8005 - precision: 0.1528 - recall: 0.8000 - val_loss: 0.5486 - val_accuracy: 0.7159 - val_auc: 0.5271 - val_precision: 0.0699 - val_recall: 0.3250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4815 - accuracy: 0.7155 - auc: 0.8565 - precision: 0.1843 - recall: 0.8488 - val_loss: 0.4896 - val_accuracy: 0.8168 - val_auc: 0.5250 - val_precision: 0.0680 - val_recall: 0.1750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4075 - accuracy: 0.7673 - auc: 0.9004 - precision: 0.2256 - recall: 0.9024 - val_loss: 0.4349 - val_accuracy: 0.8153 - val_auc: 0.5365 - val_precision: 0.0833 - val_recall: 0.2250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3736 - accuracy: 0.8011 - auc: 0.9160 - precision: 0.2517 - recall: 0.8780 - val_loss: 1.0817 - val_accuracy: 0.6207 - val_auc: 0.5398 - val_precision: 0.0749 - val_recall: 0.5000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3389 - accuracy: 0.8220 - auc: 0.9315 - precision: 0.2798 - recall: 0.9171 - val_loss: 0.6201 - val_accuracy: 0.7486 - val_auc: 0.4930 - val_precision: 0.0523 - val_recall: 0.2000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.7486 - auc: 0.4930 - precision: 0.0523 - recall: 0.2000   \n",
      "Scaler: MinMaxScaler(), Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.3523 - accuracy: 0.5119 - auc: 0.4930 - precision: 0.0768 - recall: 0.5171 - val_loss: 0.8453 - val_accuracy: 0.2713 - val_auc: 0.4329 - val_precision: 0.0529 - val_recall: 0.7000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9218 - accuracy: 0.5009 - auc: 0.5559 - precision: 0.0851 - recall: 0.6000 - val_loss: 0.9036 - val_accuracy: 0.2670 - val_auc: 0.5221 - val_precision: 0.0543 - val_recall: 0.7250\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7848 - accuracy: 0.5464 - auc: 0.6019 - precision: 0.0908 - recall: 0.5805 - val_loss: 0.6554 - val_accuracy: 0.6151 - val_auc: 0.4772 - val_precision: 0.0398 - val_recall: 0.2500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7147 - accuracy: 0.5805 - auc: 0.6644 - precision: 0.1127 - recall: 0.6927 - val_loss: 0.6793 - val_accuracy: 0.6193 - val_auc: 0.4739 - val_precision: 0.0476 - val_recall: 0.3000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6332 - accuracy: 0.6234 - auc: 0.7337 - precision: 0.1311 - recall: 0.7415 - val_loss: 0.4980 - val_accuracy: 0.7443 - val_auc: 0.4885 - val_precision: 0.0513 - val_recall: 0.2000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5736 - accuracy: 0.6785 - auc: 0.7876 - precision: 0.1562 - recall: 0.7756 - val_loss: 0.4891 - val_accuracy: 0.7585 - val_auc: 0.5168 - val_precision: 0.0486 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4902 - accuracy: 0.7098 - auc: 0.8464 - precision: 0.1792 - recall: 0.8341 - val_loss: 0.4410 - val_accuracy: 0.8068 - val_auc: 0.5175 - val_precision: 0.0636 - val_recall: 0.1750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4082 - accuracy: 0.7616 - auc: 0.8999 - precision: 0.2200 - recall: 0.8927 - val_loss: 0.4966 - val_accuracy: 0.7642 - val_auc: 0.4871 - val_precision: 0.0563 - val_recall: 0.2000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3431 - accuracy: 0.8156 - auc: 0.9291 - precision: 0.2738 - recall: 0.9268 - val_loss: 0.4188 - val_accuracy: 0.8310 - val_auc: 0.5326 - val_precision: 0.0562 - val_recall: 0.1250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2661 - accuracy: 0.8526 - auc: 0.9604 - precision: 0.3238 - recall: 0.9415 - val_loss: 0.4367 - val_accuracy: 0.8310 - val_auc: 0.5788 - val_precision: 0.0928 - val_recall: 0.2250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8310 - auc: 0.5788 - precision: 0.0928 - recall: 0.2250   \n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3796 - accuracy: 0.4856 - auc: 0.4749 - precision: 0.0711 - recall: 0.5024 - val_loss: 0.9742 - val_accuracy: 0.0568 - val_auc: 0.5092 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9581 - accuracy: 0.5044 - auc: 0.5219 - precision: 0.0750 - recall: 0.5122 - val_loss: 0.8589 - val_accuracy: 0.0568 - val_auc: 0.4884 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9278 - accuracy: 0.5115 - auc: 0.4923 - precision: 0.0767 - recall: 0.5171 - val_loss: 1.5563 - val_accuracy: 0.0568 - val_auc: 0.4905 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8469 - accuracy: 0.4963 - auc: 0.5126 - precision: 0.0779 - recall: 0.5463 - val_loss: 0.4613 - val_accuracy: 0.9432 - val_auc: 0.4659 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8454 - accuracy: 0.4920 - auc: 0.4966 - precision: 0.0749 - recall: 0.5268 - val_loss: 0.9765 - val_accuracy: 0.0568 - val_auc: 0.5015 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7841 - accuracy: 0.5044 - auc: 0.4996 - precision: 0.0732 - recall: 0.4976 - val_loss: 0.6887 - val_accuracy: 0.9432 - val_auc: 0.5017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7618 - accuracy: 0.5016 - auc: 0.5069 - precision: 0.0709 - recall: 0.4829 - val_loss: 0.5728 - val_accuracy: 0.9432 - val_auc: 0.4917 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7571 - accuracy: 0.5048 - auc: 0.4955 - precision: 0.0732 - recall: 0.4976 - val_loss: 0.5309 - val_accuracy: 0.9432 - val_auc: 0.5343 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7407 - accuracy: 0.4920 - auc: 0.5072 - precision: 0.0749 - recall: 0.5268 - val_loss: 0.3911 - val_accuracy: 0.9432 - val_auc: 0.4840 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7363 - accuracy: 0.5002 - auc: 0.4997 - precision: 0.0756 - recall: 0.5220 - val_loss: 0.4746 - val_accuracy: 0.9432 - val_auc: 0.5044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.9432 - auc: 0.5044 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2907 - accuracy: 0.5055 - auc: 0.5108 - precision: 0.0770 - recall: 0.5268 - val_loss: 1.1217 - val_accuracy: 0.0568 - val_auc: 0.4949 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9737 - accuracy: 0.5229 - auc: 0.5209 - precision: 0.0791 - recall: 0.5220 - val_loss: 0.4862 - val_accuracy: 0.9432 - val_auc: 0.5247 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8864 - accuracy: 0.5098 - auc: 0.5322 - precision: 0.0789 - recall: 0.5366 - val_loss: 0.6154 - val_accuracy: 0.8835 - val_auc: 0.4732 - val_precision: 0.0800 - val_recall: 0.1000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8005 - accuracy: 0.5048 - auc: 0.5582 - precision: 0.0810 - recall: 0.5610 - val_loss: 0.5916 - val_accuracy: 0.8026 - val_auc: 0.4864 - val_precision: 0.0459 - val_recall: 0.1250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8195 - accuracy: 0.5162 - auc: 0.5095 - precision: 0.0768 - recall: 0.5122 - val_loss: 2.5852 - val_accuracy: 0.0568 - val_auc: 0.5015 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8146 - accuracy: 0.4998 - auc: 0.4959 - precision: 0.0713 - recall: 0.4878 - val_loss: 0.5739 - val_accuracy: 0.9432 - val_auc: 0.5333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7750 - accuracy: 0.5069 - auc: 0.5073 - precision: 0.0772 - recall: 0.5268 - val_loss: 0.6740 - val_accuracy: 0.6634 - val_auc: 0.5081 - val_precision: 0.0502 - val_recall: 0.2750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7729 - accuracy: 0.5002 - auc: 0.4825 - precision: 0.0695 - recall: 0.4732 - val_loss: 0.4481 - val_accuracy: 0.9432 - val_auc: 0.4941 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7228 - accuracy: 0.5293 - auc: 0.5545 - precision: 0.0858 - recall: 0.5659 - val_loss: 1.2191 - val_accuracy: 0.0568 - val_auc: 0.5115 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7335 - accuracy: 0.5123 - auc: 0.5051 - precision: 0.0743 - recall: 0.4976 - val_loss: 1.0543 - val_accuracy: 0.0568 - val_auc: 0.5497 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0543 - accuracy: 0.0568 - auc: 0.5497 - precision: 0.0568 - recall: 1.0000\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2160 - accuracy: 0.5208 - auc: 0.5471 - precision: 0.0837 - recall: 0.5610 - val_loss: 1.1365 - val_accuracy: 0.0568 - val_auc: 0.5089 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9733 - accuracy: 0.5052 - auc: 0.5316 - precision: 0.0793 - recall: 0.5463 - val_loss: 0.6587 - val_accuracy: 0.7259 - val_auc: 0.5651 - val_precision: 0.0726 - val_recall: 0.3250\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9231 - accuracy: 0.5172 - auc: 0.5105 - precision: 0.0751 - recall: 0.4976 - val_loss: 0.6217 - val_accuracy: 0.9432 - val_auc: 0.5060 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8792 - accuracy: 0.5098 - auc: 0.5139 - precision: 0.0764 - recall: 0.5171 - val_loss: 0.4780 - val_accuracy: 0.9432 - val_auc: 0.4829 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8438 - accuracy: 0.5076 - auc: 0.4894 - precision: 0.0693 - recall: 0.4634 - val_loss: 1.0295 - val_accuracy: 0.0568 - val_auc: 0.5906 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8026 - accuracy: 0.4888 - auc: 0.4659 - precision: 0.0636 - recall: 0.4390 - val_loss: 2.9948 - val_accuracy: 0.0568 - val_auc: 0.5000 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7527 - accuracy: 0.5012 - auc: 0.5111 - precision: 0.0751 - recall: 0.5171 - val_loss: 1.0674 - val_accuracy: 0.0568 - val_auc: 0.5327 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7619 - accuracy: 0.5012 - auc: 0.4830 - precision: 0.0721 - recall: 0.4927 - val_loss: 0.5843 - val_accuracy: 0.9432 - val_auc: 0.5450 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7403 - accuracy: 0.5094 - auc: 0.5114 - precision: 0.0806 - recall: 0.5512 - val_loss: 0.8928 - val_accuracy: 0.0568 - val_auc: 0.4338 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7366 - accuracy: 0.4966 - auc: 0.4893 - precision: 0.0696 - recall: 0.4780 - val_loss: 0.5084 - val_accuracy: 0.9432 - val_auc: 0.4696 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.9432 - auc: 0.4696 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 21ms/step - loss: 1.3211 - accuracy: 0.4970 - auc: 0.4887 - precision: 0.0647 - recall: 0.4390 - val_loss: 1.0160 - val_accuracy: 0.0568 - val_auc: 0.4965 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9585 - accuracy: 0.4863 - auc: 0.5151 - precision: 0.0770 - recall: 0.5512 - val_loss: 1.1324 - val_accuracy: 0.0568 - val_auc: 0.4461 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9306 - accuracy: 0.5059 - auc: 0.4862 - precision: 0.0709 - recall: 0.4780 - val_loss: 1.3424 - val_accuracy: 0.0568 - val_auc: 0.4927 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8751 - accuracy: 0.4920 - auc: 0.4970 - precision: 0.0761 - recall: 0.5366 - val_loss: 1.5900 - val_accuracy: 0.0568 - val_auc: 0.5453 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8006 - accuracy: 0.5190 - auc: 0.5303 - precision: 0.0810 - recall: 0.5415 - val_loss: 1.3589 - val_accuracy: 0.0568 - val_auc: 0.5265 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7991 - accuracy: 0.4945 - auc: 0.4762 - precision: 0.0669 - recall: 0.4585 - val_loss: 0.8715 - val_accuracy: 0.0568 - val_auc: 0.5084 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7800 - accuracy: 0.5087 - auc: 0.4793 - precision: 0.0694 - recall: 0.4634 - val_loss: 2.0332 - val_accuracy: 0.0568 - val_auc: 0.5000 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7668 - accuracy: 0.4881 - auc: 0.4852 - precision: 0.0720 - recall: 0.5073 - val_loss: 0.5410 - val_accuracy: 0.9432 - val_auc: 0.4970 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7323 - accuracy: 0.4899 - auc: 0.5034 - precision: 0.0740 - recall: 0.5220 - val_loss: 0.4445 - val_accuracy: 0.9432 - val_auc: 0.5886 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7242 - accuracy: 0.5023 - auc: 0.5250 - precision: 0.0753 - recall: 0.5171 - val_loss: 0.5916 - val_accuracy: 0.9432 - val_auc: 0.5059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.9432 - auc: 0.5059 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2567 - accuracy: 0.5144 - auc: 0.5198 - precision: 0.0778 - recall: 0.5220 - val_loss: 0.8279 - val_accuracy: 0.0568 - val_auc: 0.4962 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0356 - accuracy: 0.5187 - auc: 0.5442 - precision: 0.0869 - recall: 0.5902 - val_loss: 0.6855 - val_accuracy: 0.7003 - val_auc: 0.4322 - val_precision: 0.0328 - val_recall: 0.1500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9014 - accuracy: 0.5233 - auc: 0.5224 - precision: 0.0722 - recall: 0.4683 - val_loss: 1.0906 - val_accuracy: 0.0568 - val_auc: 0.5294 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8666 - accuracy: 0.5229 - auc: 0.5220 - precision: 0.0779 - recall: 0.5122 - val_loss: 1.2143 - val_accuracy: 0.0568 - val_auc: 0.5231 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8483 - accuracy: 0.5012 - auc: 0.4883 - precision: 0.0678 - recall: 0.4585 - val_loss: 0.2816 - val_accuracy: 0.9432 - val_auc: 0.4965 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7696 - accuracy: 0.5048 - auc: 0.5203 - precision: 0.0757 - recall: 0.5171 - val_loss: 1.2044 - val_accuracy: 0.0568 - val_auc: 0.5000 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7569 - accuracy: 0.5272 - auc: 0.5406 - precision: 0.0872 - recall: 0.5805 - val_loss: 0.4411 - val_accuracy: 0.9432 - val_auc: 0.4973 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7744 - accuracy: 0.5005 - auc: 0.4706 - precision: 0.0677 - recall: 0.4585 - val_loss: 0.3541 - val_accuracy: 0.9432 - val_auc: 0.4891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7525 - accuracy: 0.4877 - auc: 0.4986 - precision: 0.0743 - recall: 0.5268 - val_loss: 0.7361 - val_accuracy: 0.0568 - val_auc: 0.5423 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7234 - accuracy: 0.5151 - auc: 0.5440 - precision: 0.0839 - recall: 0.5707 - val_loss: 0.3501 - val_accuracy: 0.9432 - val_auc: 0.4819 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.9432 - auc: 0.4819 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "# Run the experiment for each type of scaler 5 times\n",
    "for scaler in ['standard', 'None', '[0,1]', '[-1,1]']:\n",
    "    # Run experiment\n",
    "    results = test_scaler(X, y, results=results, scaler=scaler, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8133b0aa-62e6-4d05-be0b-cd8817ce399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACA6ElEQVR4nOzdd3iN9//H8dfJRsQWK/aWqlliVK2olhrVmkXt2kERqlbtWjVjtqhSe9RKtVZpbbWrtUdsIkHGOffvD7+cbyJBqo6T8Xxcl6u973Pfd95H3Ofcr/szbpNhGIYAAAAAAMAr52DvAgAAAAAASKoI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QCAROvbb7+VyWSy/nFyclLWrFnVpEkTnTlzxt7lSZJy586t1q1bW5fPnz8vk8mkb7/99rn7bdu2TSaTScuXL7dtgZL++OMPNWjQQDlz5pSrq6s8PT3l4+Oj3r172+xnRv3uzp8/b7OfIT35+4/+b+RZf170+wAA4GU52bsAAAD+q/nz56tw4cJ6/PixfvvtN40YMUK//vqrTp06pXTp0tm7vATtp59+0gcffKB33nlHY8eOVdasWXXt2jXt379fS5Ys0fjx4+1d4n+yatUqhYWFWZfnzJmjuXPnatOmTUqTJo11fb58+exRHgAgGSB0AwASPW9vb5UpU0aS9M4778hsNmvw4MFavXq1Pv30UztXl7CNHTtWefLk0ebNm+Xk9L/LgiZNmmjs2LF2rOzfefjwoVKmTBlrfcmSJWMsb9q0SZJUunRpZcyY8bXUBgBI3uheDgBIcqIC+PXr12Os379/vz744AOlT59ebm5uKlmypH788cdY+1+5ckUdOnSQl5eXXFxclC1bNjVq1Mh6vMePH6t3794qUaKE0qRJo/Tp08vHx0dr1qx55e/l8ePH6tWrl7JkyaIUKVKoSpUqOnTokPX1hQsXymQyac+ePbH2HTZsmJydnXX16tVnHv/27dvKmDFjjMAdxcEh9mXC4sWL5ePjI3d3d7m7u6tEiRKaO3eu9fXAwEDVq1dPOXLkkJubm/Lnz6+OHTvq1q1b8Xq/P//8s6pXry4PDw+lTJlSFStW1NatW2NsM2TIEJlMJh08eFCNGjVSunTpXrqlevjw4XJyctKlS5divdamTRtlyJBBjx8/lvSkq3qdOnW0atUqFS9eXG5ubsqbN6+++eabWPsGBwerT58+ypMnj1xcXJQ9e3b17NlToaGhL1UnACDxInQDAJKcc+fOSZIKFixoXffrr7+qYsWKunfvnmbOnKk1a9aoRIkSaty4cYzxvFeuXFHZsmW1atUq9erVSxs3btSkSZOUJk0a3b17V5IUFhamO3fuqE+fPlq9erV++OEHVapUSQ0bNtSCBQte6XsZMGCAzp49qzlz5mjOnDm6evWq3nnnHZ09e1aS1LhxY2XJkkXTpk2LsV9kZKQCAgLUoEEDZcuW7ZnH9/Hx0R9//KHu3bvrjz/+UERExDO3/fLLL9W8eXNly5ZN3377rVatWqVWrVrpwoUL1m3++ecf+fj4aMaMGdqyZYu+/PJL/fHHH6pUqdJzjy1JixYtkq+vrzw8PPTdd9/pxx9/VPr06VWrVq1YwVuSGjZsqPz582vZsmWaOXPmc4/9LB07dpSTk5MCAgJirL9z546WLFmitm3bys3Nzbr+8OHD6tmzp/z8/LRq1SpVqFBBPXr00Ndff23d5uHDh6pSpYq+++47de/eXRs3blS/fv307bff6oMPPpBhGC9VKwAgkTIAAEik5s+fb0gyfv/9dyMiIsJ48OCBsWnTJiNLlizG22+/bURERFi3LVy4sFGyZMkY6wzDMOrUqWNkzZrVMJvNhmEYRps2bQxnZ2fjxIkT8a4jMjLSiIiIMNq2bWuULFkyxmu5cuUyWrVqZV0+d+6cIcmYP3/+c4/566+/GpKMUqVKGRaLxbr+/PnzhrOzs9GuXTvrusGDBxsuLi7G9evXreuWLl1qSDK2b9/+3J9z69Yto1KlSoYkQ5Lh7OxsVKhQwRg1apTx4MED63Znz541HB0djebNmz/3eNFZLBYjIiLCuHDhgiHJWLNmjfW1qN/duXPnDMMwjNDQUCN9+vRG3bp1YxzDbDYbb775pvHWW2/FeL+SjC+//DLetTy9782bN63rWrVqZWTOnNkICwuzrhszZozh4OBgrc8wnvwuTSaTcfjw4RjHrFmzpuHh4WGEhoYahmEYo0aNMhwcHIx9+/bF2G758uWGJGPDhg3/um4AQOJFSzcAINErX768nJ2dlTp1ar377rtKly6d1qxZY+0y/ffff+vUqVNq3ry5pCetwFF/3nvvPV27dk2nT5+WJG3cuFFVq1ZVkSJFnvszly1bpooVK8rd3V1OTk5ydnbW3LlzdfLkyVf63po1ayaTyWRdzpUrlypUqKBff/3Vuu6zzz6TJM2ePdu6burUqXrjjTf09ttvP/f4GTJk0M6dO7Vv3z6NHj1a9erV019//SV/f3+98cYb1m7hgYGBMpvN6tKly3OPd+PGDXXq1EleXl7Wv5dcuXJJ0nP/bnbv3q07d+6oVatWMX4/FotF7777rvbt2xera/aHH3743Friq0ePHrpx44aWLVsmSbJYLJoxY4bef/995c6dO8a2xYoV05tvvhljXbNmzRQcHKyDBw9KktavXy9vb2+VKFEixnupVauWTCaTtm3b9krqBgAkDoRuAECit2DBAu3bt0+//PKLOnbsqJMnT6pp06bW16PGYvfp00fOzs4x/nTu3FmSrOHy5s2bypEjx3N/3sqVK/Xxxx8re/bsWrRokfbs2aN9+/apTZs21vG/r0qWLFniXHf79m3rsqenpxo3bqyAgACZzWb9+eef2rlzp7p27Rrvn1OmTBn169dPy5Yt09WrV+Xn56fz589bJ1O7efOmJD3378ZiscjX11crV65U3759tXXrVu3du1e///67JOnRo0fP3Dfqd9SoUaNYv6MxY8bIMAzduXMnxj5Zs2aN9/t7npIlS6py5crWLvrr16/X+fPn4/z7e9bvQ5L1d3L9+nX9+eefsd5H6tSpZRhGvMe3AwCSBmYvBwAkekWKFLFOnla1alWZzWbNmTNHy5cvV6NGjayzVPv7+6thw4ZxHqNQoUKSpEyZMuny5cvP/XmLFi1Snjx5tHTp0hit0NEfTfWqBAUFxbkuQ4YMMdb16NFDCxcu1Jo1a7Rp0yalTZvW2rL/bzk7O2vw4MGaOHGijh07JunJ34skXb58WV5eXnHud+zYMR05ckTffvutWrVqZV3/999/v/BnRv2OpkyZovLly8e5jaenZ4zl6H/3/1X37t310Ucf6eDBg5o6daoKFiyomjVrxtruWb8PSdbfScaMGZUiRQrNmzcvzp/FrOkAkLwQugEASc7YsWO1YsUKffnll2rYsKEKFSqkAgUK6MiRIxo5cuRz961du7YWLlyo06dPW4P400wmk1xcXGKEvqCgIJvMXv7DDz+oV69e1p914cIF7d69Wy1btoyxXenSpVWhQgWNGTNGx44dU4cOHZQqVaoXHv/atWtxthhHdQWPmoTN19dXjo6OmjFjhnx8fOI8VlSNrq6uMdY/PUlZXCpWrKi0adPqxIkT/6qF/lVp0KCBcubMqd69e2v79u2aOHFinKH++PHjOnLkSIwu5osXL1bq1KlVqlQpSVKdOnU0cuRIZciQQXny5Hlt7wEAkDARugEASU66dOnk7++vvn37avHixWrRooUCAgJUu3Zt1apVS61bt1b27Nl1584dnTx5UgcPHrSO5x02bJg2btyot99+WwMGDNAbb7yhe/fuadOmTerVq5cKFy6sOnXqaOXKlercubMaNWqkS5cuafjw4cqaNavOnDnzSt/LjRs31KBBA7Vv317379/X4MGD5ebmJn9//1jb9ujRQ40bN5bJZLJ2m3+RWrVqKUeOHKpbt64KFy4si8Wiw4cPa/z48XJ3d1ePHj0kPXlc1oABAzR8+HA9evRITZs2VZo0aXTixAndunVLQ4cOVeHChZUvXz71799fhmEoffr0WrdunQIDA19Yh7u7u6ZMmaJWrVrpzp07atSokTJnzqybN2/qyJEjunnzpmbMmPHv/vL+BUdHR3Xp0kX9+vVTqlSp1Lp16zi3y5Ytmz744AMNGTJEWbNm1aJFixQYGKgxY8ZYnxPes2dPrVixQm+//bb8/PxUvHhxWSwWXbx4UVu2bFHv3r1Vrlw5m70XAEACY+eJ3AAAeGlRM2A/PUu0YRjGo0ePjJw5cxoFChQwIiMjDcMwjCNHjhgff/yxkTlzZsPZ2dnIkiWLUa1aNWPmzJkx9r106ZLRpk0bI0uWLIazs7ORLVs24+OPP44xO/jo0aON3LlzG66urkaRIkWM2bNnW2fGju6/zl6+cOFCo3v37kamTJkMV1dXo3Llysb+/fvj3CcsLMxwdXU13n333eceO7qlS5cazZo1MwoUKGC4u7sbzs7ORs6cOY1PPvkkzhncFyxYYJQtW9Zwc3Mz3N3djZIlS8Z4LydOnDBq1qxppE6d2kiXLp3x0UcfGRcvXjQkGYMHD7Zu9/Ts5VG2b99uvP/++0b69OkNZ2dnI3v27Mb7779vLFu2zLpNXDOQx9fz9j1//rwhyejUqVOc++bKlct4//33jeXLlxvFihUzXFxcjNy5cxsTJkyItW1ISIjxxRdfGIUKFTJcXFyMNGnSGG+88Ybh5+dnBAUF/eu6AQCJl8kweFgkAABJwbp16/TBBx/op59+0nvvvWfvchKdKVOmqHv37jp27JiKFSsW6/XcuXPL29tb69evt0N1AIDEiu7lAAAkcidOnNCFCxfUu3dvlShRQrVr17Z3SYnKoUOHdO7cOQ0bNkz16tWLM3ADAPCyCN0AACRynTt31m+//aZSpUrpu+++e6WzeicHDRo0UFBQkCpXrqyZM2fauxwAQBJD93IAAAAAAGzEwd4FAAAAAACQVBG6AQAAAACwEUI3AAAAAAA2kuwmUrNYLLp69apSp07NRDMAAAAAgJdiGIYePHigbNmyycHh2e3ZyS50X716VV5eXvYuAwAAAACQBFy6dEk5cuR45uvJLnSnTp1a0pO/GA8PDztXAwAAAABIjIKDg+Xl5WXNmM+S7EJ3VJdyDw8PQjcAAAAA4D950bBlJlIDAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCN2D93Tp09Xnjx55ObmptKlS2vnzp3P3T4sLEwDBw5Urly55Orqqnz58mnevHmvqVoAAAAAAOLPrrOXL126VD179tT06dNVsWJFBQQEqHbt2jpx4oRy5swZ5z4ff/yxrl+/rrlz5yp//vy6ceOGIiMjX3PlAAAAAAC8mMkwDMNeP7xcuXIqVaqUZsyYYV1XpEgR1a9fX6NGjYq1/aZNm9SkSROdPXtW6dOnf6mfGRwcrDRp0uj+/fs8MgwAAADAa2MYhkJDQ63LqVKleuHjppBwxTdb2q2lOzw8XAcOHFD//v1jrPf19dXu3bvj3Gft2rUqU6aMxo4dq4ULFypVqlT64IMPNHz4cKVIkSLOfcLCwhQWFmZdDg4OliRFREQoIiLiFb0bAAAAAHi+kJAQNWrUyLq8fPlyubu727Ei/BfxzZN2C923bt2S2WyWp6dnjPWenp4KCgqKc5+zZ89q165dcnNz06pVq3Tr1i117txZd+7ceea47lGjRmno0KGx1m/ZskUpU6b8728EAAAAAOIhemOgJAUGBsrV1dVO1eC/evjwYby2s+uYbkmxulMYhvHMLhYWi0Umk0nff/+90qRJI0maMGGCGjVqpGnTpsXZ2u3v769evXpZl4ODg+Xl5SVfX1+6lwMAAAB4bUJCQhQQEGBdrlmzJi3diVhUL+oXsVvozpgxoxwdHWO1at+4cSNW63eUrFmzKnv27NbALT0ZA24Yhi5fvqwCBQrE2sfV1TXOu0fOzs5ydnb+j+8CAAAAAOLn6fxBJknc4vu7s9sjw1xcXFS6dGkFBgbGWB8YGKgKFSrEuU/FihV19epVhYSEWNf99ddfcnBwUI4cOWxaLwAAAAAA/5Zdn9Pdq1cvzZkzR/PmzdPJkyfl5+enixcvqlOnTpKedA1v2bKldftmzZopQ4YM+vTTT3XixAnt2LFDn3/+udq0afPMidQAAAAAALAXu47pbty4sW7fvq1hw4bp2rVr8vb21oYNG5QrVy5J0rVr13Tx4kXr9u7u7goMDFS3bt1UpkwZZciQQR9//LG++uore70FAAAAAACeya7P6bYHntMNAAAAwB5CQkJUr1496/KaNWuYSC0Ri2+2tGv3cgAAAAAAkjJCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBG7h+7p06crT548cnNzU+nSpbVz585nbrtt2zaZTKZYf06dOvUaKwYAAAAAIH7sGrqXLl2qnj17auDAgTp06JAqV66s2rVr6+LFi8/d7/Tp07p27Zr1T4ECBV5TxQAAAAAAxJ9dQ/eECRPUtm1btWvXTkWKFNGkSZPk5eWlGTNmPHe/zJkzK0uWLNY/jo6Or6liAAAAAADiz8lePzg8PFwHDhxQ//79Y6z39fXV7t27n7tvyZIl9fjxYxUtWlRffPGFqlat+sxtw8LCFBYWZl0ODg6WJEVERCgiIuI/vAMAAAAAiL+n8weZJHGL7+/ObqH71q1bMpvN8vT0jLHe09NTQUFBce6TNWtWzZo1S6VLl1ZYWJgWLlyo6tWra9u2bXr77bfj3GfUqFEaOnRorPVbtmxRypQp//sbAQBIkgzDUHh4uHXZxcVFJpPJjhUBAJCwRG8MlKTAwEC5urraqRr8Vw8fPozXdnYL3VGeviAzDOOZF2mFChVSoUKFrMs+Pj66dOmSvv7662eGbn9/f/Xq1cu6HBwcLC8vL/n6+srDw+MVvAMAgCSFhISoUaNG1uXly5fL3d3djhUBAJCwhISEKCAgwLpcs2ZNvisTsahe1C9it9CdMWNGOTo6xmrVvnHjRqzW7+cpX768Fi1a9MzXXV1d47x75OzsLGdn5/gXDAB4rqc/U/mcBQAgJr4rk5b4/u7sNpGai4uLSpcurcDAwBjrAwMDVaFChXgf59ChQ8qaNeurLg8AAAAAgP/Mrt3Le/XqpU8++URlypSRj4+PZs2apYsXL6pTp06SnnQNv3LlihYsWCBJmjRpknLnzq1ixYopPDxcixYt0ooVK7RixQp7vg0AAAAAAOJk19DduHFj3b59W8OGDdO1a9fk7e2tDRs2KFeuXJKka9euxXhmd3h4uPr06aMrV64oRYoUKlasmH766Se999579noLAAAAAAA8k8kwDMPeRbxOwcHBSpMmje7fv89EagDwCoWEhKhevXrW5TVr1jA5DAAA0fBdmbTEN1vabUw3AAAAAABJHaEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYiN1D9/Tp05UnTx65ubmpdOnS2rlzZ7z2++233+Tk5KQSJUrYtkAAAAAAAF6SXUP30qVL1bNnTw0cOFCHDh1S5cqVVbt2bV28ePG5+92/f18tW7ZU9erVX1OlAAAAAAD8e3YN3RMmTFDbtm3Vrl07FSlSRJMmTZKXl5dmzJjx3P06duyoZs2aycfH5zVVCgAAAADAv+dkrx8cHh6uAwcOqH///jHW+/r6avfu3c/cb/78+frnn3+0aNEiffXVVy/8OWFhYQoLC7MuBwcHS5IiIiIUERHxktUDAJ729Gcqn7MAAMTEd2XSEt/fnd1C961bt2Q2m+Xp6Rljvaenp4KCguLc58yZM+rfv7927twpJ6f4lT5q1CgNHTo01votW7YoZcqU/75wAECcot/glKTAwEC5urraqRoAABIeviuTlocPH8ZrO7uF7igmkynGsmEYsdZJktlsVrNmzTR06FAVLFgw3sf39/dXr169rMvBwcHy8vKSr6+vPDw8Xr5wAEAMISEhCggIsC7XrFlT7u7udqwIAICEhe/KpCWqF/WL2C10Z8yYUY6OjrFatW/cuBGr9VuSHjx4oP379+vQoUPq2rWrJMliscgwDDk5OWnLli2qVq1arP1cXV3jvHvk7OwsZ2fnV/RuAABPf6byOQsAQEx8VyYt8f3d2W0iNRcXF5UuXVqBgYEx1gcGBqpChQqxtvfw8NDRo0d1+PBh659OnTqpUKFCOnz4sMqVK/e6SgcAAAAAIF7s2r28V69e+uSTT1SmTBn5+Pho1qxZunjxojp16iTpSdfwK1euaMGCBXJwcJC3t3eM/TNnziw3N7dY6wEAAAAASAjsGrobN26s27dva9iwYbp27Zq8vb21YcMG5cqVS5J07dq1Fz6zGwAAAACAhMpkGIZh7yJep+DgYKVJk0b3799nIjUAeIVCQkJUr1496/KaNWuYHAYAgGj4rkxa4pst7TamGwAAAACApI7QDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABtxiu+Ga9eujfdBP/jgg5cqBgAAAACApCTeobt+/frx2s5kMslsNr9sPQAAAAAAJBnxDt0Wi8WWdQAAAAAAkOQwphsAAAAAABuJd0v3N998E++Ddu/e/aWKAQBbKP35AnuXkCyYIsOVJtryO4OWyHBysVs9ycWBcS3tXQIAAHiOeIfuiRMnxms7k8lE6AYAAAAAQP8idJ87d86WdQAAAAAAkOQwphsAAAAAABuJd0v30y5fvqy1a9fq4sWLCg8Pj/HahAkT/nNhAAAAAAAkdi8Vurdu3aoPPvhAefLk0enTp+Xt7a3z58/LMAyVKlXqVdcIAAAAAECi9FLdy/39/dW7d28dO3ZMbm5uWrFihS5duqQqVaroo48+etU1AgAAAACQKL1U6D558qRatWolSXJyctKjR4/k7u6uYcOGacyYMa+0QAAAAAAAEquXCt2pUqVSWFiYJClbtmz6559/rK/dunXr1VQGAAAAAEAi91JjusuXL6/ffvtNRYsW1fvvv6/evXvr6NGjWrlypcqXL/+qawQAAAAAIFF6qdA9YcIEhYSESJKGDBmikJAQLV26VPnz59fEiRNfaYEAAAAAACRWLxW68+bNa/3/lClTavr06a+sIAAAAAAAkoqXGtO9b98+/fHHH7HW//HHH9q/f/9/LgoAAAAAgKTgpUJ3ly5ddOnSpVjrr1y5oi5duvznogAAAPDfGYahkJAQ6x/DMOxdEgAkOy8Vuk+cOKFSpUrFWl+yZEmdOHHiXx1r+vTpypMnj9zc3FS6dGnt3Lnzmdvu2rVLFStWVIYMGZQiRQoVLlyYMeQAAADPEBoaqnr16ln/hIaG2rskAEh2XmpMt6urq65fvx5jbLckXbt2TU5O8T/k0qVL1bNnT02fPl0VK1ZUQECAateurRMnTihnzpyxtk+VKpW6du2q4sWLK1WqVNq1a5c6duyoVKlSqUOHDi/zVgAAAAAAsJmXaumuWbOm/P39df/+feu6e/fuacCAAapZs2a8jzNhwgS1bdtW7dq1U5EiRTRp0iR5eXlpxowZcW5fsmRJNW3aVMWKFVPu3LnVokUL1apV67mt4wAAAAAA2MtLtXSPHz9eb7/9tnLlyqWSJUtKkg4fPixPT08tXLgwXscIDw/XgQMH1L9//xjrfX19tXv37ngd49ChQ9q9e7e++uqrZ24TFhamsLAw63JwcLAkKSIiQhEREfH6OQASNxdHe1eQTDw1VNTZURJ/9zbHdxme5+l/H1z/APbFOZm0xPd391KhO3v27Przzz/1/fff68iRI0qRIoU+/fRTNW3aVM7OzvE6xq1bt2Q2m+Xp6Rljvaenp4KCgp67b44cOXTz5k1FRkZqyJAhateu3TO3HTVqlIYOHRpr/ZYtW5QyZcp41Qogcevvk8beJSQLYWFhCjj0v2W/tzzk6upqv4KSiQ0bNti7BCRg0RseJCkwMJDzErAjzsmk5eHDh/Ha7qVCt6RXNo7aZDLFWDYMI9a6p+3cuVMhISH6/fff1b9/f+XPn19NmzaNc1t/f3/16tXLuhwcHCwvLy/5+vrKw8PjP9cPIOF7e9AP9i4heYgMV/RbmRP3BktOLnYrJ7nYMTzu7z9AkkJCQhQQEGBdrlmzptzd3e1YEZC8cU4mLVG9qF/kpUP3woULFRAQoLNnz2rPnj3KlSuXJk6cqLx586pevXov3D9jxoxydHSM1ap948aNWK3fT8uTJ48k6Y033tD169c1ZMiQZ4ZuV1fXOO8eOTs7x7tVHkDiFm62dwXJg+mpv+cIs2Q8/x4qXgG+y/A8T//74PoHsC/OyaQlvr+7l5pIbcaMGerVq5dq166tu3fvymx+cqWVLl06TZo0KV7HcHFxUenSpRUYGBhjfWBgoCpUqBDvWgzDiNVNAwAAAACAhOClQveUKVM0e/ZsDRw4MMYjwsqUKaOjR4/G+zi9evXSnDlzNG/ePJ08eVJ+fn66ePGiOnXqJOlJ1/CWLVtat582bZrWrVunM2fO6MyZM5o/f76+/vprtWjR4mXeBgAAAAAANvVS3cvPnTtnnbU8OldXV4WGhsb7OI0bN9bt27c1bNgwXbt2Td7e3tqwYYNy5col6clzvy9evGjd3mKxyN/fX+fOnZOTk5Py5cun0aNHq2PHji/zNgAAAAAAsKmXCt158uTR4cOHreE4ysaNG1WkSJF/dazOnTurc+fOcb727bffxlju1q2bunXr9q+ODwAAAACAvbxU6P7888/VpUsXPX78WIZhaO/evfrhhx80cuRIzZ0791XXCAAAAABAovRSofvTTz9VZGSk+vbtq4cPH6pZs2bKnj27pkyZosqVK7/qGgEAAAAASJReaiI1SWrfvr0uXLigGzduKCgoSHv37tWhQ4eUP3/+V1kfAAAAAACJ1r8K3ffu3VPz5s2VKVMmZcuWTd98843Sp0+vadOmKX/+/Pr99981b948W9UKAAAAAECi8q+6lw8YMEA7duxQq1attGnTJvn5+WnTpk16/PixNmzYoCpVqtiqTgAAkISU/nyBvUtIFkyR4UoTbfmdQUtkOLnYrZ7k4MC4li/eCECy8q9C908//aT58+erRo0a6ty5s/Lnz6+CBQtq0qRJNioPAAAAAIDE6191L7969aqKFi0qScqbN6/c3NzUrl07mxQGAAAAAEBi969Ct8VikbOzs3XZ0dFRqVKleuVFAQAAAACQFPyr7uWGYah169ZydXWVJD1+/FidOnWKFbxXrlz56ioEAAAAACCR+lehu1WrVjGWW7Ro8UqLAQAAAAAgKflXoXv+/Pm2qgMAAAAAgCTnX43pBgAAAAAA8UfoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANuJk7wIAAABgG4ajs+4XbxpjGQDwehG6AQAAkiqTSYaTi72rAIBkje7lAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjdg/d06dPV548eeTm5qbSpUtr586dz9x25cqVqlmzpjJlyiQPDw/5+Pho8+bNr7FaAAAAAADiz66he+nSperZs6cGDhyoQ4cOqXLlyqpdu7YuXrwY5/Y7duxQzZo1tWHDBh04cEBVq1ZV3bp1dejQoddcOQAAAAAAL2bX0D1hwgS1bdtW7dq1U5EiRTRp0iR5eXlpxowZcW4/adIk9e3bV2XLllWBAgU0cuRIFShQQOvWrXvNlQMAAAAA8GJ2e2RYeHi4Dhw4oP79+8dY7+vrq927d8frGBaLRQ8ePFD69OmfuU1YWJjCwsKsy8HBwZKkiIgIRUREvETlABIbF0d7V5BMGDEXnR0l8Xdvc4n1u4zzEklVYj0n8Xo8/e+DTJK4xfd3Z7fQfevWLZnNZnl6esZY7+npqaCgoHgdY/z48QoNDdXHH3/8zG1GjRqloUOHxlq/ZcsWpUyZ8t8VDSBR6u+Txt4lJAthYWEKiDbax+8tD7m6utqvoGRiw4YN9i7hpXBeIqlKrOckXo/ojYGSFBgYyHdlIvbw4cN4bWe30B3FZDLFWDYMI9a6uPzwww8aMmSI1qxZo8yZMz9zO39/f/Xq1cu6HBwcLC8vL/n6+srDw+PlCweQaLw96Ad7l5A8RIYr+q3MiXuDJScXu5WTXOwY3tTeJbwUzkskVZyTeC6+K+3CVudlVC/qF7Fb6M6YMaMcHR1jtWrfuHEjVuv305YuXaq2bdtq2bJlqlGjxnO3dXV1jfPukbOzs5ydnf994QASnXCzvStILpwVUfx/X2qGnCX+7m0usX6XcV4iqeKcxPOYnvp7jjBLxovbG/Ef2eq8jO9x7TaRmouLi0qXLq3AwMAY6wMDA1WhQoVn7vfDDz+odevWWrx4sd5//31blwkAiC+TSYaTi/WP4tFrCQAAIKmza/fyXr166ZNPPlGZMmXk4+OjWbNm6eLFi+rUqZOkJ13Dr1y5ogULFkh6ErhbtmypyZMnq3z58tZW8hQpUihNGsaGAQAAAAASFruG7saNG+v27dsaNmyYrl27Jm9vb23YsEG5cuWSJF27di3GM7sDAgIUGRmpLl26qEuXLtb1rVq10rfffvu6ywcAAAAA4LnsPpFa586d1blz5zhfezpIb9u2zfYFAQAAAADwitg9dAMvwzAMhYaGWpdTpUoVr1nvAQAAAOB1InQjUQoNDVW9evWsy2vWrJG7u7sdKwIAAACA2Ow2ezkAAAAAAEkdoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCNO9i4gqSn9+QJ7l5AsmCLDlSba8juDlshwcrFbPcnFgXEt7V0CAAAAkKjQ0g0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBEnexcAvAzD0Vn3izeNsQwAAAAACY3dW7qnT5+uPHnyyM3NTaVLl9bOnTufue21a9fUrFkzFSpUSA4ODurZs+frKxQJi8kkw8nF+kcmk70rAgAAAIBY7Bq6ly5dqp49e2rgwIE6dOiQKleurNq1a+vixYtxbh8WFqZMmTJp4MCBevPNN19ztQAAAAAA/Dt2Dd0TJkxQ27Zt1a5dOxUpUkSTJk2Sl5eXZsyYEef2uXPn1uTJk9WyZUulSZPmNVcLAAAAAMC/Y7cx3eHh4Tpw4ID69+8fY72vr6927979yn5OWFiYwsLCrMvBwcGSpIiICEVERLyynxPFxfGVHxJIMGxxzrwOnJdIyjgvgYSFcxLPZcRcdHaUxN+9zdnqvIzvce0Wum/duiWz2SxPT88Y6z09PRUUFPTKfs6oUaM0dOjQWOu3bNmilClTvrKfE6W/Dy3wSLo2bNhg7xJeCuclkjLOSyBh4ZzE84SFhSng0P+W/d7ykKurq/0KSiZsdV4+fPgwXtvZffZy01MTYBmGEWvdf+Hv769evXpZl4ODg+Xl5SVfX195eHi8sp8T5e1BP7zyYwIJxY7hTV+8UQLEeYmkjPMSSFg4J/FckeGK3uw3cW+w5ORit3KSC1udl1G9qF/EbqE7Y8aMcnR0jNWqfePGjVit3/+Fq6trnHePnJ2d5ez86h8zFW5+5YcEEgxbnDOvA+clkjLOSyBh4ZzE85ie+nuOMEsGD+GxOVudl/E9rt0mUnNxcVHp0qUVGBgYY31gYKAqVKhgp6oAAAAAAHh17Nq9vFevXvrkk09UpkwZ+fj4aNasWbp48aI6deok6UnX8CtXrmjBggXWfQ4fPixJCgkJ0c2bN3X48GG5uLioaNGi9ngLAAAAAAA8k11Dd+PGjXX79m0NGzZM165dk7e3tzZs2KBcuXJJkq5duxbrmd0lS5a0/v+BAwe0ePFi5cqVS+fPn3+dpQMAAAAA8EJ2n0itc+fO6ty5c5yvffvtt7HWGYYRe0MAAAAAABIgu43pBgAAAAAgqSN0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAG7F76J4+fbry5MkjNzc3lS5dWjt37nzu9tu3b1fp0qXl5uamvHnzaubMma+pUgAAAAAA/h27hu6lS5eqZ8+eGjhwoA4dOqTKlSurdu3aunjxYpzbnzt3Tu+9954qV66sQ4cOacCAAerevbtWrFjxmisHAAAAAODF7Bq6J0yYoLZt26pdu3YqUqSIJk2aJC8vL82YMSPO7WfOnKmcOXNq0qRJKlKkiNq1a6c2bdro66+/fs2VAwAAAADwYk72+sHh4eE6cOCA+vfvH2O9r6+vdu/eHec+e/bska+vb4x1tWrV0ty5cxURESFnZ+dY+4SFhSksLMy6fP/+fUnSnTt3FBER8V/fRiwOkY9e+TGBhOL27dv2LuGlcF4iKeO8BBIWzkk8V2S4IiMjrYumyEcyyWzHgpIHW52XDx48kCQZhvHc7ewWum/duiWz2SxPT88Y6z09PRUUFBTnPkFBQXFuHxkZqVu3bilr1qyx9hk1apSGDh0aa32ePHn+Q/VA8pRxUid7lwDgKZyXQMLCOYl/ZccOe1eQLNj6vHzw4IHSpEnzzNftFrqjmEymGMuGYcRa96Lt41ofxd/fX7169bIuWywW3blzRxkyZHjuz0HCFxwcLC8vL126dEkeHh72LgeAOC+BhIjzEkhYOCeTDsMw9ODBA2XLlu2529ktdGfMmFGOjo6xWrVv3LgRqzU7SpYsWeLc3snJSRkyZIhzH1dXV7m6usZYlzZt2pcvHAmOh4cHH1hAAsN5CSQ8nJdAwsI5mTQ8r4U7it0mUnNxcVHp0qUVGBgYY31gYKAqVKgQ5z4+Pj6xtt+yZYvKlCkT53huAAAAAADsya6zl/fq1Utz5szRvHnzdPLkSfn5+enixYvq1OlJn3t/f3+1bNnSun2nTp104cIF9erVSydPntS8efM0d+5c9enTx15vAQAAAACAZ7LrmO7GjRvr9u3bGjZsmK5duyZvb29t2LBBuXLlkiRdu3YtxjO78+TJow0bNsjPz0/Tpk1TtmzZ9M033+jDDz+011uAHbm6umrw4MGxhg8AsB/OSyDh4bwEEhbOyeTHZLxofnMAAAAAAPBS7Nq9HAAAAACApIzQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAACRaFotFkpRQ5wi36yPDgKTGYrHIwYF7WQAAAMDr8PXXX+vatWtq3769smXLJg8PD3uXFAvpAPiPwsLCtHXrVkmyBu6ou20AACDhtj4BSNwiIiJkMpl0//591alTR126dNGyZcvsXVYsPKcbeEmGYchkMmncuHFatmyZzGazmjZtqrp166pQoUL2Lg9IUKLOFwDJR1hYmObPn6/ixYvLx8fH+hnA5wGAV8FsNsvR0dG6vGHDBgUGBmrWrFn6/PPPNWTIEPsV9xRCN/CSoi4aHjx4oNSpU2vEiBE6ePCgtm/frilTpujjjz+O8UEAJFdR58r27dsVGBioc+fOqW7duqpevboyZcpk7/IA2Mjq1au1fv16rVixQvXr11fx4sXl5+dn77IAJDHh4eFycXGRJAUHB2vlypXq1KmTOnXqpEmTJtm3uP9H93LgJYSHh+uzzz7TzZs3lTJlSknSwIEDNWXKFHXt2lXNmzfXiBEjFBwcbOdKAfszmUxatWqVGjRooHPnzsnT01MtWrRQ//79FRQUZO/yALxiERERkqT69etrzpw52rRpk/LkyaOvv/5aderU0aVLl+xcIYDErE2bNvroo4/0xRdf6O7du9bALUkeHh5q3bq1li5dqmnTpmnChAl2rPR/CN3AS7h06ZJOnjwpk8kkR0dH6wVGtmzZNGTIEM2ePVtDhgzR3LlzJTHGG8nbuXPn5O/vr9GjR+v777/XhAkT5OrqqsyZMytLliz2Lg/AK2Q2m9WuXTtt2bJF0pOeLuXKlVP//v21ceNGnTx5Ug0aNNDRo0ftXCmAxKp///6qWrWqDh48qGLFimnUqFExPlMMw1C9evX09ddf65tvvtG2bdvsV+z/I3QDLyFfvnyKjIzUoEGDJEnOzs4xJolp27atJk+erD59+mj37t3MaI5kLTIyUmnTplWHDh105swZ5ciRQ82bN9eoUaMkScePH7dzhQBeldDQUN25c8fa0yvqprOLi4uKFy+uw4cP6+HDh/rss88S/CN+ACQ8hmGoYMGC6ty5szZs2KCePXtq8+bN6t27t3799VdJss4ZUbduXZUvX1579+6VZN9GMJIA8C+ZzWZJkr+/v06dOqXffvtNkmJMECNJXbt21aeffqphw4bpzp079ikWSABu3rypixcv6rffftO7776r9957TzNmzJAk7du3T19++aX++usvO1cJ4FXw8PBQtWrV9OWXX+ratWsx5jYxm81KnTq1fvnlF/3999/q2rWrJDGpGoB4e/p6u2/fvurfv7/Spk2rPn36aOfOndZt8+bNq3feeUfffPON7t27Z9dGMEI38C9EnyWxXLlyCgsL04IFC3T//n3rNlEfBiaTSR999JGCg4N169Ytu9QLvG5RX4LRW67KlSunt956S++8847KlCmjWbNmWc+jVatWKSgoSGnSpLFLvQBenahWpA8++EBeXl5as2aNdfiVJDk6OspisShLliyaMmWKDhw4oN9//91e5QJIREJCQiT973PGZDJZrzXeffdd9ezZU7lz59a0adNizBvRqVMnlS9fXn/++efrLzoaQjcQT4ZhWIPCoEGDFBYWptGjR2vevHkaP368wsPDrdtGfSDUqlVLHh4e+uabb+xSM/A6Rc1SvmPHDg0fPlxjx47VxYsX5ejoqNatW6tEiRK6efOm9u7dq61bt6pPnz6aNm2aZsyYIU9PT3uXD+A/MJvN1lakfPnyqWTJkpo0aVKssdtR25QvX15ubm46dOjQa68VQOIyf/585c+fX8eOHZODg0OcwbtChQpq0qSJjh8/bu1OHhkZKYvFovfee0/p06e3W/0SjwwD4iV6C3efPn0UGBioFStWKH/+/Fq0aJFatWolPz8/ffbZZ8qXL58k6fHjx3Jzc9OWLVt09uxZdejQgbHdSPI2bNigDz74QDVq1NC2bdtUpkwZ9evXT3Xr1tXq1as1e/ZsBQYGqlChQkqTJo2mTZumN998095lA/gPoj93+9NPP1X16tXVokULVaxYUcHBwVqxYoUKFiwYa9vZs2dr7ty52rx5M71dAMQpMDBQLVu2tIbtwMBAeXt7y2KxWK+ro3+u9OjRQ5s2bdLJkyetr0ff1l5IAEA8RAXuXbt26fbt25oyZYry588vSWrRooVWrlyphQsXasCAAQoICJAkubm5SZJKly6tRo0a2f1kB2wl6t7t9evXtWzZMs2cOVObNm3SlStXlDJlSo0ePVpr1qxR/fr19dNPP+nAgQPatm2b1q9fT+AGEjmz2Wy92J00aZIOHz4sHx8fSU9uwrm4uKhOnTr66aefdO/ePZlMJmuX82rVqqlly5bWR28CQHT37t3Txo0bVb9+fW3YsEHlypXTO++8E2eLd9T/Dxs2TDly5NDu3bslPblGSQjX4PavAEgk5s+fr2rVqmnt2rUxJnGwWCyqV6+eNm3aJC8vL02ePFlVqlTRxIkTdfPmTWXIkEEZM2a0c/WA7ZhMJv32229q06aN/v77b5UqVUqSlCFDBi1atEipU6fW2LFj9eOPP8piseiNN95QhgwZlDZtWvsWDuA/i7opvXTpUp04cUI9e/a0PuEjTZo02r9/v4oWLarhw4erV69eOnr0qPU7NF++fGrevLmcnZ3t+RYAJFBp06ZV1apV1bx5c7355puaMWOGKlasGCN4R934jwrWKVKkkLu7u06dOiUp4UzUSOgGnuHpkReffvqpunfvrpCQEK1fv1537tyxnsgWi0UlS5bUmDFjtHfvXjVo0EDp06e3znQOJHVZsmTR2bNntXv37hhjODNnzqxFixYpXbp0Gj58uFavXm2/IgHYxIkTJ9S6dWvNmTNHV65ckSQ5OTkpIiJCJpNJq1evVteuXeXi4qLq1aurR48eCgwMlCS6lQOIU9R1eN26dVWpUiVJUtasWTVjxgxVqlRJVapU0bFjx2QymXTjxg1t2LBB9+/fl4uLiyZPnmwd0pJQMKYbiEP0Mdxms1mhoaHy8PCQJHXp0kUbNmxQ37591axZM6VJk8Y6liT6mBIguTl//rwaNGigtGnTavDgwXrnnXesr924cUNdunTRuHHjlDt3brvVCOC/i2t85K5du9SyZUvlzJlTY8eO1VtvvSVJioiIiNGSvXfvXoWHh6tAgQJMoAgg3qJfY1+9elWdO3fWb7/9puXLl6t///5KnTq1Nm/enGCvwwndwFOiB+4BAwbozz//1OPHj1W2bFmNGjVK0pPHD/z888/q06ePmjZtyp16JCtRX3ynT5/WpUuXlDZtWmXJkkU5cuTQX3/9pUaNGilr1qzy9/ePEbwTwkQmAP6b6N+RFy9elCSlS5fO+vztNm3aqHLlyurdu7dKlCghiXMfwKsXFBSkdu3aacOGDXrjjTe0f/9+OTs7J9gGMCd7FwAkNFEXEw0bNtTff/+ttm3bKmPGjPrkk08UFhamCRMmaObMmfrss880fvx4hYSEqEuXLkqRIoWdKwdsL+rLbMWKFerRo4f1C87NzU2zZs3S22+/reXLl6tRo0YaN26cwsPD5evrK0lcdAOJnMVisX5HduzYUQcOHNCjR4/k4OBgnfdk3rx5atu2rRwcHOTn56cSJUpw7gN45Uwmk65cuaJy5cpp586dcnJyUmRkpJycEma85VMQ+H9Rsx5K0qZNm/TPP/9o7dq16tGjh+7cuaM0adLo3XfftW4zY8YMlSpVSkFBQQRuJAuRkZEymUzau3evPv30Uw0aNEi7du3Sd999p7Jly6pWrVrauXOnChYsqJUrV+ro0aMKCAjQw4cP7V06gFcgKjw3bdpUO3fu1KRJk7R27Vrdvn1bnTp10p07d1StWjXNnTtXO3bs0BdffGFtDQeAVyU8PFwTJ07Uo0ePtGPHjgQfuCVaupHMPXr0SJ9++qlmzZolDw8Paxe4ixcvKl26dMqdO7fGjBmjMWPGaOnSpfL19dX58+d18OBBNWzYUEuXLrUeK6F2ZwH+qwsXLihnzpxycnKS2WzW0aNHVaZMGbVv314ODg7Knj27ChUqJIvFoh49emjDhg3Knz+/duzYIYvFwuOAgEQqelfyKP/8848uXryoH3/8Ud7e3ho/frwiIyP11VdfKX369IqMjFS1atU0ZcoU/fLLL8qZM6edqgeQVLm4uKhevXoaMWKEHB0dE3zglmjpRjJ39epVbd++XdWqVVNISIj1Ln7OnDnl5uamPn36aMyYMVqyZIm1i+zhw4e1ePFiXbhwwXocAjeSqrCwMDVp0kR58+aVYRhydHRUcHCwDh8+rODgYElP/v1nyZJFzZo1061bt3T37l1JUu7cuZU3b157lg/gJUVERKhs2bKaNWtWjPXXrl3T6dOn5e3trcmTJ2vEiBFatGiR3n33XQUFBemrr77SgwcPVKdOHU2YMEFS7KeBAMB/5ePjI0dHR1kslgQfuCVCN5K5fPny6eeff1ZERIQqV66skJAQSZKnp6euX7+uadOmacyYMdbAfe3aNQ0bNkx58uRRrly5rMchcCOpcnFx0bhx4+Tu7q5SpUrJMAzVq1dPWbNm1fz583X//n3rv/8CBQrI2dlZDx48sHPVAP6ryMhIVa5cWV27dtWiRYus6wsWLKiyZcuqSZMmGjx4sFasWGH9jrxw4YJ27dqlEydOxDgW35EAnuW/3pRLLHNGJI4qARsqVqyYvv/+e5nNZlWqVEkhISEqWbKk+vXrp4wZM2rTpk0aNWqUpk6dqho1aih79uwaN26cJO7eI+kzmUyqUKGCZs+erUePHqlcuXLKmzevGjRooPnz52v27Nm6fv26QkJCNG/ePDk4OPBIMCAJSJEihUaOHKl+/fqpZcuW1uDt7u6uDBkyaMWKFeratauqVq0qSbpy5Yo6dOigPHnyqFy5cvYsHUAC98svv2j58uXWuWKedT0dfX1iv+bmkWFIluLqDn706FE1b95ckrR79265u7tr+fLl2rRpkzZs2KBy5copX758+vrrryXxCBQkXUFBQTp//rzKly9vXRcREaFDhw6pSZMm8vLy0vbt2zVo0CCtXr1af//9t0qUKKF//vlHmzdvVsmSJe1YPYBXKTQ0VKNGjdLIkSM1f/58tWrVSnfu3NFHH32kO3fuKFOmTMqTJ4927Nih/Pnza926dZIYdgUgbsuWLVPjxo315ptvasiQIXr//ffl5OQU6zMjrs+QxPy5QuhGsvP0xDARERFydnaWxWLRiRMn1LRpU5lMJmvwNpvNCgkJUerUqa0hm8CNpOrSpUsqWbKk7ty5oypVqsjHx0c1atRQ2bJllTp1au3bt09t27aVh4eHdu3apaCgIG3YsEHp0qVTqVKlYgy7AJD4RH2/Rb+4vX//vsaNG6eRI0dq7ty5+vTTT3X37l398MMP2rlzpzJnzqw8efKoZ8+eMY4BANGdPHlSrVq1UvXq1bVv3z4FBwdrwIABqlOnTpzBW5K6deumdOnSadiwYXaq+tUgdCNZiR64hw0bpn/++UcPHjyQn5+fKleuLEk6duyYmjZtKicnJ+3cuVPu7u4xjpGY77IBL3LhwgXVr19fjx49UurUqVWsWDEtXbpUhQsXlre3t+rWrSuTySR/f3/lzZtXmzdv5nwAkojo35H3799XeHi4MmXKJEl68OCBxowZo5EjR2revHlq3bp1nMcgcAN4ltOnT2v27Nnq0KGDcufOrffee++5wTskJETDhg3T1q1btX79emXNmtXO7+Dl8amIZCNq5mVJ+vDDD7Vs2TJ5eHgoc+bMqlq1qhYvXixJ8vb21pIlS2Q2m1WoUCGFhYXFOA4BA0lZrly5tGzZMhUtWlTZs2fXZ599ptOnT6tfv346d+6cxo8fr1atWilFihT6+eef1bBhQ0mJf6wVkNxFD9zdu3fXu+++q2rVqqldu3aSpNSpU8vf31/+/v5q3769Fi5cGOdxCNwAniVv3rzq06ePChYsKBcXF61evVqpU6fWyJEjtW7dOpnNZplMJuuErO7u7mrdurX1ySmJGS3dSHaGDx+uZcuW6eeff1bmzJk1ZcoU9ejRQ05OTpo6dao6dOggSTp06JCWLVumkSNH2rli4PU7ffq0evToIYvFohEjRqhs2bKSpHv37mndunU6ffq0Nm7cqDlz5jCGG0hCPvroI50+fVq9evVS5syZVbduXTVp0kQTJ05U5syZY4zx3rVrlypUqGDvkgEkQlHDO0NDQ/XBBx/owYMH+uKLL1S6dGl17txZ1apVU48ePSRJv/76q3XSxsSK0I0kL3o3lXv37mn69OkqVqyY6tWrp0mTJmnYsGFaunSptm7dqm+++UYBAQH65JNPYhyD7nJIjs6cOaNu3bpJkvz9/VWlSpUYr0dGRiaKZ2MCiJ958+ZpxowZWrFihXLmzKkpU6boiy++kIODg8qWLatFixYpc+bMCgkJ0aZNm9SoUSN7lwwggYrPtXNU8H748KHq1aunu3fv6s6dO3J1ddXRo0djXWMk5iGehG4kaU9PmiZJp06dUqZMmXT27Fm1aNFCY8aMUf369bV+/Xp98MEHkqSff/5Z1apVs0fJQIJy5swZde/eXYZh6Msvv6RVC0hCol8UWywWrVixQg8fPlSrVq00ffp0DRkyRD/88IPc3d1VuXJlNWrUSBMmTFCWLFniPAYASNLdu3eVLl26WOujQnNwcLA8PDwk/e9a/dy5c8qXL5/Kly+v7du3y9nZOc7r+MSKT0kkWdFP1F69eql///6SpMKFCytDhgw6d+6c0qZNa51ALVWqVBo0aJB++uknAjfw/woUKKBvvvlGzs7O6t27t37//Xd7lwTgFTCbzdawfOnSJTk4OOiDDz5QnTp1dPXqVc2ZM0djx45V9erVlT59enl5eWnJkiWaP39+jOMQuAFEN336dLVs2VIWiyXWc7ZNJpPWrl2rgQMH6u7du5IkR0dH3bp1S40aNVLRokW1Y8cOOTs7KzIyMskEbonQjSQs6kStX7++fvnlF+XNm1e3bt2yvm4Yhvbt26c9e/Zo9+7d8vPz04MHD1S7dm1JT+7eA3gSvMeNG6ccOXIoW7Zs9i4HwH8U/aZ0u3bt1KZNG506dUqurq7KkCGDgoKCdOvWLb311luSngTratWq6ezZs/L397dn6QASuBw5csgwDDk4OMhkMlmDt8lk0vLly9W4cWOVKFEiRku4o6OjSpYsqYMHD8rJySlJDl+jezmStOnTp2vSpEnaunWrvLy8JMUcD9KhQwfNmTNHuXLl0ptvvqnVq1fbsVogYQsPD5eLi4u9ywDwijRq1Eh//fWXxo8fr+LFi8vT01OSdOvWLRUsWFC+vr6qVauWxo0bp5IlS+r777+XRJdyAM/26NEjFSlSRB06dNCAAQMkPbn2vnz5sooWLarRo0erS5cuz9w/KQZuidCNJCCuSRWiLgh69uypa9euaenSpdZ1T2+/d+9eOTs7W2dg5mICAJDUbd68WT179tSKFStUtGhRSU++Ty0WixwdHfXzzz+rffv2ypQpkwoVKmR9RFhinsgIgG1F9aKZOnWqNm3apMGDB1uffiJJf//9t/Lnz2/HCu2HZIFELfqX//r167Vp0yZJijExzNWrVxUWFhYjcAcHB2vRokWSpLfeeovADQBIcqK3q0QNmYr67/nz5xUWFqZ8+fJZtzWZTHJ0dFR4eLhq1Kiho0ePau3atdbAbbFYCNwAnilq2EqlSpV09epVLViwQFevXrW+nlwDt0ToRiIWPXAPHjxYAwYM0A8//KDLly9btylevLjOnj2r9evX6+HDhzEeHTZu3DitWbMmxjEJ3ACApCD6d+SiRYs0bNgwhYaGWr/nPD095eTkpJMnT0p6Mt7SbDYrMjJS06ZN0759++Tu7m6dqTxqjCYAxCX6Tb4SJUpo0KBBmjt3riZNmqQLFy5YX0uucyYlvQ7zSDaiLiYGDhyouXPn6vvvv1fx4sWVKVMm6zbt2rXT+vXr5efnpwsXLqhMmTKKjIxU9+7dVaRIEdWrV89e5QMAYBPRA/eAAQO0YsUK1a5dW//884+KFy8uSSpYsKBCQkIUEBCgfv36KXfu3HJ0dNTNmzf17bffymKxxOgWSgs3gGeJ6lZ++fJlRUZGKleuXGrQoIHmzZunzz77TLdv31bDhg31/vvvx+iNmpxu5DGmG4naL7/8oo4dO2r+/PmqVKlSjNf++ecfa7c5Pz8/7dq1SwcOHFDJkiVVuHBhJoQBACRpQ4YMUUBAgJYtW6YyZcrIzc0txuurV69W69atVb16dRUvXlxZs2bVhAkTVKhQoVg9wQAgLlGB++jRoypbtqzmzZunZs2aWV/ftGmTZs6cqatXr6pUqVLq3r27cubMKXd3dztW/foRupGozZ07VzNnztSePXvk5OQkwzA0d+5crVmzRlu3blXJkiU1dOhQ1ahRQ7du3dLly5fl4eGhvHnzSiJwAwCSptOnT6tZs2b66quvrI/ClKT79+9r//79ypkzpwoUKKDff/9d06ZN065du5Q/f34VLlxYU6ZMkcR3JIDnix64a9asqSZNmmjSpEkyDENXrlxR9uzZZTKZdOnSJZ07d07+/v7y9PRUgQIFNGTIEKVIkcLeb+G1oXs5EpWHDx8qKCjIGpo9PDx08+ZNbd68WRUrVlTz5s0VHBysbNmyadGiRRoxYoQGDBggHx8fZcyYURkzZrQei/FpAICk6vbt2zp79qzy5Mkj6cl33pgxY7Rp0ybt3LlTbm5u6ty5s8aOHasyZcooLCxMhmFYW58I3ACeJ3rgrlatmj755BNNmDBBFotFRYsWVdu2bdW7d2+ZTCZ5eXnJy8tLO3bs0J07d3Tv3r1kFbglJlJDItOtWzeVKFFCJ06ckPRkooayZcuqVatWypUrl+7fv6/+/ftrzpw5atiwoQICAnTgwAEdP3481rEYnwYASGqiOjBmzZpVefPm1eTJk/XHH3+oUqVKWrt2rcqUKaPTp09rxIgRmjZtmn777Tc5OTkpVapU1sDNTWkAzxMVuI8dOxYrcPv4+MjLy0sdO3aM8TkS9TjCTJkyqUCBApJiTr6W1NG9HInKnTt39OGHH+ry5ctas2aNihYtqrNnz+r69eu6ceNGrInRNmzYoKFDh2rJkiXWu/0AACRFURfC0pOL2bFjx2rx4sW6du2aypQpoyFDhsjb21spU6ZURESEcufOrREjRqh169b2LRxAohE1UeORI0fk6+ur5s2bWwP3W2+9pYwZM2rZsmVKnTq1vUtNUAjdSDQiIiLk7OysBw8eqH79+goKCtKyZctUtGjROLe/evWq6tatq7Jly2rmzJmvuVoAAOxjyJAhatmypbJly6ZHjx4pKChIRYoUibHNkSNH9Mknn2jy5MmqWrWqnSoFkBjduHFD77zzjqpVq6apU6cSuOOB0I1EIfrd+ylTpujOnTsaOnSoSpQooUWLFsUI3pcuXdL27ds1YcIEZc+eXevWrZMU8xEqAAAkRefPn1f+/Pm1a9culS9fXlLM7z+z2azLly+rXr16euONN7Rw4UJ7lgsggYv6/Ij+OXLp0iUdO3ZMtWvXltlsVvny5ZUhQwYC93MQupGoNGrUSH/99Zf8/Px06dIlrVixQg8fPtTq1atVrFgxhYaGatiwYTpx4oQKFiyo8ePHS2JCGABA0hT9prT0pFdYmTJlNGLECNWpUyfGtufOndPy5cu1dOlS5ciRQ6tXr5bETWkAcYt+/XzlyhU5ODgobdq01knQDMNQrVq1FB4ernXr1hG4n4PQjQQt+oXAvn37VK9ePa1cudJ69/7q1atq1KiR7ty5oxUrVqhYsWI6f/68Hj9+rMKFC0sicAMAkr6jR4/qjTfekCTVrFlTb775pr7++mtJT4K5JM2cOVMHDx5U7ty5NWjQIEl8RwKIW/Rr8OHDh2v16tV69OiRzGazJkyYoKpVq+rhw4f66aef9OGHHya7527/W4RuJFjR795HRETo1KlTKl++vE6cOKFcuXJZX//zzz9VuXJlFSlSRDNnzlSJEiWsx+DuPQAgqevfv79mzpypbNmyycXFRSlSpFDmzJn12WefqWzZsnJzc1OqVKkkSXfv3lW6dOkkEbgBvNiwYcM0depUzZ49Wz4+PmrYsKEuXbqkX3/91foIX7wYn7RIkAzDsAZuX19f9ezZU4ULF1bWrFk1efJkSbK+7unpqYIFC+ro0aOxxqYRuAEASV2LFi10+PBhDRo0SI0aNZKzs7PWrVunL7/8UoULF9Ybb7yhSpUqKTAw0Bq4eSwYgBe5d++efv31V82YMUP16tXT3r17dfz4cfXv3z9G4LZYLHasMnFwsncBwNOi33nftGmTIiMj1bNnTzk4OKhDhw5asWKFRowYoYEDB0p60iKeI0cO/fjjjzwWDACQpD09hluSvL29JUm5c+eWJBUpUkR//fWXfvzxR509e1ZXrlzRlStXVLNmTes+3JQG8CL379/XqVOnVKVKFW3dulVNmzbVuHHj1KlTJ4WGhmry5Mnq1q0bY7njgdCNBCcqcE+aNEkbN25UyZIlVaBAAUnSJ598olu3bum7777TTz/9pJIlS2rjxo164403rIGbLuUAgKQoeuBetmyZbt++rYwZM6pOnTpyc3NTWFiYXF1dVahQIaVKlUopUqRQtWrVYhyDLuUA4itXrlwqWbKkPvvsM23cuFGTJ09W27ZtJUm3b9/Whg0bVKRIETVo0MDOlSZ8jOlGghQUFKTPPvtMO3fuVNWqVbVs2TLra7dv39ahQ4c0c+ZMubm5KWvWrBo3bpwkAjcAIGmKHpYbNWqk06dPy2w2K1OmTEqZMqVWrFihlClTSpJCQ0OVL18+TZw4UU2bNrVn2QASgeifL6NGjZLFYtHnn38uR0dHffXVV5oyZYqqV6+upUuXSnryGfPxxx8rPDxcmzZtitX7BrHR0o0E4emwnCVLFo0bN06jRo3Sxo0bNXXqVHXt2lWSlCFDBtWoUUM1atSIcQzu3gMAkqqo77cuXbro9OnT2rRpk7Jnz65OnTpp1qxZqlq1qrZu3Sp3d3c5ODgoderUioiIsHPVABK66NfPp0+f1unTp7VgwQKlTZtWXbp0kZ+fn86fP6+DBw+qatWqKlCggI4fP66QkBDt379fjo6OcQ57QUwkFNid2Wy2Bu7g4GBFREQoMjJS+fPnV79+/VSrVi0tXrxYAQEB1n2evpBgQhgAQFIRvRNieHi49f9PnDih8+fPa+7cucqePbsmT56spUuXatSoUbp3757ef/99hYaGKkWKFJoyZYpatmxpj/IBJCJR1899+/bVhx9+KJPJJG9vb3Xv3l2jR4+Wh4eHJk+erH79+il79uyyWCx69913deDAATk7OysyMpLAHQ90L4ddRb8z1qtXLx05ckTh4eGqXr26unfvrvTp0+vkyZMaO3aszpw5o5YtW6pDhw52rhoAANsbM2aMDMNQ586d5eHhIUlat26ddVKjHj16aM6cOfL19dVnn32mgIAA5cyZU6dOnZKbm5skeoEBeLG1a9eqRYsW+vnnn1WmTBk9ePBAAQEB6t+/v0aPHq2+ffvGuR8t3PFH93LYTfTHgjVq1EjHjh3TgAEDdO7cOS1dulTHjh3TzJkzVaRIEfXt21fjxo3TuHHjVKBAAVWtWtXO1QMAYDtbt26Vv7+/JMnZ2Vnt27eXh4eH6tatK0natWuX6tatK19fX0lSnjx51KFDB+XLl88auCURuAG80O3bt5U3b16VLFlSJpNJadKkUd++ffXw4UP5+/srderU6tChQ6yATeCOPz6J8VpFRERYu81FdSkfP368Lly4oO3bt6tly5Zyd3fXhQsXdPLkSbVu3Vp37txRkSJF1LNnT/Xr14/ADQBI8t555x3Vq1dPpUqVUt++fTVx4kQ9fPjQ+vqVK1e0Z88eGYahoKAgrV27VmXLltXnn38uiefmAoi/dOnS6dixYzp37pxMJpPMZrMk6b333pOjo6O6deumOXPmSIo5/AXxR+jGaxMZGany5curf//+MS4GsmbNqvr168vT01MTJ07U2LFjtWzZMnXu3Fnbtm1Tu3btdP36dRUvXlzt2rWTxAkPAEi6zGazLBaLChUqJF9fXy1ZskRDhw7VuHHjFBoaKkn69NNPFRYWJi8vL/n4+MjDw8P6KB/mOQEQl+jX39HnR3rnnXdUrVo1+fn56a+//rK2YGfIkEEdO3bU8OHD1b17dx08eJCnBL0kxnTjtZoyZYr69OmjQYMGqX///nJyejLC4d69e7p//74aNGigPn36qFmzZjp37pxq1Kih8PBwdevW7ZnjSQAASKye96jLY8eOqVy5ctq0aZOuXbumJk2aaMiQIRowYIAsFosOHDig3bt3W7t+SozhBhC36J81U6dO1cGDB+Xh4aEOHTqoaNGiWrdunSZNmqTHjx/riy++UMqUKTVmzBg5Ozvrm2++UeXKlTV06FB9+umndn4niRNjuvHaREZGqlu3bkqZMqU6dOggZ2dn9ezZU66urkqbNq0OHz6sK1euqHTp0pKkW7du6a233lKHDh3oUg4ASJKiLoKHDx+u0NBQlStXTg0aNJAkeXt7y8/PTytXrtTEiRN19+5dffbZZ5Ikf39/+fj4yMfHx3osAjeAuEQP3CNHjtSoUaPUpEkTLV68WHv27FG/fv3UsGFDpUiRQnPmzFGdOnWUP39+pUuXTr/99pssFovSpEkjd3d3O7+TxItPZrwWkZGR1lbt4sWL6+OPP5a/v7+mTJmiyMhISVLmzJmVPXt2jRkzRuvXr1erVq2UIUMGa+CmUwYAICnatm2bBg8erJkzZ+qLL76Qr6+vVq1apZs3b8rX11erV6/W1atX1bFjR82aNUtDhw7VgAED9Pjx4xjHIXADiEtU4D558qSOHz+ujRs3avbs2bpw4YIyZsyosWPHavny5apevbqWLFmiY8eO6ZdfftGePXvk6OioL774Qo8fP1b58uXt/E4SLz6d8VpEBe4GDRqoW7ducnd3V8WKFdW3b1+NHj1aklSgQAE1bdpUhw4dUo8ePVSyZElNnTpV0vO73wEAkJi988476tGjhx4+fKjOnTsrW7Zs+v7771WpUiU9ePBAbm5uGjVqlCIiItSuXTtNnDhRN27ciDFLOQA8z5w5c9S4cWOdPn1a2bNnlySlSJFCCxcuVMaMGTVhwgT98MMPioyMVJEiRZQ9e3bt2bNHXbp00dy5c/Xjjz/Ky8vLzu8i8WJMN16befPmyd/fX/v27VPOnDn18OFDzZ07Vz179tTQoUP1xRdfKDIyUg8fPtTNmzeVL18+SXSXAwAkXdF7grVp00YbN27UtGnTVKZMGa1bt07Lli3T3r17VatWLf34449ydnaOsT83pQHEx/nz5/Xxxx/r+PHjmjt3rpo0aWJ97e7du2rdurVOnjypqVOnWh9FeObMGa1evVr16tVTwYIF7VV6kkDoxmszceJELVq0SAcOHIjx2LAhQ4boq6++0tdff62uXbtaLz4kLiYAAEnTs24ot2rVSqtWrdKsWbPUpEkT3bx5U6dOnVKhQoWUOXNmvhcBvNCzPl+uXLmievXqKXXq1Priiy9UvXp162u3b9/WmDFjNGrUqBjP3zabzTyP+xUgdMMm4rooWLlypZo1a6aDBw+qaNGi1g+EwMBA1a5dWxaLRatWrVK9evXsVDUAALYX/SL26NGjcnZ2VsGCBa0XyW3atNGSJUs0b948NWzYUC4uLpLo+QXgxaJ/Thw/flx3795VsWLF5ObmphQpUuj8+fNq2LCh0qVLpwEDBsQI3lEI2q8en9x45cxmszVwRz1PVJLefvttVa1aVX379tXx48etHwjp06eXn5+ftm3bRuAGACRphmFYL2YbNWqkRo0aydvbW127dtXu3bslPRmO1aRJE3Xo0EGrVq2yTphG4AbwPIZhWD8nBg4cqHr16qlhw4aqVKmSpk2bpitXrih37txauXKl7t27pzFjxmjDhg2xjkPgfvX49MYrFf1ionfv3mrcuLFatGihffv2KWPGjOrWrZvCwsLUrFkzzZ49W4sWLVKrVq109+5dvf3225Ke3KEDACApMQwjxk3p8ePH69y5c5o7d67mz5+vrVu3auLEifrll18kPQneH330kZo2baojR47Ys3QAiUTU58tXX32l+fPna9q0abpx44YKFy6syZMna8qUKbp8+bI1eJ84cUKbN2+2c9XJA8/pxisTvTtLhw4dtGXLFn3yySf64YcfdOrUKfXp00dNmjRR2rRptWDBAn3++efKnTu33nzzTc2ZM0dSzDt0AAAkdhEREXJwcJCjo6P1pvSqVav0999/68svv1SlSpVUqVIl5c2bV127dtX06dNlMplUtWpVzZ07Vz4+PipXrpyd3wWAhCz6NfiZM2cUGBio6dOnq1atWtq8ebMCAwNVqVIlff/995Kkrl27KleuXNq/f78yZcpkz9KTDcZ045X7448/NHXqVH355ZcqUKCAzGazGjVqpMuXL8vPz0+NGzeWo6Ojrl69Kjc3N6VPn14SY9UAAEnLo0eP1LRpU3Xs2FG1a9eWYRg6cOCAfHx8ZDabNW3aNH322WfW7Xfv3q1u3bopT548atu2rWrXrm19je9IAHGJPo/SqVOnlDFjRu3atUvVq1fXn3/+qUaNGmnIkCHq2LGj6tWrp4MHD+r999/XkCFDlCVLFkmM4X4d+PTGKzV06FB9+OGHOnr0qFKnTi3pybiQhQsXKkeOHJoyZYoWLVqksLAwZcuWzRq4aeEGACQ1ERERqlatmjU8WywW66PAsmXLpi1btujYsWPW7StUqKApU6Zoz549+vvvv2Mci+9IAE+LHri7d++uli1bKjIyUtWqVVPq1Kn1/fffq27dumrbtq0kycvLS2nTppWDg4M8PT2txyFw2x6f4Hil2rdvrwIFCuj8+fPavn27dXy2u7u7Fi5cqKxZs2rYsGHat29fjP14/AkAIKkJDg5W9+7dJUlDhgzRuHHjFBERoXfffVfTpk3T/v379c033+jEiRPWfSpUqKBt27apW7du9iobQCIRdf189+5dXbhwQePGjVOWLFnk4eFhXR8SEqLw8HBJ0s2bNzVmzBhNmzZNJpNJdHh+fQjdeGlmsznWumzZsunHH39UkSJFNHXqVAUGBlpPaHd3dy1YsEA9evRQpUqVXne5AAC8NiNGjFCVKlW0aNEiSdKRI0esz9+OiIhQvXr1NHnyZG3atEmTJ0+OEbwLFCggiYlFAbzYxIkTVbFiRT18+FCFCxeO8VqBAgV05MgRNW7cWG+99Zb+/PNP1apVSyaTSRaLhUav14iJ1PBSoo/92LFjh65fvy4fHx95eHgoU6ZMWrlyperXr6+RI0dKknx9fWUymeTu7m696x/Xs7wBAEjsLl++rHnz5unBgwdatmyZ0qRJo6VLl6pz585asGCBLBaLOnXqpIYNG8pkMqlHjx66e/euJk2apGzZslmPQ5dyAC9StGhRRUZG6siRI9YbdZGRkXJyctKwYcPk4OCgoKAgZc+eXVOnTpWjoyNjuO2AidTwr0WfzKVx48Y6dOiQQkJC5OHhoebNm+uTTz5R7ty5de3aNTVs2FCurq7y8/PjGdwAgGSjb9++mjNnjmrUqKHbt2+rV69eqlmzpjp16qTjx4+rRYsW6tSpk5ydnbV48WLt3btXkyZNsnfZABIZs9msnTt3qlmzZipdurTWrVsnSQoPD5eLi0us7aMCOV4vbqHiX4sK3O3atdOpU6e0bt06Xb16VTlz5tTMmTM1ZcoUnT9/XlmzZtXKlSt18eLFGBPFAACQVDzddhE1drJz587y9fVVhQoVlDZtWo0cOVKBgYGaOXOmihUrpsWLFysgIEDh4eFq1qyZNXDTFgLg33B0dLQOZfnjjz/UsGFDSZKLi4siIyNjbU/gtg9CN+It+hju/fv368KFCwoICFChQoU0efJk7d+/XzVq1ND333+vadOm6dy5c8qaNasOHTqkgQMH2rFyAABsI2qYVNRs41EtSxkyZNDjx491//59zZo1S1myZNGoUaOswbto0aKaMGGCtm/fHufxACC+TCaTqlatqiVLlui3337TRx99JImAnZDQvRzPFH3MdUREhJydna3/7+TkpM2bN6tmzZpavny5evfurblz56pWrVp67733dPToUdWqVUsjR45U5syZYx0PAICk4quvvtLkyZNVq1Yt9evXT5kzZ5anp6f27t2rDz/8UD/99JNSpUqlvn376vbt2+rbt6+qV6+uhQsXql27dvYuH0ASYRiGtm3bpurVq6t///7WuZVgf4RuvND06dNVunRplStXTrVq1VL+/Pk1bdo0PX78WG5ubmrWrJly5MihsWPHSpLatGmjM2fO6N1336WFGwCQpN27d09Vq1bV9evXFRERobffflsPHjxQp06d5OPjo+HDh8vb21udO3fW0aNHNXToUB0/flxLlizRm2++KYmb0gBeHcMwdOjQIb355ptMlpaAELoRS/Qvf4vFojfffFMPHjxQ9uzZdefOHe3Zs0dp06aV9KTLeb169ZQ9e3Z9/fXXMplMatCggQYPHmx9LBgXEwCApOzMmTMaMGCAJKlMmTJKnz69hg4dqtq1a+unn36Sq6urDh06pLRp0+rPP//Utm3brE/yAIC4RJ+4+Gn/5tr6ecfB60PoRgzRT+J9+/apYMGCSpMmjdKnT69Hjx5pxYoVeu+992LsM2jQIC1dulSZM2fW5cuXVaRIEW3cuDHW8QAASKpOnz6tPn36KCIiQtOmTZOLi4t+/fVXTZkyRaGhodq9e7fSpEkT4zuR70gAcYkelDdu3KgLFy4oXbp0Kly4sLWHzIv2O3HihIoWLfpa6sWLEbphFf3Lf8SIEVq1apU+/PBD1ahRQwMGDNCdO3f04MEDzZ07VxUrVoxx12zy5Mm6ceOGUqVKZb3bz8UEACA5+euvv9StWzdJT8Z5ly1bVoZhKDg4WGnSpKHFCcC/0q9fP/3www8qVKiQHj9+rLt37+rLL7/Uxx9/HGvb6NfdM2bM0HfffacffvhBefLked1lIw6EbsTSt29fLVy4UFOmTFGJEiWUP39+62vly5fXjRs3tGDBAvn4+MjR0VEWi0Vms9k60ZpEVxYAQPJ05swZa/D29/dXlSpVJPG9CODf+f7779W3b18tW7ZMFSpU0OTJk9WvXz8tWrRIjRo1irFt9MA9a9Ys9e7dW/Pnz4+1HeyHT3/EsGTJEq1YsULr1q1To0aNrIE76t7M77//rvz586tVq1b6+eefdf78eXl7e+urr76KcRwuLAAAyVGBAgU0ZcoUOTo6avTo0frll18k8b0I4PksFouk/11znzx5Uu+9954qVKiglStXatCgQZo8ebIaNWqk0NBQnTlzxrp9VOAOCAjQ559/ru+++47AncDwDYAYjh8/rtKlS8vb21vSk4nS1q5dq/bt26ty5crq06ePtmzZomLFiqlt27aqXLmy8uXLp6FDh9q5cgAAEoYCBQpo0qRJun37tg4cOGDvcgAkcIZhWG/Mbdu2TaGhoXr06JHy5s2rwMBAtWrVSuPGjVPHjh1lsVi0Zs0abdy4UQ8fPozRpbx///6aN2+eGjZsaM+3gzjwxHRI+t9dtbNnzyo4OFiSFBYWpk8//VSXLl2SYRgqVKiQFi9erHv37mnt2rVat26dTCaT6tSpI4mucwAARClQoIDWrl2rLFmy2LsUAAlY9Ovnfv366bvvvtORI0eUO3du9ejRQy4uLgoICFCrVq0kSaGhofr2229VunRppUyZUpK0du1aDRgwQLNnz9aHH35ot/eCZ2NMN2LYs2ePKlasqGLFiun8+fMqUqSIevXqpUaNGsnJyUmjR4/WrFmzdOjQIaVJk8a6H4EbAIC4MbEogBe5deuWRowYoffee081a9aUJHXu3Fnz58/XTz/9pFy5cslsNqtbt266ffu2fv/9dzk5PWk/3bJli9zc3PT222/b8y3gOWjpRgw+Pj46dOiQtm7dqlSpUqldu3ZycHCwXiykS5dOOXPm1NP3agjcAADEjcAN4HkWLVqkli1bqlChQmrdurV1/RdffKHQ0FDVr19fKVKkUM6cOZUiRQrt2bNHTk5OioyMlJOTk3x9fe1XPOKFlm7E27Vr1/T++++revXqGjdunL3LAQAAABKdp3uI/vPPP/r888+1bt06/fzzz6pSpUqMHjK//fabHj58qDRp0qhMmTJycHCwBm4kDoRuvNCVK1d0/vx5de7cWblz59aaNWsk0V0OAAAAeFlbt25VuXLl5O7urnPnzql9+/Y6efKkdu/erVy5cj0zWDOsM/EhdOO5QkJC1LRpU12/fl0lS5ZUQECAJE52AAAA4GWdPn1aRYoUUffu3TVixAilSpVKFy5cUKtWrXT27Fnt2rVLOXPmlNlslqOjo73LxX9E6MYLnTx5UleuXFGNGjUkEbgBAACA/2r58uVq0aKFunTpomHDhlmDd+vWrXX+/Hlt3bpVefPmtXeZeAUI3fhX6FIOAAAA/DdR19QrVqxQ48aN1aNHDw0dOlTu7u66cOGC3n//fRUsWFArV660d6l4BQjdAAAAAGBjo0aNkmEYGjBgQIz1y5cvV+PGjdWvXz/169dPadKkUVBQkDJlykTX8iSCPsIAAAAAYEOPHz+Wq6urvvjiC02ePNm63mKxqFGjRuratavGjh2rAQMG6NGjR8qSJYscHR1lNpvtWDVeFeaZBwAAAIBXaOvWrfLy8lLBggU1cOBA5ciRQ7169ZKTk5N69uwpi8Winj17WudJ8vT0VI0aNXT06FG5urpaj0NLd9JA6AYAAACAV+Tq1asaMWKEQkNDVaxYMS1YsECHDh2SJHXv3l2GYah3796yWCxq2rSpMmXKpAMHDsjPz0+1atWSxMTFSQ1jugEAAADgFdq+fbuaN2+umzdvatmyZfrggw8UEREhZ2dnSVJAQIA6d+6swoULKywsTClTptTBgwfl5OTExMVJEKEbAAAAAF6BqBbqw4cPq3379nJycpKzs7MCAgJUpEgRmc1mmUwmOTg4aMeOHTp06JDMZrO6d+8uJycnnsudRBG6AQAAAOA/eLp1+uHDh7JYLPr999/19ddfKzg4WPPmzVPhwoWt20Rv+ZZE4E7CGCgAAAAAAC/JYrFYA/epU6d0+vRpXb9+Xe7u7qpRo4a6dOkiDw8PtW/fXidPnpQkNW/eXIsXL45xHAJ30kVLNwAAAAC8hOgt3IMHD9batWsVFBSkQoUKqXHjxvrss88kSevWrdPMmTO1d+9eFSxYUJcuXdI///wTo6UbSRezlwMAAADAS4gK3EOGDNGMGTO0aNEiZcmSRWPHjlXXrl0VGhqqPn36qG7dusqWLZt+++033bhxQ0OGDGEMdzJC6AYAAACAl/THH39o8+bNWrZsmapUqaLNmzdr7dq1qlOnjoYMGSJHR0f5+fmpdOnSKl26tHU/AnfywZhuAAAAAHhJBQoU0Hvvvae33npLW7duVevWrfX1119r3rx5KlOmjHr37q2hQ4fG2o/AnXwwphsAAAAA4iHqkWBPe/TokVKkSKG2bdvKw8NDY8eOlbOzszp27KijR48qXbp0Wr9+Pc/fTqboXg4AAAAALxA9cG/btk1XrlxR+vTpVaxYMeXMmVOhoaE6ePCgKlWqJGdnZ4WGhurOnTvq2bOnPv74Y0mxHy2G5IHQDQAAAADPYRiGNXD37dtXq1atUsqUKeXp6al//vlHq1atUvHixdWoUSPNnDlT4eHhOn78uB49eqQPP/zQegwCd/LEmG4AAAAAiMP27dsVFhZmDctz5szRd999p4ULF+rIkSOqWbOmzp07p7///luS9PHHH6tdu3b6+++/lT9/fv3+++9ydHSU2WwmcCdjjOkGAAAAgKeUKlVKuXLl0ooVKyQ9eTyYn5+fPDw8NGzYMK1Zs0YtWrTQhAkT1L59e4WGhioyMlJp0qSJMTN5ZGSknJzoYJyc0dINAAAAANH88MMPevz4sRYvXiwHBweZTCaZTCbdvXtXadOm1fr169WiRQuNGzdO7du3l8Vi0Y8//qhFixbp8ePH1sBtGAaBG4RuAAAAAIjO0dFRf//9tyIiItStWze9//77kqTs2bNrwoQJatasmcaNG6dOnTpJku7du6clS5bo/v37cnNzsx6HLuWQ6F4OAAAAADGEh4ercePG+vXXX+Xg4KCDBw8qd+7cslgsql69uo4dO6ZNmzYpW7ZsCg8PV6dOnXT79m3t3r2blm3EQks3AAAAgGTv888/1549eyRJLi4uypYtm4KDg2UymZQmTRpJkoODg5YuXao8efLoo48+0htvvKEmTZro3r17+u233+Tk5CSz2WzPt4EEiNswAAAAAJK1+/fv6++//9bDhw8lSXfu3FGWLFm0fv16TZkyRYUKFdL+/fuVM2dOZc6cWXv37tWWLVt0584dZcuWTRUrVpSjoyOTpiFOdC8HAAAAkOz17dtXv/76q3bt2iVXV1frDOQnT55U9+7ddeTIEWvwjkv0GcuB6OheDgAAACDZslgskqT27dvLw8NDS5YskcVisQboIkWKaOrUqXrzzTf11ltv6dKlS5KePAosOgI3noXQDQAAACBZslgscnB4Eony5cunPHnyaM6cOTp37lyM7QoVKmQN3rly5dL169fpRo54o3s5AAAAgGRt9OjRKlGihCpVqiRvb28VLVpU3333nTJlyhRju+PHj2v27NkaP348LduIN1q6AQAAACQrUV3KJenbb7/V1KlT5eHhIXd3d23ZskUHDx5U06ZNtX///hjdyIsVK6aJEyfK0dGRWcoRb7R0AwAAAEiW/vjjDy1dulRFihRR+/btrbOPX758We+//77SpUunKlWqqE+fPkqdOrW9y0UiRUs3AAAAgGTn0KFDqlKliqZNm6YHDx5IkpycnBQZGakcOXJo9+7dqlmzpvbv36+iRYtq8ODBOnjwoJ2rRmJESzcAAACAJM8wDJlMJut/JWnhwoXq2bOnKlSooHHjxqlw4cKSZG3xjto2akbzbNmy6Z133rHju0BiROgGAAAAkKRFn6U8JCREJpNJqVKlkiTNmzdPX3zxhZo2baouXboob968sfYB/gvmuQcAAACQZEUPz+PHj1dgYKBCQ0OVIUMGffvtt2rTpo0Mw9DgwYNlMpnUpUsX5cmTh8CNV4bQDQAAACDJigrPAwYM0Ny5czVs2DDlzJlTzZs3V+3atbV582a1bdtWkjRs2DDdv39fQ4cOVbZs2exZNpIQQjcAAACAJCd6C/c///yjjRs36vvvv1eNGjW0YcMGmc1mtWrVSh4eHpKktm3bKjg4WNu3b1fWrFntWTqSGPpMAAAAAEgymjVrpu3bt8vBwcH6PO7bt2/rzp07qlGjhn766Sc1btxYY8eOVadOnfTgwQPNmjVLkuTn56dVq1bJZDLFeJY38F8QugEAAAAkCcHBwbp//77q1q2rPXv2WFu6c+TIobx582rgwIFq0qSJJkyYoI4dO0qSzp07p1WrVmnPnj3W4xiGwZhuvDL8SwIAAACQJHh4eOjbb79V/fr1VbNmTWuQdnV1VerUqTVmzBi1b99e7du3lyQ9fvxY/v7+cnFxUbly5SRJJpPJ+kgx4FXgkWEAAAAAkpSbN2/Kz89Pq1ev1ubNm1WxYkWdOHFCTZo0Udq0aVWqVCl5eXlp3bp1un37tg4ePChnZ2ceEwabIHQDAAAASNQMw5DJZLL+V5KuX7+u3r17a9WqVdq8ebMqVaqk48ePa/78+frll1+UPXt25cyZU5MnT5aTk5MiIyPl5MQ803j1CN0AAAAAEq3ordOGYSgiIkIuLi6SpBs3bsRo8a5UqZLMZrMMw4gRsAncsCX+ZQEAAABIlKIH7qlTp2r79u0KCQmRr6+v/Pz8lDlzZk2ePFmSVLt2bW3ZskU+Pj4xjvF0AAdeNf51AQAAAEiUogK3v7+/FixYoKZNmypTpkzq3bu3bt68qS+++EIZM2bU5MmT5ejoqIoVK+rPP/+Ut7e39RhMmgZbI3QDAAAASLSWLVumZcuWacWKFSpfvry2bNkiBwcHjRkzRjdv3tQ333yjjBkzaty4ccqXL58KFy5s75KRzBC6AQAAACQa0SdNi4yM1KNHj9SzZ0+VL19eGzZsUPPmzRUQEKAMGTLoww8/VIYMGTRo0CB5enpq8ODBkhjDjdeLidQAAAAAJArRx3CHhITI3d1dt27d0oMHD+Tu7q733ntPH3/8sT7//HP9/fffqlChgm7duqURI0bI39/fztUjueIhdAAAAAASvOiBe8yYMWrbtq2uXbumjBkzKk+ePLpx44ZCQkJUs2ZNSZKbm5s++ugj7dy5U59//rk9S0cyR58KAAAAAAleVODu16+fFi5cqEGDBikkJMT6uqurq86cOaO1a9fq0aNHGj58uCIiIlShQgWZTCa6lMNu6F4OAAAAIFHYtm2bWrZsqYULF6pKlSrW9VGt4LNnz1bnzp2VN29epU2bVrt27ZKzs7N1HDhgD9zqAQAAAJCgmc1mOTo66uLFi0qbNq3eeust62uGYVhbwdu3b6/q1avr4cOHKlq0qBwcHGjhht0xphsAAABAgrNz507NmzdPkuTo6ChJcnZ21v3793XlyhXrdoZhyGw2a+HChbp48aLy5s0rb29vOTg4yGKxELhhd4RuAAAAAAnKd999p7Zt22rLli36/fffrevz5cun8PBwLV68WDdv3pT0ZKy32WzW3LlztXDhwhjHiWoBB+yJMd0AAAAAEoyFCxeqc+fOmj59ut577z1lyJAhxutjx47VsGHD1L59e1WuXFlp06bVqFGjdPv2be3du5eWbSQ4hG4AAAAACcK5c+dUr149+fn56dNPP43x2j///CMvLy+5uLho4cKFmj17tvbv368iRYooY8aMWr9+vZydna3jv4GEgttAAAAAABKEmzdv6v79+6pcubJ13aJFi7RhwwatWrVKnp6e6tWrl7p376569erp9u3bcnR0lJeXF48FQ4LFIAcAAAAACUKaNGnk7OysZcuW6cGDB2rdurUmTZoki8WiH374Qb6+vho+fLiOHj0qDw8P5cmTRzlz5pTJZGLSNCRYdC8HAAAAYDdRz9iWpLCwMA0cOFA//vijQkNDlTFjRo0ePVoVKlSQp6enDMNQunTpNHbsWHXo0MHOlQPxw60gAAAAAHYTFbi///57VatWTf3791ebNm108eJF1ahRI0br9V9//aV8+fIpb9689ioX+Ndo6QYAAABgN4Zh6K+//tIbb7yhvXv3qkSJEnFuFxISoubNmys0NFSbN29msjQkGozpBgAAAPBaWSwWSU8CtyQVKFBABQsW1OXLl2Nte//+fS1evFgfffSRzp8/r40bN8rR0VFms/m11gy8LEI3AAAAgNcqqkv5rVu3ZDKZ5ODgIHd3d+3evdu6jdlsVmRkpL799lutXLlSWbNm1YEDB+Ts7KzIyEhaupFo0L0cAAAAwGs3adIkTZw4UUWLFlW6dOkUEhIiT09P9ejRQ97e3jIMQyaTSY8fP9aVK1eUN29emUwmnsONRIfQDQAAAOC1++mnn2Q2m7Vv3z79/fff+vPPP3Xy5EkVL15cYWFhypo1q/Lly6fWrVurYsWKkmQN4kBiQugGAAAAYFPRHwv2LHPmzNHAgQO1efNm/f777/rnn39048YNzZs3j5ZtJGqEbgAAAAA2Ez1w//HHH3r48KFSpkypcuXKSXrybG5XV1edOHFCdevW1Z49e5Q5c+YYx6BLORIzntMNAAAAwCYMw7AG7gEDBmjVqlW6d++e8uTJozfeeEMBAQFydXWVJGXIkEG3b9/W7t27Vb9+fev+JpOJwI1EjdnLAQAAANhE1PjrkSNHau7cuZo9e7bOnDmjihUravbs2WrcuLF12wwZMih79uy6e/durP2BxIzQDQAAAOCVinoOtySdPHlSv/zyi7777jtVqlRJu3bt0syZM9W+fXvt2LFDzZs3lyQ5OTmpffv2+uSTT+xVNmATdC8HAAAA8MqsW7dODx48UMOGDeXm5qYiRYqocePGKlWqlH777Te1a9dO48ePV4cOHRQREaFvv/1WQUFB2rp1q3r27ClJioyMlJMTUQVJA/+SAQAAALwSu3fvVr169eTu7i5HR0d98MEHSpEihdq3by/pybO5a9WqpZYtW0qS8ufPr7p16ypNmjQxJlwjcCMpoXs5AAAAgFfC29tbb731ljw8PNS2bVv9+OOPioiIsL5+8uRJnTlzRm5uboqIiNDBgwdVq1YtLViwQA4ODjG6pQNJBbeQAAAAAPxnZrNZbm5uqlKlirXlum3btpKkpk2bysXFRS1atFCfPn1UoUIFmc1mhYaGasmSJZJiznQOJCWEbgAAAAD/maOjoxwdHVWjRg3Vr19f+/fvl4ODg7VreatWrVSjRg2NHTtWmzdvVtq0aTV69Gg5OTnxHG4kaSbDMAx7FwEAAAAg8Vm1apXu3LmjN998U2XKlLGu79q1q9zd3TV69Gj16dNH33zzjWbPnq1WrVrFOgaTpiGp4183AAAAgH9tz549+vDDD5U6dWp5eXmpSpUqat26tUqUKKEaNWpo8ODBGjx4sL7++ms5ODjos88+08OHD9W2bVu5uLhYj0PgRlLHoAkAAAAA/5qPj49q1aols9msVq1a6cSJExo2bJjq1KmjggUL6uHDhxoxYoQkaezYsWrVqpWWLl0aI3ADyQHdywEAAAD8K9G7hFepUkXBwcEaM2aMMmbMqNmzZ+vgwYM6cuSIqlWrpuXLlytlypSSnkyWZjKZrP8FkgNCNwAAAIB4iR6Wo/9/xYoVde3aNX333XeqXLmyjh8/rr1796pkyZIqUaLEM/cDkgNCNwAAAIAXslgs1kd6BQUFyc3NTWnTprW+XrlyZZ07d06LFy9W5cqVCdnA/2NMNwAAAIAXigrcgwYNUr169eTt7a0JEybo5MmTkqSdO3cqb968+uSTT7Rjxw6ZzWZJInAj2SN0AwAAAIiTYRiyWCzW5Xnz5mnOnDlq3769GjdurIkTJ2ry5Mk6ePCgJGnHjh3Kly+ffH199eeff9qrbCBBYX5+AAAAAHEymUzWluoDBw7o+PHj+uabb/TRRx9JksqUKaPhw4fLMAx17NhRpUqV0i+//KIuXbqoePHi9iwdSDAI3QAAAABi6N69u+rUqSNfX18ZhqHff/9d1apVk5OTk4oVK2bdrmnTpjKZTBo2bJgcHBzUunVrlStXTtOmTZMkmc1mOTo62uttAAkC3csBAAAAWF2+fFmRkZGqVq2apCet3T4+Pho/frwcHR21Y8cOXbhwwbp9kyZNNHjwYP3444/avn17jGMRuAFmLwcAAADwlKgW6u+//17h4eH69NNPJUmTJ0/W2LFj1aZNG3Xo0EFeXl7WfX7++WdVrVqVoA08he7lAAAAACRJR44cUY4cOZQhQwbdunVLU6dOlaurq1KkSKEmTZqoR48eioyM1MSJEyVJHTt2VI4cOSRJNWrUkESXcuBpdC8HAAAAoNWrV8vHx0eDBw/WjRs3lDFjRs2bN0/u7u6aM2eOFi9eLEnq3bu3evXqpQULFmjcuHG6ceNGjOMQuIGYCN0AAABAMhcWFqZ169bp8ePHOnv2rL766itdu3ZNRYoU0ddffy1nZ2fNmzfPGrx79eqlNm3a6MKFC8qUKZOdqwcSNsZ0AwAAANAff/yh999/Xz4+Pnr06JG8vb3Vv39/ZcmSRadOnZKfn58iIyPVtm1bNWnSRNKT53ibTCbrfwHERugGAAAAkjGLxSLDMOTg4KA+ffooQ4YMslgsWr16tSpXrqx+/fpZg3efPn10+fJljRs3TjVr1lRUlCBwA8/GRGoAAABAMnTy5El5eHgoe/bs1nU5cuTQ999/r927dytVqlTW7uT9+/dX4cKFNXr0aM2fP1/Vq1eXRNgG4oOWbgAAACCZWbFihZo2bars2bNr5MiRKlCggMqUKSNJqlatmmrVqqV+/fpp+PDh2rBhgypUqKDevXsrW7Zs1mMwSzkQP7R0AwAAAMlIeHi4tm7dqsyZM8vR0VEBAQFKnTq10qVLp6+++ko1atTQuXPnJEmDBg2Sg4OD5s2bp1y5cql79+7W8dsEbiB+aOkGAAAAkpmgoCCNGjVKFy9eVNasWdWmTRv17t1bGTNm1NmzZ3XkyBEtW7ZMH3744f+1d38vTf1xHMdfui/N3AhpUMMfBf4iJdcvcHVRliS2dqGwm8SMhNRbQ0kUqotqqRT6BwgtECqi8sJKkqAwGhSOKEgoZAVKc6AU0Y8pm13IdxBfi/jqSZ3Px9XG+Zzz+XzOzXid92efI0ny+XyqqakhaAP/A68MAwAAAFYZu92ulpYWZWRkKBAIKBAI6PHjx2pqapLL5VJWVpa2bNkSb3/8+HGZTCZFo9ElHDWwMlHpBgAAAFapDx8+yOv1yu/3q7q6WidPnpQkTU1Naf369YrFYkpOpk4HLAShGwAAAFjFQqGQLly4oGfPnqmyslKtra2S2CgNWCyEbgAAAGCVC4VC8nq9Gh4eVmlpqc6dO7fUQwISBmtFAAAAgFXObrerra1NOTk5mpiYEHU5YPFQ6QYAAAAgae6/3GlpaUpOTo6/GgzAwhC6AQAAAPyEDdSAxUPoBgAAAADAIDy+AgAAAADAIIRuAAAAAAAMQugGAAAAAMAghG4AAAAAAAxC6AYAAAAAwCCEbgAAAAAADELoBgAAf2T//v1qbGxc6mEAALCiELoBAEgQ4XBYDQ0N2rRpk8xms+x2u8rLy+X3+5d6aAAArFr/LPUAAADA4vB4PJqZmdHVq1eVnZ2tiYkJPXz4UFNTU0s9NElSNBpVUlKSkpN55g8AWD341QMAIAF8/PhRT548UUdHhw4cOKDNmzeruLhYra2tcrvd8Tb19fXauHGjUlJStHXrVvX390uSJicnVVVVpczMTKWmpqqoqEjXrl37bZ/T09M6deqUMjIyZLFY5HQ69ejRo/hxn8+ntLQ09ff3q7CwUGazWe/fvzfsHgAAsBxR6QYAIAFYrVZZrVb19fVp9+7dMpvNPx2PxWJyuVz6/Pmzent7lZOTo9evX8tkMkmSvn//rl27dqmlpUXr1q3T3bt3VVNTo+zsbDmdznn7rK2t1bt373T9+nWlp6frzp07OnTokF69eqW8vDxJ0tevX3Xx4kX19PTIZrNpw4YNxt4IAACWmaTZ2dnZpR4EAABYuFu3bqmurk7fvn3Tzp07VVJSoiNHjsjhcOjBgwdyuVwaGRlRfn7+H13P7XaroKBAly5dkjS3kdr27dvV3d2t0dFR5eXlaWxsTOnp6fFzDh48qOLiYnm9Xvl8PtXW1urFixfatm2bIXMGAGC5o9INAECC8Hg8crvdGhoakt/v18DAgDo7O9XT06NwOKzMzMxfBu5oNKr29nbduHFD4+PjikQiikQislgs87YPBAKanZ39z/UikYhsNlv8+5o1a+RwOBZvkgAArDCEbgAAEkhKSorKyspUVlamM2fO6MSJEzp79qyam5t/e97ly5fV1dWl7u5uFRUVyWKxqLGxUdPT0/O2j8ViMplMGh4eji9R/5fVao1/Xrt2rZKSkhY+MQAAVihCNwAACaywsFB9fX1yOBwaGxvTmzdv5q12Dw0NqaKiQkePHpU0F6rfvn2rgoKCea+7Y8cORaNRhcNh7d2719A5AACwkrF7OQAACWByclKlpaXq7e3Vy5cvFQwGdfPmTXV2dqqiokIlJSXat2+fPB6PBgcHFQwGdf/+fQ0MDEiScnNzNTg4qKdPn2pkZEQNDQ0KhUK/7C8/P1/V1dU6duyYbt++rWAwqOfPn6ujo0P37t37W9MGAGDZo9INAEACsFqtcjqd6urq0ujoqGZmZpSVlaW6ujq1tbVJmttorbm5WVVVVfry5Ytyc3PV3t4uSTp9+rSCwaDKy8uVmpqq+vp6VVZW6tOnT7/s88qVKzp//ryampo0Pj4um82mPXv26PDhw39lzgAArATsXg4AAAAAgEFYXg4AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABiE0A0AAAAAgEEI3QAAAAAAGITQDQAAAACAQQjdAAAAAAAYhNANAAAAAIBBCN0AAAAAABjkB0XU1AOtfHsXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize results across different scalers\n",
    "\n",
    "# Sort for consistent plotting\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=results_df, x='scaler', y='recall')\n",
    "plt.title('Recall by Scaler Type')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Scaler')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a848aa-ee31-4e58-86d1-b99ae2908e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>scaler</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.438172</td>\n",
       "      <td>0.855114</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.570387</td>\n",
       "      <td>0.832386</td>\n",
       "      <td>0.534902</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.634585</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.482549</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.499508</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.490964</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.830966</td>\n",
       "      <td>0.543581</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.637309</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.558754</td>\n",
       "      <td>0.059072</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.528445</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.409389</td>\n",
       "      <td>0.883523</td>\n",
       "      <td>0.457436</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.803103</td>\n",
       "      <td>0.634943</td>\n",
       "      <td>0.426073</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0.703350</td>\n",
       "      <td>0.649148</td>\n",
       "      <td>0.620501</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.753662</td>\n",
       "      <td>0.747159</td>\n",
       "      <td>0.503784</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.569635</td>\n",
       "      <td>0.769886</td>\n",
       "      <td>0.560392</td>\n",
       "      <td>0.087838</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.533780</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.620146</td>\n",
       "      <td>0.748580</td>\n",
       "      <td>0.492959</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.436739</td>\n",
       "      <td>0.830966</td>\n",
       "      <td>0.578822</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.474646</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.504367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>1.054314</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.549680</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.508437</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.469578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.591604</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.505892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.350099</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steps                               scaler      loss  accuracy       auc  \\\n",
       "0       0                     StandardScaler()  0.438172  0.855114  0.548663   \n",
       "1       1                     StandardScaler()  0.570387  0.832386  0.534902   \n",
       "2       2                     StandardScaler()  0.634585  0.815341  0.482549   \n",
       "3       3                     StandardScaler()  0.499508  0.863636  0.490964   \n",
       "4       4                     StandardScaler()  0.508900  0.830966  0.543581   \n",
       "5       0                                 None  0.637309  0.646307  0.558754   \n",
       "6       1                                 None  0.900360  0.542614  0.528445   \n",
       "7       2                                 None  0.409389  0.883523  0.457436   \n",
       "8       3                                 None  0.803103  0.634943  0.426073   \n",
       "9       4                                 None  0.703350  0.649148  0.620501   \n",
       "10      0                       MinMaxScaler()  0.753662  0.747159  0.503784   \n",
       "11      1                       MinMaxScaler()  0.569635  0.769886  0.560392   \n",
       "12      2                       MinMaxScaler()  0.533780  0.789773  0.518072   \n",
       "13      3                       MinMaxScaler()  0.620146  0.748580  0.492959   \n",
       "14      4                       MinMaxScaler()  0.436739  0.830966  0.578822   \n",
       "15      0  MinMaxScaler(feature_range=(-1, 1))  0.474646  0.943182  0.504367   \n",
       "16      1  MinMaxScaler(feature_range=(-1, 1))  1.054314  0.056818  0.549680   \n",
       "17      2  MinMaxScaler(feature_range=(-1, 1))  0.508437  0.943182  0.469578   \n",
       "18      3  MinMaxScaler(feature_range=(-1, 1))  0.591604  0.943182  0.505892   \n",
       "19      4  MinMaxScaler(feature_range=(-1, 1))  0.350099  0.943182  0.481928   \n",
       "\n",
       "    precision  recall  \n",
       "0    0.081081   0.150  \n",
       "1    0.085106   0.200  \n",
       "2    0.050000   0.125  \n",
       "3    0.062500   0.100  \n",
       "4    0.065934   0.150  \n",
       "5    0.059072   0.350  \n",
       "6    0.067485   0.550  \n",
       "7    0.062500   0.075  \n",
       "8    0.042194   0.250  \n",
       "9    0.084337   0.525  \n",
       "10   0.074074   0.300  \n",
       "11   0.087838   0.325  \n",
       "12   0.090909   0.300  \n",
       "13   0.052288   0.200  \n",
       "14   0.092784   0.225  \n",
       "15   0.000000   0.000  \n",
       "16   0.056818   1.000  \n",
       "17   0.000000   0.000  \n",
       "18   0.000000   0.000  \n",
       "19   0.000000   0.000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcfad4-83e7-41ef-9e99-820a5ebc5aa4",
   "metadata": {},
   "source": [
    "## Sequence Tuning\n",
    "\n",
    "Here, we tune the parameters that control how sequences are constructed from the play-level data. This affects how much historical context the model sees, and how densely overlapping the training examples are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2694855-1d62-4ab8-9b53-32f2b997213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in experiments to create a df (first as a dict) of results\n",
    "# var : {string, value} is the independent variable,\n",
    "# where var[0] is a string label for the variable\n",
    "import os\n",
    "\n",
    "def evaluate_and_save(model, X_test, y_test, var, trial, results=None):\n",
    "    # Evaluate\n",
    "    loss, accuracy, auc, precision, recall = model.evaluate(X_test, y_test)\n",
    "\n",
    "    if results is None:\n",
    "        results = {\n",
    "            'steps':[],\n",
    "            var[0]:[],\n",
    "            'loss':[],\n",
    "            'accuracy':[],\n",
    "            'auc':[],\n",
    "            'precision':[],\n",
    "            'recall':[]\n",
    "        }\n",
    "\n",
    "    # Save results\n",
    "    results['steps'].append(trial)\n",
    "    results[var[0]].append(var[1])\n",
    "    results['loss'].append(loss)\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['auc'].append(auc)\n",
    "    results['precision'].append(precision)\n",
    "    results['recall'].append(recall)\n",
    "\n",
    "    # Set up results directory if it doesn't exist\n",
    "    os.makedirs(f'{var[0]}_experiment', exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(f'{var[0]}_experiment/{var[1]}_{var[0]}_trial_{trial}.keras')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5d6ca56-81b7-42b7-b442-e886bdb290ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from 31 games\n",
      "Created 3643 sequences of length 1\n",
      "X shape: (3643, 1, 1968)\n",
      "y shape: (3643,)\n",
      "Epoch 1/25\n",
      "92/92 [==============================] - 7s 20ms/step - loss: 1.1462 - accuracy: 0.5130 - auc: 0.5456 - precision: 0.0807 - recall: 0.5764 - val_loss: 0.8277 - val_accuracy: 0.0700 - val_auc: 0.4435 - val_precision: 0.0687 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 1.0670 - accuracy: 0.5388 - auc: 0.5304 - precision: 0.0752 - recall: 0.4975 - val_loss: 0.9982 - val_accuracy: 0.0823 - val_auc: 0.5494 - val_precision: 0.0695 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.8214 - accuracy: 0.5405 - auc: 0.5924 - precision: 0.0884 - recall: 0.6010 - val_loss: 0.8808 - val_accuracy: 0.1728 - val_auc: 0.4473 - val_precision: 0.0726 - val_recall: 0.9400 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7680 - accuracy: 0.5577 - auc: 0.6213 - precision: 0.0954 - recall: 0.6305 - val_loss: 0.7615 - val_accuracy: 0.3512 - val_auc: 0.5325 - val_precision: 0.0744 - val_recall: 0.7400 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6832 - accuracy: 0.5450 - auc: 0.6455 - precision: 0.0922 - recall: 0.6256 - val_loss: 0.4696 - val_accuracy: 0.8395 - val_auc: 0.5328 - val_precision: 0.0964 - val_recall: 0.1600 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6939 - accuracy: 0.5625 - auc: 0.6437 - precision: 0.0933 - recall: 0.6059 - val_loss: 0.5502 - val_accuracy: 0.8217 - val_auc: 0.5465 - val_precision: 0.0745 - val_recall: 0.1400 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6959 - accuracy: 0.6043 - auc: 0.6224 - precision: 0.0905 - recall: 0.5172 - val_loss: 0.8274 - val_accuracy: 0.3868 - val_auc: 0.5430 - val_precision: 0.0786 - val_recall: 0.7400 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6241 - accuracy: 0.5127 - auc: 0.6910 - precision: 0.1025 - recall: 0.7734 - val_loss: 0.9051 - val_accuracy: 0.3649 - val_auc: 0.5414 - val_precision: 0.0777 - val_recall: 0.7600 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6027 - accuracy: 0.5844 - auc: 0.7150 - precision: 0.1099 - recall: 0.6995 - val_loss: 0.8081 - val_accuracy: 0.7558 - val_auc: 0.5484 - val_precision: 0.0676 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6241 - accuracy: 0.5789 - auc: 0.6915 - precision: 0.1019 - recall: 0.6453 - val_loss: 0.8025 - val_accuracy: 0.7462 - val_auc: 0.5128 - val_precision: 0.0470 - val_recall: 0.1400 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5716 - accuracy: 0.5827 - auc: 0.7402 - precision: 0.1131 - recall: 0.7291 - val_loss: 0.8311 - val_accuracy: 0.3978 - val_auc: 0.5412 - val_precision: 0.0744 - val_recall: 0.6800 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5551 - accuracy: 0.5704 - auc: 0.7575 - precision: 0.1152 - recall: 0.7734 - val_loss: 0.8037 - val_accuracy: 0.4088 - val_auc: 0.5539 - val_precision: 0.0776 - val_recall: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5475 - accuracy: 0.5827 - auc: 0.7602 - precision: 0.1125 - recall: 0.7241 - val_loss: 0.8007 - val_accuracy: 0.4143 - val_auc: 0.5347 - val_precision: 0.0783 - val_recall: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5484 - accuracy: 0.5631 - auc: 0.7508 - precision: 0.1123 - recall: 0.7635 - val_loss: 0.7664 - val_accuracy: 0.4129 - val_auc: 0.5297 - val_precision: 0.0743 - val_recall: 0.6600 - lr: 2.0000e-04\n",
      "Epoch 15/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5358 - accuracy: 0.5611 - auc: 0.7746 - precision: 0.1168 - recall: 0.8079 - val_loss: 0.7760 - val_accuracy: 0.4088 - val_auc: 0.5328 - val_precision: 0.0719 - val_recall: 0.6400 - lr: 2.0000e-04\n",
      "Epoch 16/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5267 - accuracy: 0.5580 - auc: 0.7922 - precision: 0.1166 - recall: 0.8128 - val_loss: 0.7664 - val_accuracy: 0.4060 - val_auc: 0.5323 - val_precision: 0.0716 - val_recall: 0.6400 - lr: 1.0000e-04\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.8217 - auc: 0.5465 - precision: 0.0745 - recall: 0.1400   \n",
      "Sampling from 31 games\n",
      "Created 1829 sequences of length 1\n",
      "X shape: (1829, 1, 1968)\n",
      "y shape: (1829,)\n",
      "Epoch 1/25\n",
      "46/46 [==============================] - 8s 33ms/step - loss: 1.1929 - accuracy: 0.4607 - auc: 0.4645 - precision: 0.0656 - recall: 0.4474 - val_loss: 0.7840 - val_accuracy: 0.0656 - val_auc: 0.5447 - val_precision: 0.0606 - val_recall: 0.9565 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1227 - accuracy: 0.4798 - auc: 0.5332 - precision: 0.0793 - recall: 0.5351 - val_loss: 0.5278 - val_accuracy: 0.9372 - val_auc: 0.5670 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.8187 - accuracy: 0.5311 - auc: 0.6533 - precision: 0.1050 - recall: 0.6667 - val_loss: 0.5473 - val_accuracy: 0.9317 - val_auc: 0.5700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.8065 - accuracy: 0.5516 - auc: 0.6223 - precision: 0.0955 - recall: 0.5614 - val_loss: 0.8816 - val_accuracy: 0.0984 - val_auc: 0.4857 - val_precision: 0.0602 - val_recall: 0.9130 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6791 - accuracy: 0.5571 - auc: 0.7120 - precision: 0.1229 - recall: 0.7632 - val_loss: 0.7049 - val_accuracy: 0.4481 - val_auc: 0.4675 - val_precision: 0.0634 - val_recall: 0.5652 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6329 - accuracy: 0.5981 - auc: 0.7309 - precision: 0.1250 - recall: 0.6930 - val_loss: 0.4688 - val_accuracy: 0.9153 - val_auc: 0.4741 - val_precision: 0.1667 - val_recall: 0.0870 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5669 - accuracy: 0.5892 - auc: 0.7649 - precision: 0.1305 - recall: 0.7544 - val_loss: 1.0656 - val_accuracy: 0.2240 - val_auc: 0.4897 - val_precision: 0.0546 - val_recall: 0.6957 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5363 - accuracy: 0.6309 - auc: 0.7907 - precision: 0.1485 - recall: 0.7895 - val_loss: 0.8864 - val_accuracy: 0.3634 - val_auc: 0.4690 - val_precision: 0.0551 - val_recall: 0.5652 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5702 - accuracy: 0.6179 - auc: 0.7589 - precision: 0.1322 - recall: 0.7018 - val_loss: 0.7627 - val_accuracy: 0.4454 - val_auc: 0.4831 - val_precision: 0.0545 - val_recall: 0.4783 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.6582 - auc: 0.8323 - precision: 0.1626 - recall: 0.8158 - val_loss: 0.9640 - val_accuracy: 0.4016 - val_auc: 0.4490 - val_precision: 0.0545 - val_recall: 0.5217 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.6562 - auc: 0.8253 - precision: 0.1698 - recall: 0.8772 - val_loss: 0.5356 - val_accuracy: 0.8361 - val_auc: 0.4791 - val_precision: 0.0488 - val_recall: 0.0870 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.7396 - auc: 0.8495 - precision: 0.1888 - recall: 0.7105 - val_loss: 0.7777 - val_accuracy: 0.4590 - val_auc: 0.4674 - val_precision: 0.0558 - val_recall: 0.4783 - lr: 2.0000e-04\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.9372 - auc: 0.5670 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1223 sequences of length 1\n",
      "X shape: (1223, 1, 1968)\n",
      "y shape: (1223,)\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 7s 46ms/step - loss: 1.0422 - accuracy: 0.4857 - auc: 0.5132 - precision: 0.0557 - recall: 0.5000 - val_loss: 0.8862 - val_accuracy: 0.0776 - val_auc: 0.3987 - val_precision: 0.0776 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1452 - accuracy: 0.4642 - auc: 0.5721 - precision: 0.0667 - recall: 0.6429 - val_loss: 0.7978 - val_accuracy: 0.0776 - val_auc: 0.4277 - val_precision: 0.0776 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9089 - accuracy: 0.5348 - auc: 0.6602 - precision: 0.0800 - recall: 0.6786 - val_loss: 0.6131 - val_accuracy: 0.8939 - val_auc: 0.4315 - val_precision: 0.1111 - val_recall: 0.0526 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7311 - accuracy: 0.5552 - auc: 0.7240 - precision: 0.0889 - recall: 0.7321 - val_loss: 0.5423 - val_accuracy: 0.9184 - val_auc: 0.4675 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.5542 - auc: 0.7619 - precision: 0.0957 - recall: 0.8036 - val_loss: 0.6968 - val_accuracy: 0.3469 - val_auc: 0.5298 - val_precision: 0.0877 - val_recall: 0.7895 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.6176 - auc: 0.8097 - precision: 0.1103 - recall: 0.8036 - val_loss: 0.6468 - val_accuracy: 0.5469 - val_auc: 0.5965 - val_precision: 0.1034 - val_recall: 0.6316 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5512 - accuracy: 0.6094 - auc: 0.7963 - precision: 0.1005 - recall: 0.7321 - val_loss: 0.9352 - val_accuracy: 0.1633 - val_auc: 0.5009 - val_precision: 0.0773 - val_recall: 0.8947 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5096 - accuracy: 0.7014 - auc: 0.8235 - precision: 0.1312 - recall: 0.7500 - val_loss: 0.8706 - val_accuracy: 0.3551 - val_auc: 0.5833 - val_precision: 0.0838 - val_recall: 0.7368 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5168 - accuracy: 0.6544 - auc: 0.8281 - precision: 0.1250 - recall: 0.8393 - val_loss: 0.5323 - val_accuracy: 0.8776 - val_auc: 0.5163 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4528 - accuracy: 0.6677 - auc: 0.8732 - precision: 0.1335 - recall: 0.8750 - val_loss: 0.3245 - val_accuracy: 0.9224 - val_auc: 0.4589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4462 - accuracy: 0.7157 - auc: 0.8692 - precision: 0.1487 - recall: 0.8393 - val_loss: 0.5871 - val_accuracy: 0.5918 - val_auc: 0.5618 - val_precision: 0.1068 - val_recall: 0.5789 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4376 - accuracy: 0.6922 - auc: 0.8557 - precision: 0.1321 - recall: 0.7857 - val_loss: 0.4208 - val_accuracy: 0.9102 - val_auc: 0.5141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4423 - accuracy: 0.7168 - auc: 0.8494 - precision: 0.1353 - recall: 0.7321 - val_loss: 0.6257 - val_accuracy: 0.5551 - val_auc: 0.5344 - val_precision: 0.0982 - val_recall: 0.5789 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.7372 - auc: 0.9027 - precision: 0.1616 - recall: 0.8571 - val_loss: 0.4975 - val_accuracy: 0.8857 - val_auc: 0.5261 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.9184 - auc: 0.4675 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 923 sequences of length 1\n",
      "X shape: (923, 1, 1968)\n",
      "y shape: (923,)\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 6s 56ms/step - loss: 1.2610 - accuracy: 0.4593 - auc: 0.4727 - precision: 0.0557 - recall: 0.4583 - val_loss: 0.9139 - val_accuracy: 0.0324 - val_auc: 0.6606 - val_precision: 0.0324 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0109 - accuracy: 0.4919 - auc: 0.6481 - precision: 0.0840 - recall: 0.6875 - val_loss: 0.6674 - val_accuracy: 0.7838 - val_auc: 0.6322 - val_precision: 0.0526 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8287 - accuracy: 0.5352 - auc: 0.6639 - precision: 0.0868 - recall: 0.6458 - val_loss: 0.7984 - val_accuracy: 0.0432 - val_auc: 0.2295 - val_precision: 0.0328 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7310 - accuracy: 0.5556 - auc: 0.7189 - precision: 0.1045 - recall: 0.7708 - val_loss: 0.6450 - val_accuracy: 0.8919 - val_auc: 0.7435 - val_precision: 0.1111 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7172 - accuracy: 0.5705 - auc: 0.7282 - precision: 0.1032 - recall: 0.7292 - val_loss: 0.8130 - val_accuracy: 0.0649 - val_auc: 0.6401 - val_precision: 0.0335 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7552 - accuracy: 0.6518 - auc: 0.7460 - precision: 0.1254 - recall: 0.7292 - val_loss: 0.8344 - val_accuracy: 0.1784 - val_auc: 0.6834 - val_precision: 0.0380 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5502 - accuracy: 0.6640 - auc: 0.7999 - precision: 0.1296 - recall: 0.7292 - val_loss: 0.7475 - val_accuracy: 0.3405 - val_auc: 0.6406 - val_precision: 0.0469 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4833 - accuracy: 0.6314 - auc: 0.8518 - precision: 0.1291 - recall: 0.8125 - val_loss: 0.8908 - val_accuracy: 0.0919 - val_auc: 0.7747 - val_precision: 0.0345 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3982 - accuracy: 0.7087 - auc: 0.8955 - precision: 0.1700 - recall: 0.8958 - val_loss: 0.8449 - val_accuracy: 0.1514 - val_auc: 0.7160 - val_precision: 0.0368 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.7290 - auc: 0.8805 - precision: 0.1696 - recall: 0.8125 - val_loss: 0.8455 - val_accuracy: 0.2486 - val_auc: 0.7207 - val_precision: 0.0414 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4315 - accuracy: 0.6924 - auc: 0.8763 - precision: 0.1518 - recall: 0.8125 - val_loss: 0.8105 - val_accuracy: 0.3297 - val_auc: 0.6201 - val_precision: 0.0462 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.7127 - auc: 0.8818 - precision: 0.1555 - recall: 0.7708 - val_loss: 0.7074 - val_accuracy: 0.4595 - val_auc: 0.6392 - val_precision: 0.0481 - val_recall: 0.8333 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7838 - auc: 0.6322 - precision: 0.0526 - recall: 0.3333        \n",
      "Sampling from 31 games\n",
      "Created 3581 sequences of length 3\n",
      "X shape: (3581, 3, 1968)\n",
      "y shape: (3581,)\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 7s 21ms/step - loss: 1.2959 - accuracy: 0.4735 - auc: 0.4887 - precision: 0.0692 - recall: 0.5224 - val_loss: 0.8524 - val_accuracy: 0.0976 - val_auc: 0.4782 - val_precision: 0.0717 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.0355 - accuracy: 0.5059 - auc: 0.4934 - precision: 0.0713 - recall: 0.5025 - val_loss: 1.0704 - val_accuracy: 0.0781 - val_auc: 0.5201 - val_precision: 0.0691 - val_recall: 0.9800 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.8536 - accuracy: 0.5168 - auc: 0.5725 - precision: 0.0855 - recall: 0.6070 - val_loss: 0.3465 - val_accuracy: 0.9289 - val_auc: 0.4378 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7485 - accuracy: 0.5534 - auc: 0.6264 - precision: 0.0935 - recall: 0.6169 - val_loss: 0.6290 - val_accuracy: 0.6946 - val_auc: 0.4308 - val_precision: 0.0481 - val_recall: 0.1800 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6853 - accuracy: 0.5597 - auc: 0.6663 - precision: 0.1021 - recall: 0.6766 - val_loss: 0.4647 - val_accuracy: 0.8312 - val_auc: 0.4952 - val_precision: 0.0617 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6504 - accuracy: 0.6009 - auc: 0.6926 - precision: 0.1075 - recall: 0.6418 - val_loss: 0.6852 - val_accuracy: 0.6722 - val_auc: 0.5494 - val_precision: 0.0814 - val_recall: 0.3600 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5753 - accuracy: 0.5946 - auc: 0.7616 - precision: 0.1232 - recall: 0.7811 - val_loss: 0.8192 - val_accuracy: 0.6179 - val_auc: 0.5151 - val_precision: 0.0758 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5465 - accuracy: 0.6341 - auc: 0.7853 - precision: 0.1308 - recall: 0.7463 - val_loss: 0.8923 - val_accuracy: 0.4184 - val_auc: 0.5747 - val_precision: 0.0742 - val_recall: 0.6400 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5199 - accuracy: 0.6285 - auc: 0.8114 - precision: 0.1377 - recall: 0.8159 - val_loss: 0.7316 - val_accuracy: 0.5300 - val_auc: 0.5702 - val_precision: 0.0865 - val_recall: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4881 - accuracy: 0.6606 - auc: 0.8405 - precision: 0.1511 - recall: 0.8308 - val_loss: 0.6907 - val_accuracy: 0.5453 - val_auc: 0.5705 - val_precision: 0.0868 - val_recall: 0.5800 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4727 - accuracy: 0.6686 - auc: 0.8487 - precision: 0.1556 - recall: 0.8408 - val_loss: 0.6892 - val_accuracy: 0.5676 - val_auc: 0.5760 - val_precision: 0.0886 - val_recall: 0.5600 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4731 - accuracy: 0.6976 - auc: 0.8475 - precision: 0.1652 - recall: 0.8159 - val_loss: 0.7064 - val_accuracy: 0.5551 - val_auc: 0.5712 - val_precision: 0.0836 - val_recall: 0.5400 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4601 - accuracy: 0.6735 - auc: 0.8603 - precision: 0.1602 - recall: 0.8607 - val_loss: 0.6654 - val_accuracy: 0.5816 - val_auc: 0.5722 - val_precision: 0.0833 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.9289 - auc: 0.4378 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1798 sequences of length 3\n",
      "X shape: (1798, 3, 1968)\n",
      "y shape: (1798,)\n",
      "Epoch 1/25\n",
      "45/45 [==============================] - 7s 33ms/step - loss: 1.2269 - accuracy: 0.5028 - auc: 0.5153 - precision: 0.0793 - recall: 0.5182 - val_loss: 0.5284 - val_accuracy: 0.9000 - val_auc: 0.5160 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 1.0537 - accuracy: 0.5209 - auc: 0.5747 - precision: 0.0905 - recall: 0.5818 - val_loss: 0.4592 - val_accuracy: 0.9306 - val_auc: 0.5325 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.8288 - accuracy: 0.5452 - auc: 0.6731 - precision: 0.1103 - recall: 0.7000 - val_loss: 0.5620 - val_accuracy: 0.9083 - val_auc: 0.5151 - val_precision: 0.1000 - val_recall: 0.0400 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7409 - accuracy: 0.5821 - auc: 0.6713 - precision: 0.1072 - recall: 0.6091 - val_loss: 0.8890 - val_accuracy: 0.1167 - val_auc: 0.4726 - val_precision: 0.0653 - val_recall: 0.8800 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7146 - accuracy: 0.6078 - auc: 0.7104 - precision: 0.1217 - recall: 0.6636 - val_loss: 0.5928 - val_accuracy: 0.8083 - val_auc: 0.4941 - val_precision: 0.0926 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.6484 - accuracy: 0.6370 - auc: 0.7468 - precision: 0.1386 - recall: 0.7182 - val_loss: 0.5030 - val_accuracy: 0.8778 - val_auc: 0.4364 - val_precision: 0.0476 - val_recall: 0.0400 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.6163 - accuracy: 0.6439 - auc: 0.7593 - precision: 0.1436 - recall: 0.7364 - val_loss: 0.4249 - val_accuracy: 0.9194 - val_auc: 0.4899 - val_precision: 0.1667 - val_recall: 0.0400 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5693 - accuracy: 0.6405 - auc: 0.8021 - precision: 0.1473 - recall: 0.7727 - val_loss: 0.3413 - val_accuracy: 0.9139 - val_auc: 0.5335 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4961 - accuracy: 0.7302 - auc: 0.8337 - precision: 0.1869 - recall: 0.7545 - val_loss: 0.5572 - val_accuracy: 0.6806 - val_auc: 0.4314 - val_precision: 0.0408 - val_recall: 0.1600 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4990 - accuracy: 0.7191 - auc: 0.8301 - precision: 0.1762 - recall: 0.7273 - val_loss: 0.6681 - val_accuracy: 0.5417 - val_auc: 0.4021 - val_precision: 0.0333 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4991 - accuracy: 0.6898 - auc: 0.8307 - precision: 0.1680 - recall: 0.7727 - val_loss: 0.3731 - val_accuracy: 0.9083 - val_auc: 0.4060 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.9000 - auc: 0.5160 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1204 sequences of length 3\n",
      "X shape: (1204, 3, 1968)\n",
      "y shape: (1204,)\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 6s 45ms/step - loss: 1.0268 - accuracy: 0.5306 - auc: 0.5894 - precision: 0.0975 - recall: 0.6389 - val_loss: 0.6788 - val_accuracy: 0.6473 - val_auc: 0.2972 - val_precision: 0.0541 - val_recall: 0.2105 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1973 - accuracy: 0.5161 - auc: 0.5703 - precision: 0.0896 - recall: 0.5972 - val_loss: 0.7368 - val_accuracy: 0.2033 - val_auc: 0.5231 - val_precision: 0.0900 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8576 - accuracy: 0.5421 - auc: 0.6502 - precision: 0.1032 - recall: 0.6667 - val_loss: 0.7602 - val_accuracy: 0.1369 - val_auc: 0.4116 - val_precision: 0.0800 - val_recall: 0.9474 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7465 - accuracy: 0.5805 - auc: 0.7190 - precision: 0.1244 - recall: 0.7639 - val_loss: 0.5631 - val_accuracy: 0.8921 - val_auc: 0.4580 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7430 - accuracy: 0.6158 - auc: 0.7206 - precision: 0.1199 - recall: 0.6528 - val_loss: 1.1255 - val_accuracy: 0.0830 - val_auc: 0.5699 - val_precision: 0.0792 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6038 - accuracy: 0.6106 - auc: 0.7734 - precision: 0.1384 - recall: 0.8056 - val_loss: 0.7946 - val_accuracy: 0.2614 - val_auc: 0.5301 - val_precision: 0.0794 - val_recall: 0.7895 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5484 - accuracy: 0.6386 - auc: 0.8158 - precision: 0.1480 - recall: 0.8056 - val_loss: 0.8950 - val_accuracy: 0.2324 - val_auc: 0.5931 - val_precision: 0.0891 - val_recall: 0.9474 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5460 - accuracy: 0.6532 - auc: 0.8148 - precision: 0.1571 - recall: 0.8333 - val_loss: 0.4977 - val_accuracy: 0.8797 - val_auc: 0.4887 - val_precision: 0.0833 - val_recall: 0.0526 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5004 - accuracy: 0.7020 - auc: 0.8320 - precision: 0.1692 - recall: 0.7639 - val_loss: 0.8139 - val_accuracy: 0.3361 - val_auc: 0.4655 - val_precision: 0.0727 - val_recall: 0.6316 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5344 - accuracy: 0.6469 - auc: 0.8081 - precision: 0.1510 - recall: 0.8056 - val_loss: 0.6632 - val_accuracy: 0.5975 - val_auc: 0.4523 - val_precision: 0.0465 - val_recall: 0.2105 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4644 - accuracy: 0.7051 - auc: 0.8611 - precision: 0.1807 - recall: 0.8333 - val_loss: 0.3546 - val_accuracy: 0.8838 - val_auc: 0.5224 - val_precision: 0.0909 - val_recall: 0.0526 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.7051 - auc: 0.8439 - precision: 0.1826 - recall: 0.8472 - val_loss: 0.5318 - val_accuracy: 0.8008 - val_auc: 0.5294 - val_precision: 0.0606 - val_recall: 0.1053 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4355 - accuracy: 0.7269 - auc: 0.8773 - precision: 0.2006 - recall: 0.8889 - val_loss: 0.4573 - val_accuracy: 0.8174 - val_auc: 0.4913 - val_precision: 0.0690 - val_recall: 0.1053 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4468 - accuracy: 0.7342 - auc: 0.8656 - precision: 0.1954 - recall: 0.8194 - val_loss: 0.5977 - val_accuracy: 0.7178 - val_auc: 0.5127 - val_precision: 0.0702 - val_recall: 0.2105 - lr: 0.0010\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.8921 - auc: 0.4580 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 906 sequences of length 3\n",
      "X shape: (906, 3, 1968)\n",
      "y shape: (906,)\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 6s 61ms/step - loss: 1.1744 - accuracy: 0.4724 - auc: 0.4537 - precision: 0.0716 - recall: 0.3662 - val_loss: 0.6581 - val_accuracy: 0.7747 - val_auc: 0.6250 - val_precision: 0.0323 - val_recall: 0.0833 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.1163 - accuracy: 0.5000 - auc: 0.5862 - precision: 0.1181 - recall: 0.6338 - val_loss: 0.5756 - val_accuracy: 0.9341 - val_auc: 0.6162 - val_precision: 0.5000 - val_recall: 0.0833 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9698 - accuracy: 0.5345 - auc: 0.6258 - precision: 0.1306 - recall: 0.6620 - val_loss: 0.6201 - val_accuracy: 0.8901 - val_auc: 0.5767 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7606 - accuracy: 0.5884 - auc: 0.7220 - precision: 0.1550 - recall: 0.7183 - val_loss: 0.6212 - val_accuracy: 0.8791 - val_auc: 0.5407 - val_precision: 0.0833 - val_recall: 0.0833 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6690 - accuracy: 0.6312 - auc: 0.7621 - precision: 0.1755 - recall: 0.7465 - val_loss: 0.4076 - val_accuracy: 0.9341 - val_auc: 0.5512 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6096 - accuracy: 0.6492 - auc: 0.7925 - precision: 0.1789 - recall: 0.7183 - val_loss: 0.4398 - val_accuracy: 0.9341 - val_auc: 0.5505 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5540 - accuracy: 0.6533 - auc: 0.8288 - precision: 0.1918 - recall: 0.7887 - val_loss: 0.4689 - val_accuracy: 0.9341 - val_auc: 0.5882 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4823 - accuracy: 0.6740 - auc: 0.8589 - precision: 0.2165 - recall: 0.8873 - val_loss: 0.5385 - val_accuracy: 0.9121 - val_auc: 0.5679 - val_precision: 0.1667 - val_recall: 0.0833 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.7307 - auc: 0.9015 - precision: 0.2500 - recall: 0.8732 - val_loss: 0.3741 - val_accuracy: 0.9286 - val_auc: 0.5176 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.7762 - auc: 0.9232 - precision: 0.2864 - recall: 0.8592 - val_loss: 0.3804 - val_accuracy: 0.9341 - val_auc: 0.4892 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3453 - accuracy: 0.8052 - auc: 0.9283 - precision: 0.3214 - recall: 0.8873 - val_loss: 0.3882 - val_accuracy: 0.9231 - val_auc: 0.4760 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3760 - accuracy: 0.8149 - auc: 0.9164 - precision: 0.3279 - recall: 0.8451 - val_loss: 0.4192 - val_accuracy: 0.8956 - val_auc: 0.5157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.3254 - accuracy: 0.8177 - auc: 0.9365 - precision: 0.3386 - recall: 0.9014 - val_loss: 0.5302 - val_accuracy: 0.7637 - val_auc: 0.5174 - val_precision: 0.1026 - val_recall: 0.3333 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.8901 - auc: 0.5767 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3519 sequences of length 5\n",
      "X shape: (3519, 5, 1968)\n",
      "y shape: (3519,)\n",
      "Epoch 1/25\n",
      "88/88 [==============================] - 7s 21ms/step - loss: 1.3242 - accuracy: 0.4938 - auc: 0.4708 - precision: 0.0661 - recall: 0.4537 - val_loss: 0.6528 - val_accuracy: 0.7528 - val_auc: 0.5101 - val_precision: 0.0592 - val_recall: 0.2250 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.0039 - accuracy: 0.4920 - auc: 0.5268 - precision: 0.0773 - recall: 0.5463 - val_loss: 0.6269 - val_accuracy: 0.7756 - val_auc: 0.4411 - val_precision: 0.0462 - val_recall: 0.1500 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7880 - accuracy: 0.5453 - auc: 0.6196 - precision: 0.0980 - recall: 0.6390 - val_loss: 1.2378 - val_accuracy: 0.0582 - val_auc: 0.4648 - val_precision: 0.0569 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6711 - accuracy: 0.5933 - auc: 0.6926 - precision: 0.1160 - recall: 0.6927 - val_loss: 0.8014 - val_accuracy: 0.3906 - val_auc: 0.5325 - val_precision: 0.0629 - val_recall: 0.7000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6010 - accuracy: 0.6185 - auc: 0.7568 - precision: 0.1352 - recall: 0.7854 - val_loss: 0.5972 - val_accuracy: 0.7045 - val_auc: 0.5359 - val_precision: 0.0532 - val_recall: 0.2500 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5652 - accuracy: 0.6554 - auc: 0.7841 - precision: 0.1468 - recall: 0.7756 - val_loss: 0.7183 - val_accuracy: 0.6207 - val_auc: 0.4925 - val_precision: 0.0514 - val_recall: 0.3250 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5432 - accuracy: 0.6682 - auc: 0.7944 - precision: 0.1512 - recall: 0.7707 - val_loss: 0.7767 - val_accuracy: 0.5824 - val_auc: 0.4794 - val_precision: 0.0528 - val_recall: 0.3750 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5230 - accuracy: 0.6963 - auc: 0.8161 - precision: 0.1622 - recall: 0.7610 - val_loss: 0.8271 - val_accuracy: 0.6179 - val_auc: 0.5172 - val_precision: 0.0613 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4924 - accuracy: 0.7073 - auc: 0.8438 - precision: 0.1746 - recall: 0.8098 - val_loss: 0.9250 - val_accuracy: 0.5412 - val_auc: 0.4460 - val_precision: 0.0450 - val_recall: 0.3500 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4813 - accuracy: 0.7297 - auc: 0.8498 - precision: 0.1855 - recall: 0.8000 - val_loss: 0.8965 - val_accuracy: 0.5767 - val_auc: 0.4845 - val_precision: 0.0612 - val_recall: 0.4500 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4008 - accuracy: 0.7329 - auc: 0.9013 - precision: 0.1971 - recall: 0.8683 - val_loss: 0.7025 - val_accuracy: 0.6591 - val_auc: 0.4987 - val_precision: 0.0575 - val_recall: 0.3250 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.3546 - accuracy: 0.7748 - auc: 0.9312 - precision: 0.2335 - recall: 0.9171 - val_loss: 0.6289 - val_accuracy: 0.7543 - val_auc: 0.4864 - val_precision: 0.0710 - val_recall: 0.2750 - lr: 2.0000e-04\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7756 - auc: 0.4411 - precision: 0.0462 - recall: 0.1500\n",
      "Sampling from 31 games\n",
      "Created 1767 sequences of length 5\n",
      "X shape: (1767, 5, 1968)\n",
      "y shape: (1767,)\n",
      "Epoch 1/25\n",
      "45/45 [==============================] - 7s 34ms/step - loss: 1.2390 - accuracy: 0.4897 - auc: 0.5075 - precision: 0.0823 - recall: 0.5357 - val_loss: 0.7522 - val_accuracy: 0.1525 - val_auc: 0.5126 - val_precision: 0.0570 - val_recall: 0.9000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 1.1424 - accuracy: 0.4961 - auc: 0.4986 - precision: 0.0751 - recall: 0.4732 - val_loss: 0.6564 - val_accuracy: 0.7034 - val_auc: 0.5180 - val_precision: 0.0330 - val_recall: 0.1500 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.9186 - accuracy: 0.5485 - auc: 0.6116 - precision: 0.1075 - recall: 0.6429 - val_loss: 0.4774 - val_accuracy: 0.9435 - val_auc: 0.5867 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.5541 - auc: 0.6619 - precision: 0.1099 - recall: 0.6518 - val_loss: 0.7106 - val_accuracy: 0.4181 - val_auc: 0.6370 - val_precision: 0.0734 - val_recall: 0.8000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7325 - accuracy: 0.5817 - auc: 0.6867 - precision: 0.1216 - recall: 0.6875 - val_loss: 0.8257 - val_accuracy: 0.1836 - val_auc: 0.5270 - val_precision: 0.0561 - val_recall: 0.8500 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7102 - accuracy: 0.6207 - auc: 0.7066 - precision: 0.1357 - recall: 0.7054 - val_loss: 0.9609 - val_accuracy: 0.1751 - val_auc: 0.5376 - val_precision: 0.0613 - val_recall: 0.9500 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.6113 - accuracy: 0.6433 - auc: 0.7736 - precision: 0.1487 - recall: 0.7411 - val_loss: 0.6383 - val_accuracy: 0.6243 - val_auc: 0.4966 - val_precision: 0.0620 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5747 - accuracy: 0.6263 - auc: 0.7883 - precision: 0.1498 - recall: 0.7946 - val_loss: 0.4650 - val_accuracy: 0.8051 - val_auc: 0.5240 - val_precision: 0.0984 - val_recall: 0.3000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5362 - accuracy: 0.6745 - auc: 0.8142 - precision: 0.1679 - recall: 0.7857 - val_loss: 0.7951 - val_accuracy: 0.4350 - val_auc: 0.6159 - val_precision: 0.0673 - val_recall: 0.7000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5935 - accuracy: 0.6645 - auc: 0.7851 - precision: 0.1546 - recall: 0.7232 - val_loss: 0.7470 - val_accuracy: 0.6356 - val_auc: 0.4740 - val_precision: 0.0640 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5749 - accuracy: 0.6447 - auc: 0.7939 - precision: 0.1530 - recall: 0.7679 - val_loss: 0.5626 - val_accuracy: 0.7853 - val_auc: 0.5156 - val_precision: 0.0758 - val_recall: 0.2500 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5137 - accuracy: 0.6681 - auc: 0.8250 - precision: 0.1613 - recall: 0.7589 - val_loss: 0.5845 - val_accuracy: 0.7119 - val_auc: 0.5013 - val_precision: 0.0444 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4626 - accuracy: 0.7304 - auc: 0.8604 - precision: 0.2018 - recall: 0.8125 - val_loss: 0.6514 - val_accuracy: 0.6243 - val_auc: 0.4790 - val_precision: 0.0551 - val_recall: 0.3500 - lr: 0.0010\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.9435 - auc: 0.5867 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1185 sequences of length 5\n",
      "X shape: (1185, 5, 1968)\n",
      "y shape: (1185,)\n",
      "Epoch 1/25\n",
      "30/30 [==============================] - 8s 101ms/step - loss: 1.3372 - accuracy: 0.4842 - auc: 0.4706 - precision: 0.0771 - recall: 0.5278 - val_loss: 0.6951 - val_accuracy: 0.5274 - val_auc: 0.3757 - val_precision: 0.0550 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1023 - accuracy: 0.5053 - auc: 0.5775 - precision: 0.0873 - recall: 0.5833 - val_loss: 0.6047 - val_accuracy: 0.9072 - val_auc: 0.5830 - val_precision: 0.1818 - val_recall: 0.1333 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8282 - accuracy: 0.5570 - auc: 0.6880 - precision: 0.1133 - recall: 0.7083 - val_loss: 0.8002 - val_accuracy: 0.0970 - val_auc: 0.4221 - val_precision: 0.0617 - val_recall: 0.9333 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6879 - accuracy: 0.5928 - auc: 0.7602 - precision: 0.1349 - recall: 0.8056 - val_loss: 0.5336 - val_accuracy: 0.9114 - val_auc: 0.6098 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7054 - accuracy: 0.6224 - auc: 0.7333 - precision: 0.1257 - recall: 0.6667 - val_loss: 0.3640 - val_accuracy: 0.9367 - val_auc: 0.4587 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5329 - accuracy: 0.6751 - auc: 0.8478 - precision: 0.1722 - recall: 0.8611 - val_loss: 0.4479 - val_accuracy: 0.9325 - val_auc: 0.5524 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4820 - accuracy: 0.7342 - auc: 0.8664 - precision: 0.2020 - recall: 0.8472 - val_loss: 0.3189 - val_accuracy: 0.9325 - val_auc: 0.4479 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5083 - accuracy: 0.7162 - auc: 0.8579 - precision: 0.1873 - recall: 0.8194 - val_loss: 0.2971 - val_accuracy: 0.9367 - val_auc: 0.5012 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.7795 - auc: 0.8742 - precision: 0.2314 - recall: 0.8194 - val_loss: 0.6068 - val_accuracy: 0.6667 - val_auc: 0.4583 - val_precision: 0.0676 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5163 - accuracy: 0.7605 - auc: 0.8417 - precision: 0.2075 - recall: 0.7639 - val_loss: 0.7475 - val_accuracy: 0.4937 - val_auc: 0.4779 - val_precision: 0.0588 - val_recall: 0.4667 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3735 - accuracy: 0.7542 - auc: 0.9190 - precision: 0.2215 - recall: 0.8889 - val_loss: 0.3456 - val_accuracy: 0.8987 - val_auc: 0.4347 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3097 - accuracy: 0.8154 - auc: 0.9457 - precision: 0.2790 - recall: 0.9028 - val_loss: 0.3582 - val_accuracy: 0.9030 - val_auc: 0.4389 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3495 - accuracy: 0.8112 - auc: 0.9265 - precision: 0.2704 - recall: 0.8750 - val_loss: 0.5247 - val_accuracy: 0.7806 - val_auc: 0.4815 - val_precision: 0.0256 - val_recall: 0.0667 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3259 - accuracy: 0.8238 - auc: 0.9332 - precision: 0.2831 - recall: 0.8611 - val_loss: 0.4417 - val_accuracy: 0.8481 - val_auc: 0.4961 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.9114 - auc: 0.6098 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 892 sequences of length 5\n",
      "X shape: (892, 5, 1968)\n",
      "y shape: (892,)\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 6s 59ms/step - loss: 1.1456 - accuracy: 0.4769 - auc: 0.5000 - precision: 0.0661 - recall: 0.5556 - val_loss: 0.6189 - val_accuracy: 0.8324 - val_auc: 0.3069 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0524 - accuracy: 0.5147 - auc: 0.6502 - precision: 0.0761 - recall: 0.6000 - val_loss: 1.0749 - val_accuracy: 0.0391 - val_auc: 0.3592 - val_precision: 0.0391 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9827 - accuracy: 0.5708 - auc: 0.6980 - precision: 0.1009 - recall: 0.7333 - val_loss: 0.9626 - val_accuracy: 0.0391 - val_auc: 0.5424 - val_precision: 0.0391 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7207 - accuracy: 0.5891 - auc: 0.7393 - precision: 0.1125 - recall: 0.8000 - val_loss: 0.6615 - val_accuracy: 0.6760 - val_auc: 0.5490 - val_precision: 0.0364 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6424 - accuracy: 0.6073 - auc: 0.8177 - precision: 0.1197 - recall: 0.8222 - val_loss: 0.5081 - val_accuracy: 0.9609 - val_auc: 0.4826 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6089 - accuracy: 0.6788 - auc: 0.8191 - precision: 0.1434 - recall: 0.8222 - val_loss: 0.5486 - val_accuracy: 0.9218 - val_auc: 0.5021 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.7069 - auc: 0.8573 - precision: 0.1555 - recall: 0.8222 - val_loss: 0.7954 - val_accuracy: 0.2235 - val_auc: 0.5797 - val_precision: 0.0417 - val_recall: 0.8571 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.7363 - auc: 0.9137 - precision: 0.1794 - recall: 0.8889 - val_loss: 0.6359 - val_accuracy: 0.7598 - val_auc: 0.5150 - val_precision: 0.0263 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4377 - accuracy: 0.7672 - auc: 0.8813 - precision: 0.1865 - recall: 0.8000 - val_loss: 0.7886 - val_accuracy: 0.4190 - val_auc: 0.5502 - val_precision: 0.0467 - val_recall: 0.7143 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3551 - accuracy: 0.7686 - auc: 0.9397 - precision: 0.2087 - recall: 0.9556 - val_loss: 0.3958 - val_accuracy: 0.9218 - val_auc: 0.4635 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.3553 - accuracy: 0.8065 - auc: 0.9280 - precision: 0.2312 - recall: 0.8889 - val_loss: 0.4367 - val_accuracy: 0.8883 - val_auc: 0.5096 - val_precision: 0.0667 - val_recall: 0.1429 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.8324 - auc: 0.3069 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3457 sequences of length 7\n",
      "X shape: (3457, 7, 1968)\n",
      "y shape: (3457,)\n",
      "Epoch 1/25\n",
      "87/87 [==============================] - 7s 22ms/step - loss: 1.2584 - accuracy: 0.5042 - auc: 0.4975 - precision: 0.0652 - recall: 0.4811 - val_loss: 0.7396 - val_accuracy: 0.3439 - val_auc: 0.5038 - val_precision: 0.0870 - val_recall: 0.7636 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.9706 - accuracy: 0.5291 - auc: 0.5647 - precision: 0.0759 - recall: 0.5405 - val_loss: 0.5903 - val_accuracy: 0.8309 - val_auc: 0.4485 - val_precision: 0.0441 - val_recall: 0.0545 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.8287 - accuracy: 0.5382 - auc: 0.5872 - precision: 0.0845 - recall: 0.6000 - val_loss: 0.3562 - val_accuracy: 0.9191 - val_auc: 0.4530 - val_precision: 0.3333 - val_recall: 0.0182 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.7289 - accuracy: 0.5722 - auc: 0.6550 - precision: 0.0950 - recall: 0.6324 - val_loss: 0.8068 - val_accuracy: 0.3598 - val_auc: 0.4407 - val_precision: 0.0764 - val_recall: 0.6364 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.6441 - accuracy: 0.6181 - auc: 0.7280 - precision: 0.1170 - recall: 0.7189 - val_loss: 0.5743 - val_accuracy: 0.7413 - val_auc: 0.4541 - val_precision: 0.0634 - val_recall: 0.1636 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.5826 - accuracy: 0.6514 - auc: 0.7684 - precision: 0.1287 - recall: 0.7297 - val_loss: 0.4255 - val_accuracy: 0.8540 - val_auc: 0.4734 - val_precision: 0.1034 - val_recall: 0.1091 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.5498 - accuracy: 0.6778 - auc: 0.7952 - precision: 0.1434 - recall: 0.7676 - val_loss: 0.8611 - val_accuracy: 0.5361 - val_auc: 0.4888 - val_precision: 0.0791 - val_recall: 0.4545 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.5285 - accuracy: 0.6951 - auc: 0.8134 - precision: 0.1485 - recall: 0.7514 - val_loss: 0.7218 - val_accuracy: 0.6445 - val_auc: 0.4870 - val_precision: 0.0866 - val_recall: 0.3636 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4822 - accuracy: 0.7071 - auc: 0.8480 - precision: 0.1600 - recall: 0.7946 - val_loss: 0.7035 - val_accuracy: 0.6590 - val_auc: 0.4944 - val_precision: 0.0751 - val_recall: 0.2909 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4378 - accuracy: 0.7219 - auc: 0.8782 - precision: 0.1734 - recall: 0.8378 - val_loss: 0.6733 - val_accuracy: 0.7038 - val_auc: 0.4956 - val_precision: 0.0690 - val_recall: 0.2182 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4110 - accuracy: 0.7454 - auc: 0.9006 - precision: 0.1900 - recall: 0.8595 - val_loss: 0.6715 - val_accuracy: 0.7168 - val_auc: 0.4892 - val_precision: 0.0727 - val_recall: 0.2182 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4195 - accuracy: 0.7740 - auc: 0.8969 - precision: 0.2120 - recall: 0.8757 - val_loss: 0.6333 - val_accuracy: 0.7558 - val_auc: 0.4867 - val_precision: 0.0746 - val_recall: 0.1818 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4061 - accuracy: 0.7722 - auc: 0.9018 - precision: 0.2076 - recall: 0.8541 - val_loss: 0.7144 - val_accuracy: 0.6503 - val_auc: 0.4862 - val_precision: 0.0691 - val_recall: 0.2727 - lr: 2.0000e-04\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.9191 - auc: 0.4530 - precision: 0.3333 - recall: 0.0182   \n",
      "Sampling from 31 games\n",
      "Created 1736 sequences of length 7\n",
      "X shape: (1736, 7, 1968)\n",
      "y shape: (1736,)\n",
      "Epoch 1/25\n",
      "44/44 [==============================] - 7s 35ms/step - loss: 1.2453 - accuracy: 0.5036 - auc: 0.5061 - precision: 0.0760 - recall: 0.4771 - val_loss: 0.3799 - val_accuracy: 0.9368 - val_auc: 0.5607 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.2586 - accuracy: 0.5166 - auc: 0.5325 - precision: 0.0843 - recall: 0.5229 - val_loss: 0.5266 - val_accuracy: 0.9368 - val_auc: 0.5600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.8821 - accuracy: 0.5317 - auc: 0.6108 - precision: 0.1016 - recall: 0.6330 - val_loss: 0.6027 - val_accuracy: 0.8908 - val_auc: 0.5310 - val_precision: 0.0556 - val_recall: 0.0455 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.5684 - auc: 0.7078 - precision: 0.1242 - recall: 0.7431 - val_loss: 0.5436 - val_accuracy: 0.9224 - val_auc: 0.5252 - val_precision: 0.1429 - val_recall: 0.0455 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6363 - accuracy: 0.6383 - auc: 0.7432 - precision: 0.1394 - recall: 0.6972 - val_loss: 0.8544 - val_accuracy: 0.2184 - val_auc: 0.5081 - val_precision: 0.0660 - val_recall: 0.8636 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6136 - accuracy: 0.6369 - auc: 0.7744 - precision: 0.1467 - recall: 0.7523 - val_loss: 0.6031 - val_accuracy: 0.6983 - val_auc: 0.5144 - val_precision: 0.0538 - val_recall: 0.2273 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4981 - accuracy: 0.6859 - auc: 0.8445 - precision: 0.1788 - recall: 0.8349 - val_loss: 0.6153 - val_accuracy: 0.6925 - val_auc: 0.5459 - val_precision: 0.0619 - val_recall: 0.2727 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4576 - accuracy: 0.7097 - auc: 0.8693 - precision: 0.1912 - recall: 0.8349 - val_loss: 0.5780 - val_accuracy: 0.7098 - val_auc: 0.5765 - val_precision: 0.0928 - val_recall: 0.4091 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.7176 - auc: 0.8932 - precision: 0.2034 - recall: 0.8899 - val_loss: 0.5723 - val_accuracy: 0.7126 - val_auc: 0.5923 - val_precision: 0.0761 - val_recall: 0.3182 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.7248 - auc: 0.8707 - precision: 0.1960 - recall: 0.8073 - val_loss: 0.5919 - val_accuracy: 0.7069 - val_auc: 0.5884 - val_precision: 0.0833 - val_recall: 0.3636 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.7565 - auc: 0.8999 - precision: 0.2306 - recall: 0.8991 - val_loss: 0.6166 - val_accuracy: 0.6954 - val_auc: 0.6140 - val_precision: 0.0714 - val_recall: 0.3182 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.9368 - auc: 0.5607 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1161 sequences of length 7\n",
      "X shape: (1161, 7, 1968)\n",
      "y shape: (1161,)\n",
      "Epoch 1/25\n",
      "29/29 [==============================] - 6s 48ms/step - loss: 1.1548 - accuracy: 0.5054 - auc: 0.5396 - precision: 0.0681 - recall: 0.6038 - val_loss: 0.7704 - val_accuracy: 0.1760 - val_auc: 0.5417 - val_precision: 0.0732 - val_recall: 0.8824 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.0546 - accuracy: 0.5054 - auc: 0.6048 - precision: 0.0735 - recall: 0.6604 - val_loss: 0.3447 - val_accuracy: 0.9270 - val_auc: 0.4318 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.0047 - accuracy: 0.5668 - auc: 0.6602 - precision: 0.0875 - recall: 0.6981 - val_loss: 0.9581 - val_accuracy: 0.0773 - val_auc: 0.4943 - val_precision: 0.0733 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8666 - accuracy: 0.5765 - auc: 0.7097 - precision: 0.0952 - recall: 0.7547 - val_loss: 0.6906 - val_accuracy: 0.4936 - val_auc: 0.4834 - val_precision: 0.0609 - val_recall: 0.4118 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.6369 - auc: 0.8055 - precision: 0.1162 - recall: 0.8113 - val_loss: 0.3050 - val_accuracy: 0.9270 - val_auc: 0.4888 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6418 - accuracy: 0.6595 - auc: 0.7729 - precision: 0.1121 - recall: 0.7170 - val_loss: 0.4405 - val_accuracy: 0.9270 - val_auc: 0.4921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5255 - accuracy: 0.6875 - auc: 0.8494 - precision: 0.1354 - recall: 0.8302 - val_loss: 0.4881 - val_accuracy: 0.9142 - val_auc: 0.6510 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4500 - accuracy: 0.7371 - auc: 0.8865 - precision: 0.1649 - recall: 0.8868 - val_loss: 0.5894 - val_accuracy: 0.7039 - val_auc: 0.5534 - val_precision: 0.0667 - val_recall: 0.2353 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.7489 - auc: 0.8778 - precision: 0.1642 - recall: 0.8302 - val_loss: 0.5655 - val_accuracy: 0.8412 - val_auc: 0.5836 - val_precision: 0.2059 - val_recall: 0.4118 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3746 - accuracy: 0.7522 - auc: 0.9219 - precision: 0.1758 - recall: 0.9057 - val_loss: 0.3063 - val_accuracy: 0.9270 - val_auc: 0.3883 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2853 - accuracy: 0.8330 - auc: 0.9603 - precision: 0.2524 - recall: 0.9811 - val_loss: 0.3318 - val_accuracy: 0.9142 - val_auc: 0.4001 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3146 - accuracy: 0.7996 - auc: 0.9462 - precision: 0.2096 - recall: 0.9057 - val_loss: 0.3752 - val_accuracy: 0.8884 - val_auc: 0.3818 - val_precision: 0.0909 - val_recall: 0.0588 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.9270 - auc: 0.4318 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 875 sequences of length 7\n",
      "X shape: (875, 7, 1968)\n",
      "y shape: (875,)\n",
      "Epoch 1/25\n",
      "22/22 [==============================] - 6s 62ms/step - loss: 1.0271 - accuracy: 0.5143 - auc: 0.5270 - precision: 0.1017 - recall: 0.5303 - val_loss: 0.5714 - val_accuracy: 0.9143 - val_auc: 0.5286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1367 - accuracy: 0.4986 - auc: 0.5318 - precision: 0.0963 - recall: 0.5152 - val_loss: 0.5741 - val_accuracy: 0.9200 - val_auc: 0.4896 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8806 - accuracy: 0.5457 - auc: 0.6799 - precision: 0.1400 - recall: 0.7424 - val_loss: 0.4364 - val_accuracy: 0.9200 - val_auc: 0.4592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7726 - accuracy: 0.5729 - auc: 0.7202 - precision: 0.1459 - recall: 0.7273 - val_loss: 0.4314 - val_accuracy: 0.9200 - val_auc: 0.4900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7078 - accuracy: 0.6357 - auc: 0.7298 - precision: 0.1684 - recall: 0.7273 - val_loss: 0.3326 - val_accuracy: 0.9200 - val_auc: 0.5342 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7212 - accuracy: 0.6186 - auc: 0.7459 - precision: 0.1705 - recall: 0.7879 - val_loss: 0.2826 - val_accuracy: 0.9200 - val_auc: 0.4068 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6531 - accuracy: 0.6586 - auc: 0.7788 - precision: 0.1855 - recall: 0.7727 - val_loss: 0.2871 - val_accuracy: 0.9200 - val_auc: 0.5308 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.6886 - auc: 0.8274 - precision: 0.2099 - recall: 0.8333 - val_loss: 0.2892 - val_accuracy: 0.9200 - val_auc: 0.4399 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5237 - accuracy: 0.7357 - auc: 0.8457 - precision: 0.2379 - recall: 0.8182 - val_loss: 0.3212 - val_accuracy: 0.9200 - val_auc: 0.3824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.7329 - auc: 0.8978 - precision: 0.2447 - recall: 0.8788 - val_loss: 0.5755 - val_accuracy: 0.8114 - val_auc: 0.4494 - val_precision: 0.0870 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4172 - accuracy: 0.7471 - auc: 0.8913 - precision: 0.2442 - recall: 0.8030 - val_loss: 0.3827 - val_accuracy: 0.9200 - val_auc: 0.4366 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.9143 - auc: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3395 sequences of length 9\n",
      "X shape: (3395, 9, 1968)\n",
      "y shape: (3395,)\n",
      "Epoch 1/25\n",
      "85/85 [==============================] - 7s 23ms/step - loss: 1.2294 - accuracy: 0.5099 - auc: 0.5077 - precision: 0.0754 - recall: 0.5206 - val_loss: 1.1460 - val_accuracy: 0.0619 - val_auc: 0.4783 - val_precision: 0.0619 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 1.0229 - accuracy: 0.5099 - auc: 0.4990 - precision: 0.0748 - recall: 0.5155 - val_loss: 1.1356 - val_accuracy: 0.0766 - val_auc: 0.4722 - val_precision: 0.0615 - val_recall: 0.9762 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.7588 - accuracy: 0.5346 - auc: 0.6353 - precision: 0.0983 - recall: 0.6753 - val_loss: 0.4102 - val_accuracy: 0.9367 - val_auc: 0.5069 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.6890 - accuracy: 0.5777 - auc: 0.6784 - precision: 0.1085 - recall: 0.6804 - val_loss: 0.4845 - val_accuracy: 0.8719 - val_auc: 0.5133 - val_precision: 0.0588 - val_recall: 0.0714 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.6403 - accuracy: 0.6241 - auc: 0.7253 - precision: 0.1251 - recall: 0.7113 - val_loss: 0.5371 - val_accuracy: 0.7923 - val_auc: 0.5042 - val_precision: 0.0840 - val_recall: 0.2381 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.6039 - accuracy: 0.6421 - auc: 0.7535 - precision: 0.1302 - recall: 0.7062 - val_loss: 0.5756 - val_accuracy: 0.7084 - val_auc: 0.5593 - val_precision: 0.0568 - val_recall: 0.2381 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.5344 - accuracy: 0.6657 - auc: 0.8082 - precision: 0.1486 - recall: 0.7784 - val_loss: 0.6484 - val_accuracy: 0.7128 - val_auc: 0.5490 - val_precision: 0.0629 - val_recall: 0.2619 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.5214 - accuracy: 0.6988 - auc: 0.8200 - precision: 0.1660 - recall: 0.7990 - val_loss: 0.5894 - val_accuracy: 0.7865 - val_auc: 0.5804 - val_precision: 0.1008 - val_recall: 0.3095 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.4511 - accuracy: 0.7364 - auc: 0.8699 - precision: 0.1893 - recall: 0.8196 - val_loss: 0.7251 - val_accuracy: 0.7158 - val_auc: 0.5668 - val_precision: 0.0919 - val_recall: 0.4048 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.3999 - accuracy: 0.7246 - auc: 0.9120 - precision: 0.1936 - recall: 0.9021 - val_loss: 0.7147 - val_accuracy: 0.7158 - val_auc: 0.5687 - val_precision: 0.0874 - val_recall: 0.3810 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.3867 - accuracy: 0.7636 - auc: 0.9142 - precision: 0.2157 - recall: 0.8763 - val_loss: 0.7731 - val_accuracy: 0.6937 - val_auc: 0.5640 - val_precision: 0.0808 - val_recall: 0.3810 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.3889 - accuracy: 0.7717 - auc: 0.9113 - precision: 0.2234 - recall: 0.8866 - val_loss: 0.7649 - val_accuracy: 0.6613 - val_auc: 0.5755 - val_precision: 0.0841 - val_recall: 0.4524 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.3626 - accuracy: 0.7920 - auc: 0.9265 - precision: 0.2420 - recall: 0.8969 - val_loss: 0.7909 - val_accuracy: 0.6613 - val_auc: 0.5616 - val_precision: 0.0877 - val_recall: 0.4762 - lr: 2.0000e-04\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.9367 - auc: 0.5069 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1705 sequences of length 9\n",
      "X shape: (1705, 9, 1968)\n",
      "y shape: (1705,)\n",
      "Epoch 1/25\n",
      "43/43 [==============================] - 7s 36ms/step - loss: 1.2119 - accuracy: 0.5044 - auc: 0.5289 - precision: 0.0729 - recall: 0.5556 - val_loss: 0.4754 - val_accuracy: 0.8856 - val_auc: 0.4965 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 1.2638 - accuracy: 0.5073 - auc: 0.5185 - precision: 0.0670 - recall: 0.5000 - val_loss: 0.4950 - val_accuracy: 0.8856 - val_auc: 0.5087 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.8990 - accuracy: 0.5638 - auc: 0.6593 - precision: 0.0973 - recall: 0.6778 - val_loss: 0.5795 - val_accuracy: 0.8622 - val_auc: 0.5021 - val_precision: 0.2143 - val_recall: 0.0769 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.7509 - accuracy: 0.5821 - auc: 0.6993 - precision: 0.1053 - recall: 0.7111 - val_loss: 0.3743 - val_accuracy: 0.8856 - val_auc: 0.4842 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.6356 - auc: 0.7351 - precision: 0.1224 - recall: 0.7333 - val_loss: 0.3747 - val_accuracy: 0.8768 - val_auc: 0.5538 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5738 - accuracy: 0.6408 - auc: 0.7943 - precision: 0.1296 - recall: 0.7778 - val_loss: 0.5769 - val_accuracy: 0.7478 - val_auc: 0.4800 - val_precision: 0.0392 - val_recall: 0.0513 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5518 - accuracy: 0.6921 - auc: 0.8305 - precision: 0.1534 - recall: 0.8111 - val_loss: 1.0010 - val_accuracy: 0.2287 - val_auc: 0.5631 - val_precision: 0.1190 - val_recall: 0.8974 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4819 - accuracy: 0.7082 - auc: 0.8537 - precision: 0.1652 - recall: 0.8444 - val_loss: 0.6194 - val_accuracy: 0.6804 - val_auc: 0.5340 - val_precision: 0.1429 - val_recall: 0.3590 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.7573 - auc: 0.9001 - precision: 0.2010 - recall: 0.9000 - val_loss: 0.5009 - val_accuracy: 0.8094 - val_auc: 0.5263 - val_precision: 0.0938 - val_recall: 0.0769 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3495 - accuracy: 0.7911 - auc: 0.9306 - precision: 0.2254 - recall: 0.8889 - val_loss: 0.5115 - val_accuracy: 0.7947 - val_auc: 0.5183 - val_precision: 0.0811 - val_recall: 0.0769 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2975 - accuracy: 0.8226 - auc: 0.9592 - precision: 0.2654 - recall: 0.9556 - val_loss: 0.5706 - val_accuracy: 0.7654 - val_auc: 0.5282 - val_precision: 0.1273 - val_recall: 0.1795 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.8856 - auc: 0.4965 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1142 sequences of length 9\n",
      "X shape: (1142, 9, 1968)\n",
      "y shape: (1142,)\n",
      "Epoch 1/25\n",
      "29/29 [==============================] - 6s 49ms/step - loss: 1.1133 - accuracy: 0.5225 - auc: 0.5497 - precision: 0.0893 - recall: 0.5882 - val_loss: 0.5106 - val_accuracy: 0.9301 - val_auc: 0.4849 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1381 - accuracy: 0.5400 - auc: 0.5804 - precision: 0.0963 - recall: 0.6176 - val_loss: 0.8035 - val_accuracy: 0.1135 - val_auc: 0.5518 - val_precision: 0.0731 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9462 - accuracy: 0.5608 - auc: 0.6363 - precision: 0.1026 - recall: 0.6324 - val_loss: 0.8494 - val_accuracy: 0.0699 - val_auc: 0.5257 - val_precision: 0.0699 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7506 - accuracy: 0.5827 - auc: 0.7211 - precision: 0.1229 - recall: 0.7500 - val_loss: 0.5201 - val_accuracy: 0.9301 - val_auc: 0.4410 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7238 - accuracy: 0.6177 - auc: 0.7157 - precision: 0.1233 - recall: 0.6765 - val_loss: 0.7487 - val_accuracy: 0.2009 - val_auc: 0.5646 - val_precision: 0.0718 - val_recall: 0.8750 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6575 - accuracy: 0.6243 - auc: 0.7516 - precision: 0.1333 - recall: 0.7353 - val_loss: 0.5166 - val_accuracy: 0.9258 - val_auc: 0.4434 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4483 - accuracy: 0.6813 - auc: 0.8870 - precision: 0.1805 - recall: 0.9265 - val_loss: 0.4874 - val_accuracy: 0.9345 - val_auc: 0.4366 - val_precision: 1.0000 - val_recall: 0.0625 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.6922 - auc: 0.8779 - precision: 0.1858 - recall: 0.9265 - val_loss: 0.5184 - val_accuracy: 0.9039 - val_auc: 0.4020 - val_precision: 0.1250 - val_recall: 0.0625 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4278 - accuracy: 0.7065 - auc: 0.8968 - precision: 0.1914 - recall: 0.9118 - val_loss: 0.5159 - val_accuracy: 0.8908 - val_auc: 0.4993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4262 - accuracy: 0.7163 - auc: 0.8926 - precision: 0.1909 - recall: 0.8676 - val_loss: 0.4690 - val_accuracy: 0.9039 - val_auc: 0.4756 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4267 - accuracy: 0.7174 - auc: 0.8994 - precision: 0.1935 - recall: 0.8824 - val_loss: 0.4674 - val_accuracy: 0.8777 - val_auc: 0.4893 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.9301 - auc: 0.4849 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 861 sequences of length 9\n",
      "X shape: (861, 9, 1968)\n",
      "y shape: (861,)\n",
      "Epoch 1/25\n",
      "22/22 [==============================] - 6s 62ms/step - loss: 1.1536 - accuracy: 0.5218 - auc: 0.5311 - precision: 0.0682 - recall: 0.6053 - val_loss: 0.4822 - val_accuracy: 0.9249 - val_auc: 0.5978 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9730 - accuracy: 0.5392 - auc: 0.6371 - precision: 0.0811 - recall: 0.7105 - val_loss: 0.7297 - val_accuracy: 0.3815 - val_auc: 0.4767 - val_precision: 0.0727 - val_recall: 0.6154 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9437 - accuracy: 0.5509 - auc: 0.7384 - precision: 0.0831 - recall: 0.7105 - val_loss: 1.0619 - val_accuracy: 0.0751 - val_auc: 0.4377 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6382 - accuracy: 0.5814 - auc: 0.8247 - precision: 0.1094 - recall: 0.9211 - val_loss: 0.5603 - val_accuracy: 0.9133 - val_auc: 0.4591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5395 - accuracy: 0.6541 - auc: 0.8626 - precision: 0.1241 - recall: 0.8684 - val_loss: 0.4850 - val_accuracy: 0.9191 - val_auc: 0.4303 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5287 - accuracy: 0.6802 - auc: 0.8807 - precision: 0.1301 - recall: 0.8421 - val_loss: 0.7084 - val_accuracy: 0.5087 - val_auc: 0.4736 - val_precision: 0.0909 - val_recall: 0.6154 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4198 - accuracy: 0.7209 - auc: 0.9186 - precision: 0.1593 - recall: 0.9474 - val_loss: 0.5402 - val_accuracy: 0.8150 - val_auc: 0.4577 - val_precision: 0.0870 - val_recall: 0.1538 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3774 - accuracy: 0.7282 - auc: 0.9249 - precision: 0.1567 - recall: 0.8947 - val_loss: 0.5707 - val_accuracy: 0.7630 - val_auc: 0.5010 - val_precision: 0.0882 - val_recall: 0.2308 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3349 - accuracy: 0.7776 - auc: 0.9464 - precision: 0.1892 - recall: 0.9211 - val_loss: 0.5505 - val_accuracy: 0.7977 - val_auc: 0.4043 - val_precision: 0.0769 - val_recall: 0.1538 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3380 - accuracy: 0.7863 - auc: 0.9470 - precision: 0.1989 - recall: 0.9474 - val_loss: 0.5363 - val_accuracy: 0.8150 - val_auc: 0.4091 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3411 - accuracy: 0.7689 - auc: 0.9382 - precision: 0.1799 - recall: 0.8947 - val_loss: 0.6554 - val_accuracy: 0.6647 - val_auc: 0.3945 - val_precision: 0.0588 - val_recall: 0.2308 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.9249 - auc: 0.5978 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3333 sequences of length 11\n",
      "X shape: (3333, 11, 1968)\n",
      "y shape: (3333,)\n",
      "Epoch 1/25\n",
      "84/84 [==============================] - 7s 23ms/step - loss: 1.2620 - accuracy: 0.5128 - auc: 0.5144 - precision: 0.0714 - recall: 0.5082 - val_loss: 0.7951 - val_accuracy: 0.0945 - val_auc: 0.4630 - val_precision: 0.0668 - val_recall: 0.9348 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.0713 - accuracy: 0.5165 - auc: 0.5109 - precision: 0.0733 - recall: 0.5191 - val_loss: 0.7255 - val_accuracy: 0.3418 - val_auc: 0.5497 - val_precision: 0.0810 - val_recall: 0.8261 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.8589 - accuracy: 0.5236 - auc: 0.5800 - precision: 0.0810 - recall: 0.5738 - val_loss: 0.5492 - val_accuracy: 0.8216 - val_auc: 0.5306 - val_precision: 0.0899 - val_recall: 0.1739 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.6471 - accuracy: 0.5923 - auc: 0.7322 - precision: 0.1143 - recall: 0.7322 - val_loss: 0.6853 - val_accuracy: 0.5382 - val_auc: 0.5534 - val_precision: 0.0828 - val_recall: 0.5652 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.5887 - accuracy: 0.6403 - auc: 0.7708 - precision: 0.1326 - recall: 0.7650 - val_loss: 0.5989 - val_accuracy: 0.6852 - val_auc: 0.5331 - val_precision: 0.0638 - val_recall: 0.2609 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.5120 - accuracy: 0.6905 - auc: 0.8273 - precision: 0.1578 - recall: 0.8087 - val_loss: 0.5847 - val_accuracy: 0.7121 - val_auc: 0.5341 - val_precision: 0.0655 - val_recall: 0.2391 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4632 - accuracy: 0.7243 - auc: 0.8630 - precision: 0.1798 - recall: 0.8470 - val_loss: 0.6785 - val_accuracy: 0.6507 - val_auc: 0.5172 - val_precision: 0.0610 - val_recall: 0.2826 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4685 - accuracy: 0.7449 - auc: 0.8638 - precision: 0.1928 - recall: 0.8525 - val_loss: 0.9373 - val_accuracy: 0.5562 - val_auc: 0.4887 - val_precision: 0.0660 - val_recall: 0.4130 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4274 - accuracy: 0.7607 - auc: 0.8857 - precision: 0.2034 - recall: 0.8525 - val_loss: 0.6446 - val_accuracy: 0.7106 - val_auc: 0.4784 - val_precision: 0.0491 - val_recall: 0.1739 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3635 - accuracy: 0.7843 - auc: 0.9249 - precision: 0.2300 - recall: 0.9126 - val_loss: 0.5919 - val_accuracy: 0.7376 - val_auc: 0.5069 - val_precision: 0.0490 - val_recall: 0.1522 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3609 - accuracy: 0.7926 - auc: 0.9229 - precision: 0.2319 - recall: 0.8743 - val_loss: 0.6036 - val_accuracy: 0.7331 - val_auc: 0.5266 - val_precision: 0.0658 - val_recall: 0.2174 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.8151 - auc: 0.9364 - precision: 0.2601 - recall: 0.9180 - val_loss: 0.6567 - val_accuracy: 0.7061 - val_auc: 0.5173 - val_precision: 0.0536 - val_recall: 0.1957 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3379 - accuracy: 0.8147 - auc: 0.9345 - precision: 0.2574 - recall: 0.9016 - val_loss: 0.6221 - val_accuracy: 0.7316 - val_auc: 0.5310 - val_precision: 0.0710 - val_recall: 0.2391 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3230 - accuracy: 0.8241 - auc: 0.9399 - precision: 0.2656 - recall: 0.8852 - val_loss: 0.6499 - val_accuracy: 0.7151 - val_auc: 0.5322 - val_precision: 0.0663 - val_recall: 0.2391 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.2990 - accuracy: 0.8290 - auc: 0.9527 - precision: 0.2788 - recall: 0.9399 - val_loss: 0.5987 - val_accuracy: 0.7466 - val_auc: 0.5282 - val_precision: 0.0699 - val_recall: 0.2174 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.8271 - auc: 0.9442 - precision: 0.2729 - recall: 0.9126 - val_loss: 0.6651 - val_accuracy: 0.7091 - val_auc: 0.5288 - val_precision: 0.0698 - val_recall: 0.2609 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2917 - accuracy: 0.8387 - auc: 0.9542 - precision: 0.2896 - recall: 0.9290 - val_loss: 0.5934 - val_accuracy: 0.7601 - val_auc: 0.5256 - val_precision: 0.0682 - val_recall: 0.1957 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2947 - accuracy: 0.8447 - auc: 0.9515 - precision: 0.2991 - recall: 0.9399 - val_loss: 0.6095 - val_accuracy: 0.7451 - val_auc: 0.5317 - val_precision: 0.0694 - val_recall: 0.2174 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2772 - accuracy: 0.8432 - auc: 0.9598 - precision: 0.2991 - recall: 0.9563 - val_loss: 0.5661 - val_accuracy: 0.7766 - val_auc: 0.5370 - val_precision: 0.0672 - val_recall: 0.1739 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.2703 - accuracy: 0.8631 - auc: 0.9606 - precision: 0.3277 - recall: 0.9454 - val_loss: 0.6025 - val_accuracy: 0.7541 - val_auc: 0.5320 - val_precision: 0.0662 - val_recall: 0.1957 - lr: 1.0000e-04\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7376 - auc: 0.5069 - precision: 0.0490 - recall: 0.1522   \n",
      "Sampling from 31 games\n",
      "Created 1674 sequences of length 11\n",
      "X shape: (1674, 11, 1968)\n",
      "y shape: (1674,)\n",
      "Epoch 1/25\n",
      "42/42 [==============================] - 7s 37ms/step - loss: 1.2206 - accuracy: 0.5049 - auc: 0.5458 - precision: 0.0783 - recall: 0.5761 - val_loss: 0.7580 - val_accuracy: 0.1761 - val_auc: 0.4737 - val_precision: 0.0990 - val_recall: 0.9091 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1910 - accuracy: 0.5123 - auc: 0.5337 - precision: 0.0718 - recall: 0.5109 - val_loss: 0.5617 - val_accuracy: 0.9015 - val_auc: 0.4927 - val_precision: 0.5000 - val_recall: 0.0606 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.8541 - accuracy: 0.5422 - auc: 0.6715 - precision: 0.0923 - recall: 0.6413 - val_loss: 0.5842 - val_accuracy: 0.8955 - val_auc: 0.5492 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.7299 - accuracy: 0.5930 - auc: 0.7248 - precision: 0.1154 - recall: 0.7391 - val_loss: 0.4216 - val_accuracy: 0.9015 - val_auc: 0.6218 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6713 - accuracy: 0.6460 - auc: 0.7541 - precision: 0.1284 - recall: 0.7174 - val_loss: 0.3954 - val_accuracy: 0.9015 - val_auc: 0.5261 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.5957 - accuracy: 0.6639 - auc: 0.7955 - precision: 0.1406 - recall: 0.7609 - val_loss: 0.3715 - val_accuracy: 0.8925 - val_auc: 0.5685 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.5264 - accuracy: 0.6878 - auc: 0.8351 - precision: 0.1576 - recall: 0.8152 - val_loss: 0.7422 - val_accuracy: 0.3910 - val_auc: 0.4283 - val_precision: 0.0746 - val_recall: 0.4545 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4856 - accuracy: 0.7237 - auc: 0.8568 - precision: 0.1752 - recall: 0.8152 - val_loss: 0.8233 - val_accuracy: 0.4209 - val_auc: 0.5187 - val_precision: 0.1073 - val_recall: 0.6667 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4217 - accuracy: 0.7401 - auc: 0.8954 - precision: 0.1938 - recall: 0.8804 - val_loss: 1.1049 - val_accuracy: 0.2806 - val_auc: 0.5003 - val_precision: 0.1000 - val_recall: 0.7879 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.7685 - auc: 0.8819 - precision: 0.2038 - recall: 0.8152 - val_loss: 1.0717 - val_accuracy: 0.3343 - val_auc: 0.4915 - val_precision: 0.0940 - val_recall: 0.6667 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3419 - accuracy: 0.7834 - auc: 0.9353 - precision: 0.2280 - recall: 0.9022 - val_loss: 0.6105 - val_accuracy: 0.6985 - val_auc: 0.5186 - val_precision: 0.1047 - val_recall: 0.2727 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3272 - accuracy: 0.8432 - auc: 0.9363 - precision: 0.2862 - recall: 0.8587 - val_loss: 0.7104 - val_accuracy: 0.6209 - val_auc: 0.5089 - val_precision: 0.1148 - val_recall: 0.4242 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3644 - accuracy: 0.8111 - auc: 0.9171 - precision: 0.2461 - recall: 0.8478 - val_loss: 0.8061 - val_accuracy: 0.5731 - val_auc: 0.5158 - val_precision: 0.1127 - val_recall: 0.4848 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.8955 - auc: 0.5492 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1123 sequences of length 11\n",
      "X shape: (1123, 11, 1968)\n",
      "y shape: (1123,)\n",
      "Epoch 1/25\n",
      "29/29 [==============================] - 9s 51ms/step - loss: 1.0369 - accuracy: 0.5212 - auc: 0.5595 - precision: 0.0923 - recall: 0.6029 - val_loss: 0.6117 - val_accuracy: 0.8756 - val_auc: 0.4888 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0695 - accuracy: 0.5546 - auc: 0.6305 - precision: 0.1103 - recall: 0.6912 - val_loss: 0.5410 - val_accuracy: 0.9289 - val_auc: 0.5206 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9363 - accuracy: 0.5802 - auc: 0.6845 - precision: 0.1128 - recall: 0.6618 - val_loss: 0.6476 - val_accuracy: 0.7156 - val_auc: 0.5112 - val_precision: 0.0556 - val_recall: 0.1875 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7730 - accuracy: 0.6169 - auc: 0.7171 - precision: 0.1250 - recall: 0.6765 - val_loss: 0.3103 - val_accuracy: 0.9289 - val_auc: 0.4824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6513 - accuracy: 0.6473 - auc: 0.7867 - precision: 0.1453 - recall: 0.7612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 26ms/step - loss: 0.6502 - accuracy: 0.6481 - auc: 0.7892 - precision: 0.1477 - recall: 0.7647 - val_loss: 0.2804 - val_accuracy: 0.9289 - val_auc: 0.5378 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5678 - accuracy: 0.6804 - auc: 0.8299 - precision: 0.1712 - recall: 0.8382 - val_loss: 0.6151 - val_accuracy: 0.8000 - val_auc: 0.4557 - val_precision: 0.0606 - val_recall: 0.1250 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5322 - accuracy: 0.7082 - auc: 0.8388 - precision: 0.1745 - recall: 0.7647 - val_loss: 1.7191 - val_accuracy: 0.0711 - val_auc: 0.4993 - val_precision: 0.0711 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5115 - accuracy: 0.6748 - auc: 0.8663 - precision: 0.1706 - recall: 0.8529 - val_loss: 0.4370 - val_accuracy: 0.9156 - val_auc: 0.4252 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4584 - accuracy: 0.7127 - auc: 0.8848 - precision: 0.1895 - recall: 0.8529 - val_loss: 0.7449 - val_accuracy: 0.4311 - val_auc: 0.4572 - val_precision: 0.0882 - val_recall: 0.7500 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4488 - accuracy: 0.7350 - auc: 0.8972 - precision: 0.2049 - recall: 0.8676 - val_loss: 0.5569 - val_accuracy: 0.7289 - val_auc: 0.5404 - val_precision: 0.0408 - val_recall: 0.1250 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.3540 - accuracy: 0.7717 - auc: 0.9317 - precision: 0.2355 - recall: 0.8971 - val_loss: 0.4637 - val_accuracy: 0.8267 - val_auc: 0.5223 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.8756 - auc: 0.4888 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 844 sequences of length 11\n",
      "X shape: (844, 11, 1968)\n",
      "y shape: (844,)\n",
      "Epoch 1/25\n",
      "22/22 [==============================] - 6s 63ms/step - loss: 1.0992 - accuracy: 0.4681 - auc: 0.4972 - precision: 0.0914 - recall: 0.5156 - val_loss: 0.6838 - val_accuracy: 0.5621 - val_auc: 0.4604 - val_precision: 0.0588 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.8834 - accuracy: 0.5481 - auc: 0.6947 - precision: 0.1445 - recall: 0.7656 - val_loss: 0.7006 - val_accuracy: 0.4615 - val_auc: 0.4694 - val_precision: 0.0575 - val_recall: 0.3571 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.9537 - accuracy: 0.5793 - auc: 0.6773 - precision: 0.1497 - recall: 0.7344 - val_loss: 0.5951 - val_accuracy: 0.9112 - val_auc: 0.4933 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7938 - accuracy: 0.5956 - auc: 0.6990 - precision: 0.1409 - recall: 0.6406 - val_loss: 0.8045 - val_accuracy: 0.1302 - val_auc: 0.4793 - val_precision: 0.0764 - val_recall: 0.8571 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7019 - accuracy: 0.6444 - auc: 0.7516 - precision: 0.1716 - recall: 0.7188 - val_loss: 0.4840 - val_accuracy: 0.9172 - val_auc: 0.4666 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5650 - accuracy: 0.6504 - auc: 0.8240 - precision: 0.1972 - recall: 0.8750 - val_loss: 0.3531 - val_accuracy: 0.9172 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4809 - accuracy: 0.7037 - auc: 0.8737 - precision: 0.2258 - recall: 0.8750 - val_loss: 0.4114 - val_accuracy: 0.9172 - val_auc: 0.5240 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4187 - accuracy: 0.7363 - auc: 0.9076 - precision: 0.2478 - recall: 0.8750 - val_loss: 0.3280 - val_accuracy: 0.9172 - val_auc: 0.5459 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.7585 - auc: 0.8921 - precision: 0.2632 - recall: 0.8594 - val_loss: 0.3015 - val_accuracy: 0.9172 - val_auc: 0.5168 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.7630 - auc: 0.9075 - precision: 0.2670 - recall: 0.8594 - val_loss: 0.3537 - val_accuracy: 0.9172 - val_auc: 0.5410 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3581 - accuracy: 0.8193 - auc: 0.9248 - precision: 0.3232 - recall: 0.8281 - val_loss: 0.3106 - val_accuracy: 0.9172 - val_auc: 0.4800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.2630 - accuracy: 0.8370 - auc: 0.9658 - precision: 0.3598 - recall: 0.9219 - val_loss: 0.3404 - val_accuracy: 0.9112 - val_auc: 0.5677 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.2271 - accuracy: 0.8430 - auc: 0.9766 - precision: 0.3704 - recall: 0.9375 - val_loss: 0.3050 - val_accuracy: 0.9112 - val_auc: 0.4970 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.9112 - auc: 0.4933 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3271 sequences of length 13\n",
      "X shape: (3271, 13, 1968)\n",
      "y shape: (3271,)\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 7s 24ms/step - loss: 1.1466 - accuracy: 0.5092 - auc: 0.5617 - precision: 0.0791 - recall: 0.5876 - val_loss: 0.9122 - val_accuracy: 0.0687 - val_auc: 0.5493 - val_precision: 0.0687 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 1.0701 - accuracy: 0.5619 - auc: 0.5803 - precision: 0.0834 - recall: 0.5480 - val_loss: 0.4111 - val_accuracy: 0.9313 - val_auc: 0.4377 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.8957 - accuracy: 0.5646 - auc: 0.5999 - precision: 0.0882 - recall: 0.5819 - val_loss: 0.3693 - val_accuracy: 0.9313 - val_auc: 0.4541 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7346 - accuracy: 0.5845 - auc: 0.6603 - precision: 0.1023 - recall: 0.6610 - val_loss: 0.6684 - val_accuracy: 0.5802 - val_auc: 0.5000 - val_precision: 0.0611 - val_recall: 0.3556 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6427 - accuracy: 0.6067 - auc: 0.7272 - precision: 0.1120 - recall: 0.6949 - val_loss: 0.3440 - val_accuracy: 0.9084 - val_auc: 0.5776 - val_precision: 0.2000 - val_recall: 0.1111 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5276 - accuracy: 0.6820 - auc: 0.8205 - precision: 0.1549 - recall: 0.8305 - val_loss: 0.5986 - val_accuracy: 0.7405 - val_auc: 0.4838 - val_precision: 0.0915 - val_recall: 0.3111 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5272 - accuracy: 0.6938 - auc: 0.8191 - precision: 0.1556 - recall: 0.7966 - val_loss: 0.5515 - val_accuracy: 0.8031 - val_auc: 0.4981 - val_precision: 0.0882 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5017 - accuracy: 0.7179 - auc: 0.8387 - precision: 0.1657 - recall: 0.7853 - val_loss: 0.9160 - val_accuracy: 0.5542 - val_auc: 0.4845 - val_precision: 0.0573 - val_recall: 0.3556 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4866 - accuracy: 0.7164 - auc: 0.8462 - precision: 0.1688 - recall: 0.8136 - val_loss: 0.8363 - val_accuracy: 0.5786 - val_auc: 0.5109 - val_precision: 0.0674 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4498 - accuracy: 0.7592 - auc: 0.8713 - precision: 0.1976 - recall: 0.8362 - val_loss: 0.6158 - val_accuracy: 0.7588 - val_auc: 0.5182 - val_precision: 0.0935 - val_recall: 0.2889 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3712 - accuracy: 0.7844 - auc: 0.9183 - precision: 0.2240 - recall: 0.8870 - val_loss: 0.6140 - val_accuracy: 0.7389 - val_auc: 0.5190 - val_precision: 0.0685 - val_recall: 0.2222 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3440 - accuracy: 0.8001 - auc: 0.9347 - precision: 0.2426 - recall: 0.9209 - val_loss: 0.5952 - val_accuracy: 0.7634 - val_auc: 0.5258 - val_precision: 0.0896 - val_recall: 0.2667 - lr: 2.0000e-04\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.9313 - auc: 0.4377 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1643 sequences of length 13\n",
      "X shape: (1643, 13, 1968)\n",
      "y shape: (1643,)\n",
      "Epoch 1/25\n",
      "42/42 [==============================] - 7s 37ms/step - loss: 1.2795 - accuracy: 0.4962 - auc: 0.4827 - precision: 0.0653 - recall: 0.4831 - val_loss: 0.4641 - val_accuracy: 0.9088 - val_auc: 0.5897 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1723 - accuracy: 0.5152 - auc: 0.5691 - precision: 0.0772 - recall: 0.5618 - val_loss: 0.9222 - val_accuracy: 0.0912 - val_auc: 0.4849 - val_precision: 0.0912 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.9822 - accuracy: 0.5616 - auc: 0.6124 - precision: 0.0921 - recall: 0.6180 - val_loss: 0.8474 - val_accuracy: 0.1611 - val_auc: 0.5132 - val_precision: 0.0900 - val_recall: 0.9000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.7512 - accuracy: 0.5875 - auc: 0.7121 - precision: 0.1115 - recall: 0.7303 - val_loss: 0.4896 - val_accuracy: 0.8419 - val_auc: 0.5858 - val_precision: 0.1562 - val_recall: 0.1667 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6986 - accuracy: 0.6134 - auc: 0.7185 - precision: 0.1113 - recall: 0.6742 - val_loss: 0.5001 - val_accuracy: 0.8267 - val_auc: 0.5212 - val_precision: 0.0345 - val_recall: 0.0333 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6498 - accuracy: 0.6324 - auc: 0.7626 - precision: 0.1212 - recall: 0.7079 - val_loss: 1.9896 - val_accuracy: 0.0912 - val_auc: 0.3668 - val_precision: 0.0912 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.5001 - accuracy: 0.6781 - auc: 0.8521 - precision: 0.1592 - recall: 0.8764 - val_loss: 1.4853 - val_accuracy: 0.1246 - val_auc: 0.3668 - val_precision: 0.0892 - val_recall: 0.9333 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4444 - accuracy: 0.6948 - auc: 0.8819 - precision: 0.1652 - recall: 0.8652 - val_loss: 1.1262 - val_accuracy: 0.1976 - val_auc: 0.3546 - val_precision: 0.0667 - val_recall: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4199 - accuracy: 0.7184 - auc: 0.9002 - precision: 0.1828 - recall: 0.9101 - val_loss: 1.3524 - val_accuracy: 0.1611 - val_auc: 0.3604 - val_precision: 0.0638 - val_recall: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3870 - accuracy: 0.7306 - auc: 0.9214 - precision: 0.1911 - recall: 0.9213 - val_loss: 1.2912 - val_accuracy: 0.2188 - val_auc: 0.3879 - val_precision: 0.0684 - val_recall: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3772 - accuracy: 0.7527 - auc: 0.9260 - precision: 0.2065 - recall: 0.9326 - val_loss: 1.1610 - val_accuracy: 0.3222 - val_auc: 0.3720 - val_precision: 0.0711 - val_recall: 0.5333 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.9088 - auc: 0.5897 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1099 sequences of length 13\n",
      "X shape: (1099, 13, 1968)\n",
      "y shape: (1099,)\n",
      "Epoch 1/25\n",
      "28/28 [==============================] - 7s 52ms/step - loss: 1.1861 - accuracy: 0.5358 - auc: 0.5236 - precision: 0.0639 - recall: 0.4906 - val_loss: 0.5528 - val_accuracy: 0.9455 - val_auc: 0.5467 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.3661 - accuracy: 0.5313 - auc: 0.5880 - precision: 0.0835 - recall: 0.6792 - val_loss: 0.9541 - val_accuracy: 0.0545 - val_auc: 0.4123 - val_precision: 0.0545 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.1550 - accuracy: 0.5279 - auc: 0.6708 - precision: 0.0810 - recall: 0.6604 - val_loss: 0.7279 - val_accuracy: 0.2682 - val_auc: 0.4874 - val_precision: 0.0539 - val_recall: 0.7500 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.7795 - accuracy: 0.5813 - auc: 0.7544 - precision: 0.0992 - recall: 0.7358 - val_loss: 0.6759 - val_accuracy: 0.6000 - val_auc: 0.4659 - val_precision: 0.0476 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.5984 - accuracy: 0.6121 - auc: 0.8078 - precision: 0.1190 - recall: 0.8491 - val_loss: 0.4846 - val_accuracy: 0.9455 - val_auc: 0.4599 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.4992 - accuracy: 0.6849 - auc: 0.8811 - precision: 0.1522 - recall: 0.9245 - val_loss: 0.6664 - val_accuracy: 0.5864 - val_auc: 0.4665 - val_precision: 0.0562 - val_recall: 0.4167 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.4439 - accuracy: 0.7327 - auc: 0.8875 - precision: 0.1703 - recall: 0.8868 - val_loss: 0.4198 - val_accuracy: 0.9455 - val_auc: 0.5481 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.3841 - accuracy: 0.7550 - auc: 0.9190 - precision: 0.1958 - recall: 0.9400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 25ms/step - loss: 0.3824 - accuracy: 0.7520 - auc: 0.9185 - precision: 0.1887 - recall: 0.9434 - val_loss: 0.2266 - val_accuracy: 0.9455 - val_auc: 0.6062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.3302 - accuracy: 0.8055 - auc: 0.9408 - precision: 0.2217 - recall: 0.8868 - val_loss: 0.3706 - val_accuracy: 0.9409 - val_auc: 0.4896 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.3495 - accuracy: 0.8191 - auc: 0.9315 - precision: 0.2376 - recall: 0.9057 - val_loss: 0.8465 - val_accuracy: 0.4000 - val_auc: 0.5072 - val_precision: 0.0522 - val_recall: 0.5833 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.2710 - accuracy: 0.8510 - auc: 0.9598 - precision: 0.2833 - recall: 0.9623 - val_loss: 0.6531 - val_accuracy: 0.5955 - val_auc: 0.4954 - val_precision: 0.0471 - val_recall: 0.3333 - lr: 0.0010\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.9455 - auc: 0.5467 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 830 sequences of length 13\n",
      "X shape: (830, 13, 1968)\n",
      "y shape: (830,)\n",
      "Epoch 1/25\n",
      "21/21 [==============================] - 6s 66ms/step - loss: 0.9773 - accuracy: 0.4985 - auc: 0.5688 - precision: 0.0593 - recall: 0.5556 - val_loss: 0.4058 - val_accuracy: 0.9337 - val_auc: 0.4642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0863 - accuracy: 0.5136 - auc: 0.6334 - precision: 0.0691 - recall: 0.6389 - val_loss: 0.5859 - val_accuracy: 0.9096 - val_auc: 0.5501 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0194 - accuracy: 0.5422 - auc: 0.7388 - precision: 0.0890 - recall: 0.8056 - val_loss: 0.6870 - val_accuracy: 0.5542 - val_auc: 0.3704 - val_precision: 0.0299 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.1410 - accuracy: 0.5512 - auc: 0.5959 - precision: 0.0662 - recall: 0.5556 - val_loss: 0.6627 - val_accuracy: 0.6867 - val_auc: 0.3886 - val_precision: 0.0444 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7630 - accuracy: 0.5828 - auc: 0.7724 - precision: 0.0997 - recall: 0.8333 - val_loss: 0.5897 - val_accuracy: 0.8795 - val_auc: 0.4123 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5608 - accuracy: 0.6491 - auc: 0.8465 - precision: 0.1137 - recall: 0.8056 - val_loss: 0.5467 - val_accuracy: 0.8976 - val_auc: 0.3745 - val_precision: 0.1250 - val_recall: 0.0909 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4708 - accuracy: 0.6973 - auc: 0.8988 - precision: 0.1489 - recall: 0.9722 - val_loss: 0.4601 - val_accuracy: 0.9337 - val_auc: 0.3126 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.6958 - auc: 0.9097 - precision: 0.1453 - recall: 0.9444 - val_loss: 0.4671 - val_accuracy: 0.9337 - val_auc: 0.3751 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4210 - accuracy: 0.7169 - auc: 0.9074 - precision: 0.1481 - recall: 0.8889 - val_loss: 0.4406 - val_accuracy: 0.9277 - val_auc: 0.4836 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.7108 - auc: 0.8851 - precision: 0.1455 - recall: 0.8889 - val_loss: 0.4087 - val_accuracy: 0.9277 - val_auc: 0.4226 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.7500 - auc: 0.9356 - precision: 0.1684 - recall: 0.9167 - val_loss: 0.4566 - val_accuracy: 0.9157 - val_auc: 0.3897 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.9337 - auc: 0.4642 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3209 sequences of length 15\n",
      "X shape: (3209, 15, 1968)\n",
      "y shape: (3209,)\n",
      "Epoch 1/25\n",
      "81/81 [==============================] - 7s 25ms/step - loss: 1.3993 - accuracy: 0.5072 - auc: 0.5174 - precision: 0.0704 - recall: 0.5422 - val_loss: 0.7435 - val_accuracy: 0.2445 - val_auc: 0.4464 - val_precision: 0.0795 - val_recall: 0.8039 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.9766 - accuracy: 0.5399 - auc: 0.5842 - precision: 0.0809 - recall: 0.5904 - val_loss: 0.4301 - val_accuracy: 0.9143 - val_auc: 0.4893 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.8280 - accuracy: 0.5582 - auc: 0.6015 - precision: 0.0813 - recall: 0.5663 - val_loss: 0.6580 - val_accuracy: 0.5872 - val_auc: 0.5226 - val_precision: 0.0853 - val_recall: 0.4314 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.6530 - accuracy: 0.6034 - auc: 0.7278 - precision: 0.1134 - recall: 0.7530 - val_loss: 0.3397 - val_accuracy: 0.8941 - val_auc: 0.6035 - val_precision: 0.1852 - val_recall: 0.0980 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.5979 - accuracy: 0.6424 - auc: 0.7646 - precision: 0.1232 - recall: 0.7410 - val_loss: 0.8608 - val_accuracy: 0.3879 - val_auc: 0.6106 - val_precision: 0.0889 - val_recall: 0.7255 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.5294 - accuracy: 0.6833 - auc: 0.8196 - precision: 0.1480 - recall: 0.8193 - val_loss: 0.7051 - val_accuracy: 0.6090 - val_auc: 0.4661 - val_precision: 0.0652 - val_recall: 0.2941 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.4844 - accuracy: 0.7265 - auc: 0.8505 - precision: 0.1700 - recall: 0.8313 - val_loss: 0.6490 - val_accuracy: 0.6636 - val_auc: 0.4717 - val_precision: 0.0681 - val_recall: 0.2549 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.4722 - accuracy: 0.7398 - auc: 0.8606 - precision: 0.1732 - recall: 0.8012 - val_loss: 0.8778 - val_accuracy: 0.6215 - val_auc: 0.4531 - val_precision: 0.0789 - val_recall: 0.3529 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.4364 - accuracy: 0.7538 - auc: 0.8807 - precision: 0.1877 - recall: 0.8434 - val_loss: 0.6826 - val_accuracy: 0.7118 - val_auc: 0.5080 - val_precision: 0.0864 - val_recall: 0.2745 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3906 - accuracy: 0.7900 - auc: 0.9069 - precision: 0.2187 - recall: 0.8735 - val_loss: 0.6148 - val_accuracy: 0.7539 - val_auc: 0.4861 - val_precision: 0.0787 - val_recall: 0.1961 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3600 - accuracy: 0.7939 - auc: 0.9226 - precision: 0.2254 - recall: 0.8976 - val_loss: 0.6887 - val_accuracy: 0.6963 - val_auc: 0.4709 - val_precision: 0.0714 - val_recall: 0.2353 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3203 - accuracy: 0.8118 - auc: 0.9436 - precision: 0.2464 - recall: 0.9277 - val_loss: 0.7058 - val_accuracy: 0.6885 - val_auc: 0.4655 - val_precision: 0.0643 - val_recall: 0.2157 - lr: 2.0000e-04\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.9143 - auc: 0.4893 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1612 sequences of length 15\n",
      "X shape: (1612, 15, 1968)\n",
      "y shape: (1612,)\n",
      "Epoch 1/25\n",
      "41/41 [==============================] - 7s 39ms/step - loss: 1.2311 - accuracy: 0.5089 - auc: 0.5107 - precision: 0.0769 - recall: 0.5213 - val_loss: 0.4350 - val_accuracy: 0.9319 - val_auc: 0.4191 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0901 - accuracy: 0.5136 - auc: 0.5877 - precision: 0.0881 - recall: 0.6064 - val_loss: 0.6618 - val_accuracy: 0.7647 - val_auc: 0.5285 - val_precision: 0.0909 - val_recall: 0.2727 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0145 - accuracy: 0.5500 - auc: 0.6055 - precision: 0.1016 - recall: 0.6596 - val_loss: 0.2769 - val_accuracy: 0.9319 - val_auc: 0.5662 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.7189 - accuracy: 0.6012 - auc: 0.7347 - precision: 0.1277 - recall: 0.7660 - val_loss: 0.3885 - val_accuracy: 0.9319 - val_auc: 0.4817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.6279 - accuracy: 0.6524 - auc: 0.7638 - precision: 0.1373 - recall: 0.7128 - val_loss: 0.2522 - val_accuracy: 0.9319 - val_auc: 0.5613 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.5313 - accuracy: 0.6843 - auc: 0.8477 - precision: 0.1733 - recall: 0.8830 - val_loss: 0.6422 - val_accuracy: 0.6192 - val_auc: 0.4778 - val_precision: 0.0756 - val_recall: 0.4091 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4731 - accuracy: 0.7324 - auc: 0.8718 - precision: 0.1976 - recall: 0.8723 - val_loss: 0.2802 - val_accuracy: 0.9288 - val_auc: 0.4960 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4834 - accuracy: 0.7471 - auc: 0.8824 - precision: 0.2100 - recall: 0.8936 - val_loss: 0.4655 - val_accuracy: 0.8050 - val_auc: 0.5349 - val_precision: 0.0816 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4377 - accuracy: 0.7704 - auc: 0.8846 - precision: 0.2240 - recall: 0.8723 - val_loss: 0.3359 - val_accuracy: 0.9040 - val_auc: 0.3741 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.3961 - accuracy: 0.7626 - auc: 0.9090 - precision: 0.2225 - recall: 0.9043 - val_loss: 0.3613 - val_accuracy: 0.9133 - val_auc: 0.4152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.3448 - accuracy: 0.8099 - auc: 0.9298 - precision: 0.2648 - recall: 0.9043 - val_loss: 0.3453 - val_accuracy: 0.9040 - val_auc: 0.4092 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.9319 - auc: 0.4191 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1080 sequences of length 15\n",
      "X shape: (1080, 15, 1968)\n",
      "y shape: (1080,)\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 6s 53ms/step - loss: 1.1835 - accuracy: 0.4931 - auc: 0.4886 - precision: 0.0708 - recall: 0.5000 - val_loss: 0.5575 - val_accuracy: 0.9167 - val_auc: 0.5213 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1662 - accuracy: 0.5000 - auc: 0.5871 - precision: 0.0814 - recall: 0.5806 - val_loss: 0.6884 - val_accuracy: 0.5278 - val_auc: 0.3880 - val_precision: 0.0526 - val_recall: 0.2941 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9699 - accuracy: 0.5370 - auc: 0.6449 - precision: 0.0995 - recall: 0.6774 - val_loss: 0.7630 - val_accuracy: 0.1759 - val_auc: 0.4880 - val_precision: 0.0829 - val_recall: 0.9412 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.8212 - accuracy: 0.5868 - auc: 0.7150 - precision: 0.1108 - recall: 0.6774 - val_loss: 1.7017 - val_accuracy: 0.0787 - val_auc: 0.5727 - val_precision: 0.0787 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.6296 - auc: 0.8280 - precision: 0.1456 - recall: 0.8548 - val_loss: 0.8580 - val_accuracy: 0.0833 - val_auc: 0.5395 - val_precision: 0.0791 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4846 - accuracy: 0.6782 - auc: 0.8727 - precision: 0.1707 - recall: 0.9032 - val_loss: 0.6499 - val_accuracy: 0.6204 - val_auc: 0.5034 - val_precision: 0.0886 - val_recall: 0.4118 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4371 - accuracy: 0.7373 - auc: 0.8942 - precision: 0.2000 - recall: 0.8871 - val_loss: 0.6469 - val_accuracy: 0.6759 - val_auc: 0.5262 - val_precision: 0.0794 - val_recall: 0.2941 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.7326 - auc: 0.9135 - precision: 0.2056 - recall: 0.9516 - val_loss: 0.6227 - val_accuracy: 0.6759 - val_auc: 0.5217 - val_precision: 0.0794 - val_recall: 0.2941 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3662 - accuracy: 0.7639 - auc: 0.9238 - precision: 0.2205 - recall: 0.9032 - val_loss: 0.6965 - val_accuracy: 0.5509 - val_auc: 0.5406 - val_precision: 0.0918 - val_recall: 0.5294 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3454 - accuracy: 0.7650 - auc: 0.9422 - precision: 0.2278 - recall: 0.9516 - val_loss: 0.5709 - val_accuracy: 0.7083 - val_auc: 0.5336 - val_precision: 0.0577 - val_recall: 0.1765 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3443 - accuracy: 0.7778 - auc: 0.9368 - precision: 0.2314 - recall: 0.9032 - val_loss: 0.5548 - val_accuracy: 0.7269 - val_auc: 0.5306 - val_precision: 0.0962 - val_recall: 0.2941 - lr: 2.0000e-04\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.9167 - auc: 0.5213 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 813 sequences of length 15\n",
      "X shape: (813, 15, 1968)\n",
      "y shape: (813,)\n",
      "Epoch 1/25\n",
      "21/21 [==============================] - 6s 67ms/step - loss: 1.0812 - accuracy: 0.4692 - auc: 0.5403 - precision: 0.0980 - recall: 0.6034 - val_loss: 0.4554 - val_accuracy: 0.9141 - val_auc: 0.4672 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0814 - accuracy: 0.5292 - auc: 0.6340 - precision: 0.1149 - recall: 0.6379 - val_loss: 0.6410 - val_accuracy: 0.8037 - val_auc: 0.5535 - val_precision: 0.0909 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7807 - accuracy: 0.5662 - auc: 0.7142 - precision: 0.1364 - recall: 0.7241 - val_loss: 0.5928 - val_accuracy: 0.8466 - val_auc: 0.7071 - val_precision: 0.1333 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7486 - accuracy: 0.6385 - auc: 0.7713 - precision: 0.1685 - recall: 0.7759 - val_loss: 0.4484 - val_accuracy: 0.9141 - val_auc: 0.6177 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6426 - accuracy: 0.6462 - auc: 0.8081 - precision: 0.1667 - recall: 0.7414 - val_loss: 0.3411 - val_accuracy: 0.9141 - val_auc: 0.6592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5793 - accuracy: 0.6862 - auc: 0.8285 - precision: 0.1983 - recall: 0.8276 - val_loss: 0.3667 - val_accuracy: 0.9141 - val_auc: 0.6565 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5277 - accuracy: 0.7015 - auc: 0.8468 - precision: 0.2094 - recall: 0.8448 - val_loss: 0.4407 - val_accuracy: 0.8896 - val_auc: 0.6860 - val_precision: 0.2500 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4926 - accuracy: 0.7154 - auc: 0.8639 - precision: 0.2178 - recall: 0.8448 - val_loss: 0.5022 - val_accuracy: 0.8650 - val_auc: 0.6611 - val_precision: 0.2500 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.7415 - auc: 0.9244 - precision: 0.2477 - recall: 0.9310 - val_loss: 0.5017 - val_accuracy: 0.8589 - val_auc: 0.6968 - val_precision: 0.2353 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3432 - accuracy: 0.7908 - auc: 0.9350 - precision: 0.2857 - recall: 0.8966 - val_loss: 0.8246 - val_accuracy: 0.4540 - val_auc: 0.7239 - val_precision: 0.1212 - val_recall: 0.8571 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.3057 - accuracy: 0.8138 - auc: 0.9559 - precision: 0.3220 - recall: 0.9828 - val_loss: 0.5806 - val_accuracy: 0.7239 - val_auc: 0.6822 - val_precision: 0.1702 - val_recall: 0.5714 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.9141 - auc: 0.4672 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3147 sequences of length 17\n",
      "X shape: (3147, 17, 1968)\n",
      "y shape: (3147,)\n",
      "Epoch 1/25\n",
      "79/79 [==============================] - 10s 26ms/step - loss: 1.2595 - accuracy: 0.5165 - auc: 0.5373 - precision: 0.0727 - recall: 0.5235 - val_loss: 0.2828 - val_accuracy: 0.9333 - val_auc: 0.5246 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 1.0265 - accuracy: 0.5276 - auc: 0.5297 - precision: 0.0693 - recall: 0.4824 - val_loss: 0.8522 - val_accuracy: 0.1175 - val_auc: 0.4784 - val_precision: 0.0673 - val_recall: 0.9524 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.8218 - accuracy: 0.5566 - auc: 0.6186 - precision: 0.0915 - recall: 0.6235 - val_loss: 0.8441 - val_accuracy: 0.2048 - val_auc: 0.5372 - val_precision: 0.0694 - val_recall: 0.8810 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6917 - accuracy: 0.5876 - auc: 0.6984 - precision: 0.1083 - recall: 0.7059 - val_loss: 0.8584 - val_accuracy: 0.2937 - val_auc: 0.5040 - val_precision: 0.0667 - val_recall: 0.7381 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6108 - accuracy: 0.6246 - auc: 0.7530 - precision: 0.1263 - recall: 0.7706 - val_loss: 0.5413 - val_accuracy: 0.7476 - val_auc: 0.5283 - val_precision: 0.0730 - val_recall: 0.2381 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5335 - accuracy: 0.6615 - auc: 0.8147 - precision: 0.1426 - recall: 0.8000 - val_loss: 0.4679 - val_accuracy: 0.8254 - val_auc: 0.5098 - val_precision: 0.0641 - val_recall: 0.1190 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4760 - accuracy: 0.7163 - auc: 0.8567 - precision: 0.1715 - recall: 0.8353 - val_loss: 0.8560 - val_accuracy: 0.5238 - val_auc: 0.5274 - val_precision: 0.0700 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4413 - accuracy: 0.7076 - auc: 0.8830 - precision: 0.1747 - recall: 0.8941 - val_loss: 0.6867 - val_accuracy: 0.6254 - val_auc: 0.5524 - val_precision: 0.0855 - val_recall: 0.4762 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4262 - accuracy: 0.7398 - auc: 0.8904 - precision: 0.1919 - recall: 0.8882 - val_loss: 0.7517 - val_accuracy: 0.5841 - val_auc: 0.5693 - val_precision: 0.0833 - val_recall: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4216 - accuracy: 0.7398 - auc: 0.8912 - precision: 0.1903 - recall: 0.8765 - val_loss: 0.7465 - val_accuracy: 0.5952 - val_auc: 0.5695 - val_precision: 0.0856 - val_recall: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.4151 - accuracy: 0.7517 - auc: 0.8972 - precision: 0.2003 - recall: 0.8941 - val_loss: 0.7518 - val_accuracy: 0.6190 - val_auc: 0.5780 - val_precision: 0.0943 - val_recall: 0.5476 - lr: 2.0000e-04\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.9333 - auc: 0.5246 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1581 sequences of length 17\n",
      "X shape: (1581, 17, 1968)\n",
      "y shape: (1581,)\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 7s 40ms/step - loss: 1.1745 - accuracy: 0.4976 - auc: 0.5193 - precision: 0.0820 - recall: 0.5579 - val_loss: 0.5688 - val_accuracy: 0.9306 - val_auc: 0.4494 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1027 - accuracy: 0.5340 - auc: 0.6157 - precision: 0.1003 - recall: 0.6526 - val_loss: 1.0007 - val_accuracy: 0.0631 - val_auc: 0.5312 - val_precision: 0.0631 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9103 - accuracy: 0.5799 - auc: 0.6370 - precision: 0.1107 - recall: 0.6526 - val_loss: 0.4243 - val_accuracy: 0.9369 - val_auc: 0.4908 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7669 - accuracy: 0.6155 - auc: 0.7003 - precision: 0.1262 - recall: 0.6947 - val_loss: 0.4494 - val_accuracy: 0.9369 - val_auc: 0.5657 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.6570 - accuracy: 0.6195 - auc: 0.7501 - precision: 0.1372 - recall: 0.7684 - val_loss: 0.4204 - val_accuracy: 0.9274 - val_auc: 0.5200 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5440 - accuracy: 0.6788 - auc: 0.8173 - precision: 0.1627 - recall: 0.7895 - val_loss: 0.3209 - val_accuracy: 0.9243 - val_auc: 0.5944 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5701 - accuracy: 0.6930 - auc: 0.8169 - precision: 0.1693 - recall: 0.7895 - val_loss: 0.2482 - val_accuracy: 0.9338 - val_auc: 0.5526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.4869 - accuracy: 0.7247 - auc: 0.8534 - precision: 0.1937 - recall: 0.8421 - val_loss: 0.2748 - val_accuracy: 0.9243 - val_auc: 0.6272 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.4758 - accuracy: 0.7468 - auc: 0.8720 - precision: 0.2108 - recall: 0.8632 - val_loss: 0.2651 - val_accuracy: 0.9338 - val_auc: 0.5269 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.3908 - accuracy: 0.7650 - auc: 0.9088 - precision: 0.2270 - recall: 0.8842 - val_loss: 0.2769 - val_accuracy: 0.9306 - val_auc: 0.5142 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8062 - auc: 0.8956 - precision: 0.2565 - recall: 0.8316 - val_loss: 0.3707 - val_accuracy: 0.9306 - val_auc: 0.5160 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.9306 - auc: 0.4494 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1061 sequences of length 17\n",
      "X shape: (1061, 17, 1968)\n",
      "y shape: (1061,)\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 7s 54ms/step - loss: 1.3092 - accuracy: 0.4858 - auc: 0.4554 - precision: 0.0587 - recall: 0.4167 - val_loss: 0.5587 - val_accuracy: 0.9108 - val_auc: 0.4979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0723 - accuracy: 0.5153 - auc: 0.6409 - precision: 0.0909 - recall: 0.6500 - val_loss: 0.6273 - val_accuracy: 0.8545 - val_auc: 0.5438 - val_precision: 0.1053 - val_recall: 0.1250 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0874 - accuracy: 0.5330 - auc: 0.6399 - precision: 0.0981 - recall: 0.6833 - val_loss: 0.6134 - val_accuracy: 0.8826 - val_auc: 0.4074 - val_precision: 0.0909 - val_recall: 0.0625 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.7463 - accuracy: 0.5837 - auc: 0.7367 - precision: 0.1135 - recall: 0.7167 - val_loss: 0.4872 - val_accuracy: 0.9249 - val_auc: 0.4142 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4920 - accuracy: 0.6710 - auc: 0.8752 - precision: 0.1631 - recall: 0.8833 - val_loss: 0.4872 - val_accuracy: 0.9249 - val_auc: 0.4005 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5139 - accuracy: 0.6934 - auc: 0.8438 - precision: 0.1644 - recall: 0.8167 - val_loss: 0.3798 - val_accuracy: 0.9202 - val_auc: 0.4353 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5075 - accuracy: 0.6981 - auc: 0.8709 - precision: 0.1621 - recall: 0.7833 - val_loss: 0.3054 - val_accuracy: 0.9249 - val_auc: 0.3319 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4296 - accuracy: 0.7571 - auc: 0.9008 - precision: 0.2126 - recall: 0.9000 - val_loss: 0.3087 - val_accuracy: 0.9249 - val_auc: 0.3710 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.7724 - auc: 0.9089 - precision: 0.2194 - recall: 0.8667 - val_loss: 0.4562 - val_accuracy: 0.8357 - val_auc: 0.5094 - val_precision: 0.0476 - val_recall: 0.0625 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3465 - accuracy: 0.8078 - auc: 0.9353 - precision: 0.2627 - recall: 0.9500 - val_loss: 0.3383 - val_accuracy: 0.9202 - val_auc: 0.4218 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2609 - accuracy: 0.8373 - auc: 0.9665 - precision: 0.2990 - recall: 0.9667 - val_loss: 0.6062 - val_accuracy: 0.6667 - val_auc: 0.4109 - val_precision: 0.0175 - val_recall: 0.0625 - lr: 0.0010\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5587 - accuracy: 0.9108 - auc: 0.4979 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 799 sequences of length 17\n",
      "X shape: (799, 17, 1968)\n",
      "y shape: (799,)\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 6s 69ms/step - loss: 1.1791 - accuracy: 0.4789 - auc: 0.4987 - precision: 0.0539 - recall: 0.5143 - val_loss: 0.3821 - val_accuracy: 0.9438 - val_auc: 0.4901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.9304 - accuracy: 0.5227 - auc: 0.6996 - precision: 0.0781 - recall: 0.7143 - val_loss: 0.3104 - val_accuracy: 0.9438 - val_auc: 0.5806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.7670 - accuracy: 0.5869 - auc: 0.8127 - precision: 0.1065 - recall: 0.8857 - val_loss: 0.3736 - val_accuracy: 0.9438 - val_auc: 0.5765 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6515 - accuracy: 0.6150 - auc: 0.8220 - precision: 0.1136 - recall: 0.8857 - val_loss: 0.5245 - val_accuracy: 0.9312 - val_auc: 0.5636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6939 - accuracy: 0.6448 - auc: 0.7978 - precision: 0.1033 - recall: 0.7143 - val_loss: 0.3872 - val_accuracy: 0.9438 - val_auc: 0.5202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7313 - accuracy: 0.6761 - auc: 0.7941 - precision: 0.1195 - recall: 0.7714 - val_loss: 0.3011 - val_accuracy: 0.9438 - val_auc: 0.5589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4971 - accuracy: 0.6933 - auc: 0.8840 - precision: 0.1485 - recall: 0.9714 - val_loss: 0.3709 - val_accuracy: 0.9438 - val_auc: 0.5055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3337 - accuracy: 0.7762 - auc: 0.9564 - precision: 0.1932 - recall: 0.9714 - val_loss: 0.3929 - val_accuracy: 0.9438 - val_auc: 0.4463 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3393 - accuracy: 0.8247 - auc: 0.9381 - precision: 0.2230 - recall: 0.8857 - val_loss: 0.2771 - val_accuracy: 0.9438 - val_auc: 0.4169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2506 - accuracy: 0.8310 - auc: 0.9746 - precision: 0.2411 - recall: 0.9714 - val_loss: 0.2992 - val_accuracy: 0.9438 - val_auc: 0.4194 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2591 - accuracy: 0.8466 - auc: 0.9656 - precision: 0.2520 - recall: 0.9143 - val_loss: 0.3297 - val_accuracy: 0.9375 - val_auc: 0.3355 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.9438 - auc: 0.4901 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3085 sequences of length 19\n",
      "X shape: (3085, 19, 1968)\n",
      "y shape: (3085,)\n",
      "Epoch 1/25\n",
      "78/78 [==============================] - 7s 27ms/step - loss: 1.2471 - accuracy: 0.4773 - auc: 0.5226 - precision: 0.0707 - recall: 0.5318 - val_loss: 0.4917 - val_accuracy: 0.9384 - val_auc: 0.4886 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 1.0717 - accuracy: 0.5328 - auc: 0.5569 - precision: 0.0812 - recall: 0.5491 - val_loss: 1.0702 - val_accuracy: 0.0616 - val_auc: 0.5042 - val_precision: 0.0602 - val_recall: 0.9737 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.8668 - accuracy: 0.5511 - auc: 0.6049 - precision: 0.0888 - recall: 0.5838 - val_loss: 0.7080 - val_accuracy: 0.4927 - val_auc: 0.4757 - val_precision: 0.0550 - val_recall: 0.4474 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.6567 - accuracy: 0.6033 - auc: 0.7312 - precision: 0.1227 - recall: 0.7572 - val_loss: 0.3979 - val_accuracy: 0.9173 - val_auc: 0.4593 - val_precision: 0.1176 - val_recall: 0.0526 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.6067 - accuracy: 0.6511 - auc: 0.7659 - precision: 0.1356 - recall: 0.7399 - val_loss: 0.7988 - val_accuracy: 0.4473 - val_auc: 0.5069 - val_precision: 0.0634 - val_recall: 0.5789 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.5341 - accuracy: 0.6884 - auc: 0.8235 - precision: 0.1637 - recall: 0.8382 - val_loss: 0.4434 - val_accuracy: 0.8379 - val_auc: 0.4754 - val_precision: 0.0441 - val_recall: 0.0789 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.4811 - accuracy: 0.7257 - auc: 0.8527 - precision: 0.1802 - recall: 0.8208 - val_loss: 0.6855 - val_accuracy: 0.7618 - val_auc: 0.5088 - val_precision: 0.0496 - val_recall: 0.1579 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.4761 - accuracy: 0.7362 - auc: 0.8607 - precision: 0.1880 - recall: 0.8324 - val_loss: 0.5800 - val_accuracy: 0.7861 - val_auc: 0.4866 - val_precision: 0.0566 - val_recall: 0.1579 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.4694 - accuracy: 0.7378 - auc: 0.8608 - precision: 0.1873 - recall: 0.8208 - val_loss: 0.6495 - val_accuracy: 0.7520 - val_auc: 0.5023 - val_precision: 0.0611 - val_recall: 0.2105 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3984 - accuracy: 0.7678 - auc: 0.9024 - precision: 0.2167 - recall: 0.8844 - val_loss: 0.6778 - val_accuracy: 0.7034 - val_auc: 0.5388 - val_precision: 0.0809 - val_recall: 0.3684 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3507 - accuracy: 0.7889 - auc: 0.9279 - precision: 0.2403 - recall: 0.9306 - val_loss: 0.6438 - val_accuracy: 0.7164 - val_auc: 0.5452 - val_precision: 0.0745 - val_recall: 0.3158 - lr: 2.0000e-04\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.9384 - auc: 0.4886 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1550 sequences of length 19\n",
      "X shape: (1550, 19, 1968)\n",
      "y shape: (1550,)\n",
      "Epoch 1/25\n",
      "39/39 [==============================] - 7s 41ms/step - loss: 1.2799 - accuracy: 0.4944 - auc: 0.5093 - precision: 0.0792 - recall: 0.5208 - val_loss: 0.5394 - val_accuracy: 0.9387 - val_auc: 0.5328 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.1181 - accuracy: 0.5153 - auc: 0.5714 - precision: 0.0908 - recall: 0.5833 - val_loss: 0.4499 - val_accuracy: 0.9419 - val_auc: 0.5638 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.8745 - accuracy: 0.5540 - auc: 0.6580 - precision: 0.1081 - recall: 0.6562 - val_loss: 0.4329 - val_accuracy: 0.9419 - val_auc: 0.4735 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.7199 - accuracy: 0.5968 - auc: 0.7342 - precision: 0.1300 - recall: 0.7396 - val_loss: 0.6705 - val_accuracy: 0.5806 - val_auc: 0.4051 - val_precision: 0.0556 - val_recall: 0.3889 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6467 - accuracy: 0.6516 - auc: 0.7758 - precision: 0.1500 - recall: 0.7500 - val_loss: 0.3628 - val_accuracy: 0.9419 - val_auc: 0.5399 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5434 - accuracy: 0.6847 - auc: 0.8370 - precision: 0.1786 - recall: 0.8542 - val_loss: 0.2610 - val_accuracy: 0.9419 - val_auc: 0.4952 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5062 - accuracy: 0.7306 - auc: 0.8531 - precision: 0.1995 - recall: 0.8229 - val_loss: 0.7667 - val_accuracy: 0.4323 - val_auc: 0.4901 - val_precision: 0.0562 - val_recall: 0.5556 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.7516 - auc: 0.9068 - precision: 0.2225 - recall: 0.8854 - val_loss: 0.5050 - val_accuracy: 0.7871 - val_auc: 0.3917 - val_precision: 0.0556 - val_recall: 0.1667 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4023 - accuracy: 0.7847 - auc: 0.9038 - precision: 0.2493 - recall: 0.8854 - val_loss: 0.3846 - val_accuracy: 0.8903 - val_auc: 0.4365 - val_precision: 0.0556 - val_recall: 0.0556 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3681 - accuracy: 0.7863 - auc: 0.9203 - precision: 0.2551 - recall: 0.9167 - val_loss: 0.6712 - val_accuracy: 0.6548 - val_auc: 0.4421 - val_precision: 0.0505 - val_recall: 0.2778 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3190 - accuracy: 0.8298 - auc: 0.9411 - precision: 0.3024 - recall: 0.9167 - val_loss: 0.4440 - val_accuracy: 0.8226 - val_auc: 0.4594 - val_precision: 0.0256 - val_recall: 0.0556 - lr: 0.0010\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.9387 - auc: 0.5328 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1037 sequences of length 19\n",
      "X shape: (1037, 19, 1968)\n",
      "y shape: (1037,)\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 7s 57ms/step - loss: 1.1764 - accuracy: 0.5030 - auc: 0.4729 - precision: 0.0604 - recall: 0.5208 - val_loss: 0.4430 - val_accuracy: 0.9519 - val_auc: 0.3563 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.2727 - accuracy: 0.5066 - auc: 0.5924 - precision: 0.0733 - recall: 0.6458 - val_loss: 0.8500 - val_accuracy: 0.0673 - val_auc: 0.5078 - val_precision: 0.0490 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.9250 - accuracy: 0.5501 - auc: 0.7257 - precision: 0.0927 - recall: 0.7708 - val_loss: 1.0895 - val_accuracy: 0.0481 - val_auc: 0.5013 - val_precision: 0.0481 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5887 - auc: 0.7846 - precision: 0.1051 - recall: 0.8125 - val_loss: 1.2857 - val_accuracy: 0.0481 - val_auc: 0.6035 - val_precision: 0.0481 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4949 - accuracy: 0.6526 - auc: 0.8823 - precision: 0.1341 - recall: 0.9167 - val_loss: 0.5570 - val_accuracy: 0.8990 - val_auc: 0.5045 - val_precision: 0.0769 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4775 - accuracy: 0.7407 - auc: 0.8652 - precision: 0.1647 - recall: 0.8542 - val_loss: 1.3198 - val_accuracy: 0.1250 - val_auc: 0.4419 - val_precision: 0.0474 - val_recall: 0.9000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4450 - accuracy: 0.7334 - auc: 0.9171 - precision: 0.1711 - recall: 0.9375 - val_loss: 0.9966 - val_accuracy: 0.1923 - val_auc: 0.4179 - val_precision: 0.0407 - val_recall: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3264 - accuracy: 0.7756 - auc: 0.9542 - precision: 0.2000 - recall: 0.9583 - val_loss: 0.8587 - val_accuracy: 0.2740 - val_auc: 0.3947 - val_precision: 0.0452 - val_recall: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3009 - accuracy: 0.8022 - auc: 0.9588 - precision: 0.2184 - recall: 0.9375 - val_loss: 1.1220 - val_accuracy: 0.1923 - val_auc: 0.4455 - val_precision: 0.0407 - val_recall: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.2855 - accuracy: 0.8058 - auc: 0.9654 - precision: 0.2271 - recall: 0.9792 - val_loss: 0.9872 - val_accuracy: 0.2885 - val_auc: 0.4184 - val_precision: 0.0338 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.2498 - accuracy: 0.8287 - auc: 0.9775 - precision: 0.2500 - recall: 0.9792 - val_loss: 0.8885 - val_accuracy: 0.4087 - val_auc: 0.4197 - val_precision: 0.0407 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.9519 - auc: 0.3563 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 782 sequences of length 19\n",
      "X shape: (782, 19, 1968)\n",
      "y shape: (782,)\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 6s 71ms/step - loss: 1.2459 - accuracy: 0.4912 - auc: 0.4064 - precision: 0.0724 - recall: 0.3793 - val_loss: 0.6644 - val_accuracy: 0.6688 - val_auc: 0.5369 - val_precision: 0.0465 - val_recall: 0.1538 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.1474 - accuracy: 0.4912 - auc: 0.5963 - precision: 0.1061 - recall: 0.6034 - val_loss: 0.6658 - val_accuracy: 0.6752 - val_auc: 0.4300 - val_precision: 0.0682 - val_recall: 0.2308 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.9420 - accuracy: 0.5296 - auc: 0.6404 - precision: 0.1289 - recall: 0.7069 - val_loss: 0.4333 - val_accuracy: 0.9172 - val_auc: 0.4621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7936 - accuracy: 0.6032 - auc: 0.7130 - precision: 0.1558 - recall: 0.7414 - val_loss: 0.3939 - val_accuracy: 0.9172 - val_auc: 0.4642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5769 - accuracy: 0.6448 - auc: 0.8583 - precision: 0.1940 - recall: 0.8966 - val_loss: 0.5430 - val_accuracy: 0.9172 - val_auc: 0.6044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5738 - accuracy: 0.6576 - auc: 0.8319 - precision: 0.1929 - recall: 0.8448 - val_loss: 0.3504 - val_accuracy: 0.9172 - val_auc: 0.4712 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4510 - accuracy: 0.7152 - auc: 0.8950 - precision: 0.2297 - recall: 0.8793 - val_loss: 0.3061 - val_accuracy: 0.9172 - val_auc: 0.5142 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4275 - accuracy: 0.7456 - auc: 0.9039 - precision: 0.2537 - recall: 0.8966 - val_loss: 0.2851 - val_accuracy: 0.9172 - val_auc: 0.5991 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5544 - accuracy: 0.7456 - auc: 0.8472 - precision: 0.2356 - recall: 0.7759 - val_loss: 0.5667 - val_accuracy: 0.8535 - val_auc: 0.4217 - val_precision: 0.0833 - val_recall: 0.0769 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4351 - accuracy: 0.7408 - auc: 0.9080 - precision: 0.2451 - recall: 0.8621 - val_loss: 0.3045 - val_accuracy: 0.9172 - val_auc: 0.4402 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.7840 - auc: 0.9265 - precision: 0.2919 - recall: 0.9310 - val_loss: 0.2912 - val_accuracy: 0.9172 - val_auc: 0.5956 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2581 - accuracy: 0.8656 - auc: 0.9645 - precision: 0.4030 - recall: 0.9310 - val_loss: 0.4131 - val_accuracy: 0.9108 - val_auc: 0.4904 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.2014 - accuracy: 0.8736 - auc: 0.9834 - precision: 0.4211 - recall: 0.9655 - val_loss: 0.3065 - val_accuracy: 0.9108 - val_auc: 0.5027 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.9172 - auc: 0.4621 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for n in range(1, 20, 2):\n",
    "    for step in range(1, 5):\n",
    "        # prepare your data\n",
    "        X, y, play_ids = create_sequences(\n",
    "            df,\n",
    "            n=n,\n",
    "            target_col='blitzOutcome',\n",
    "            step=step,\n",
    "            cutoff=None\n",
    "        )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # build & train\n",
    "        RNN_model = create_blitz_rnn_model(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            dropout_rate=0.2\n",
    "        )\n",
    "        cw = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        RNN_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=dict(enumerate(cw)),\n",
    "            epochs=25,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # evaluate + save\n",
    "        results = evaluate_and_save(\n",
    "            RNN_model,\n",
    "            X_test, y_test,\n",
    "            ('sequence_length', n),\n",
    "            trial=step,\n",
    "            results=results\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e656c756-6285-41de-b6f5-f8bf1b14e30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>loss_mean</th>\n",
       "      <th>loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.118333</td>\n",
       "      <td>0.157797</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>0.037758</td>\n",
       "      <td>0.865246</td>\n",
       "      <td>0.074225</td>\n",
       "      <td>0.553297</td>\n",
       "      <td>0.067876</td>\n",
       "      <td>0.571921</td>\n",
       "      <td>0.064309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.024476</td>\n",
       "      <td>0.854988</td>\n",
       "      <td>0.079589</td>\n",
       "      <td>0.509568</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.595717</td>\n",
       "      <td>0.011583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.865716</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.140891</td>\n",
       "      <td>0.564213</td>\n",
       "      <td>0.071656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.924295</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.493520</td>\n",
       "      <td>0.061072</td>\n",
       "      <td>0.413063</td>\n",
       "      <td>0.106572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902774</td>\n",
       "      <td>0.017914</td>\n",
       "      <td>0.497130</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>0.514510</td>\n",
       "      <td>0.118233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.521534</td>\n",
       "      <td>0.051659</td>\n",
       "      <td>0.469593</td>\n",
       "      <td>0.042447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.509568</td>\n",
       "      <td>0.070756</td>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.068190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919249</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.474207</td>\n",
       "      <td>0.042915</td>\n",
       "      <td>0.469515</td>\n",
       "      <td>0.059652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929620</td>\n",
       "      <td>0.013768</td>\n",
       "      <td>0.490514</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>0.448078</td>\n",
       "      <td>0.139614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936560</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.075007</td>\n",
       "      <td>0.476846</td>\n",
       "      <td>0.048914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_length  recall_mean  recall_std  precision_mean  precision_std  \\\n",
       "0                1     0.118333    0.157797        0.031775       0.037758   \n",
       "5               11     0.038043    0.076087        0.012238       0.024476   \n",
       "2                5     0.037500    0.075000        0.011538       0.023077   \n",
       "3                7     0.004545    0.009091        0.083333       0.166667   \n",
       "1                3     0.000000    0.000000        0.000000       0.000000   \n",
       "4                9     0.000000    0.000000        0.000000       0.000000   \n",
       "6               13     0.000000    0.000000        0.000000       0.000000   \n",
       "7               15     0.000000    0.000000        0.000000       0.000000   \n",
       "8               17     0.000000    0.000000        0.000000       0.000000   \n",
       "9               19     0.000000    0.000000        0.000000       0.000000   \n",
       "\n",
       "   accuracy_mean  accuracy_std  auc_mean   auc_std  loss_mean  loss_std  \n",
       "0       0.865246      0.074225  0.553297  0.067876   0.571921  0.064309  \n",
       "5       0.854988      0.079589  0.509568  0.027537   0.595717  0.011583  \n",
       "2       0.865716      0.076100  0.486097  0.140891   0.564213  0.071656  \n",
       "3       0.924295      0.009847  0.493520  0.061072   0.413063  0.106572  \n",
       "1       0.902774      0.017914  0.497130  0.062563   0.514510  0.118233  \n",
       "4       0.919322      0.022975  0.521534  0.051659   0.469593  0.042447  \n",
       "6       0.929825      0.015310  0.509568  0.070756   0.458458  0.068190  \n",
       "7       0.919249      0.008505  0.474207  0.042915   0.469515  0.059652  \n",
       "8       0.929620      0.013768  0.490514  0.031141   0.448078  0.139614  \n",
       "9       0.936560      0.014364  0.459961  0.075007   0.476846  0.048914  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_results(results, tuning_param):\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if tuning_param not in results_df.columns:\n",
    "        raise ValueError(f\"'{tuning_param}' not found in results.\")\n",
    "\n",
    "    summary = results_df.groupby(tuning_param).agg({\n",
    "        'recall': ['mean', 'std'],\n",
    "        'precision': ['mean', 'std'],\n",
    "        'accuracy': ['mean', 'std'],\n",
    "        'auc': ['mean', 'std'],\n",
    "        'loss': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "\n",
    "    summary.columns = [tuning_param, 'recall_mean', 'recall_std',\n",
    "                       'precision_mean', 'precision_std',\n",
    "                       'accuracy_mean', 'accuracy_std',\n",
    "                       'auc_mean', 'auc_std',\n",
    "                       'loss_mean', 'loss_std']\n",
    "\n",
    "    return summary.sort_values(by='recall_mean', ascending=False)\n",
    "\n",
    "# show the results\n",
    "summary = summarize_results(results, tuning_param='sequence_length')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefbf73-0f87-41b8-bc4e-59c5ecef6ce7",
   "metadata": {},
   "source": [
    "### Dropout Rate and LSTM Units\n",
    "We tune dropout and LSTM units together to manage the trade-off between model capacity and overfitting in learning blitz patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8603f5c-b1a4-4eb8-99bd-d040897b362f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4]\n",
    "lstm_units_list = [128, 256, 512]\n",
    "n_trials = 3\n",
    "\n",
    "# loop thru combos\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "    for lstm_units in lstm_units_list:\n",
    "        for i in range(n_trials):\n",
    "\n",
    "            print(f'Trial {i+1}/{n_trials} â€” Dropout: {dropout_rate}, LSTM Units: {lstm_units}')\n",
    "\n",
    "            # build model\n",
    "            model = create_blitz_rnn_model(\n",
    "                n_timesteps=X.shape[1],\n",
    "                n_features=X.shape[2],\n",
    "                dropout_rate=dropout_rate,\n",
    "                lstm_units=lstm_units\n",
    "            )\n",
    "\n",
    "            # compile\n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=0.001),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "            )\n",
    "\n",
    "            # class weights\n",
    "            class_weights = class_weight.compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.unique(y_train),\n",
    "                y=y_train\n",
    "            )\n",
    "            class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "            # train\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                class_weight=class_weights,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # save results\n",
    "            tag = f'dropout{dropout_rate}_lstm{lstm_units}'\n",
    "            results = evaluate_and_save(\n",
    "                model,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                var=('config', tag),\n",
    "                trial=trial,\n",
    "                results=results\n",
    "            )\n",
    "            trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212256a-60f0-40f4-b8a1-c5d0edf0be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_results(results, tuning_param='config')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449540ae-2e05-4b87-bd25-2df527621796",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "We experiment with learning rates to find a balance between fast convergence and stable, accurate blitz predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81269dd-f244-4581-8d80-517dfb2ea6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrs to test\n",
    "learning_rates = [0.01, 0.001, 0.0005, 0.0001]\n",
    "n_trials = 5\n",
    "\n",
    "# loop thru lrs\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for i in range(n_trials):\n",
    "        print(f'Trial {i+1}/{n_trials} â€” Learning rate: {lr}')\n",
    "\n",
    "        # create model\n",
    "        model = create_blitz_rnn_model(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            dropout_rate=0.3,\n",
    "            lstm_units=256\n",
    "        )\n",
    "\n",
    "        # compile\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "        )\n",
    "\n",
    "        # class weights\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        # train\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # log and save\n",
    "        tag = f'lr{lr}'\n",
    "        results = evaluate_and_save(\n",
    "            model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            var=('lr', tag),\n",
    "            trial=trial,\n",
    "            results=results\n",
    "        )\n",
    "        trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183349ce-b43d-4db4-a9e5-a76d525808e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output results\n",
    "summary = summarize_results(results, tuning_param='lr')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c8bc7-d234-4bcf-8adc-bc88fef32825",
   "metadata": {},
   "source": [
    "## Binary Focal Loss\n",
    "We use binary focal loss to address class imbalance by making the model focus more on misclassified examples rather than defaulting to the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2de72a-8cd9-44b7-9703-3a7ae2033cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy, BinaryFocalCrossentropy\n",
    "\n",
    "# loss fns to compare\n",
    "loss_types = {\n",
    "    'bce': BinaryCrossentropy(),\n",
    "    'focal': BinaryFocalCrossentropy(\n",
    "        gamma=2.0,\n",
    "        alpha=0.25,\n",
    "        from_logits=False,\n",
    "        name='binary_focal_crossentropy'\n",
    "    )\n",
    "}\n",
    "\n",
    "# loop thru loss fns\n",
    "n_trials = 5\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for loss_name, loss_fn in loss_types.items():\n",
    "    for i in range(n_trials):\n",
    "        print(f'Trial {i+1}/{n_trials} â€” Loss: {loss_name}')\n",
    "\n",
    "        model = create_blitz_rnn_model(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            dropout_rate=0.3,\n",
    "            lstm_units=256\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.0005),\n",
    "            loss=loss_fn,\n",
    "            metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "        )\n",
    "\n",
    "        # Compute class weights for imbalance\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_recall', patience=5, restore_best_weights=True)]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=40,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        results = evaluate_and_save(\n",
    "            model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            var=('loss_fn', loss_name),\n",
    "            trial=trial,\n",
    "            results=results\n",
    "        )\n",
    "\n",
    "        trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e6d92-6afd-4113-ad4c-2e30b2e6a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_results(results, tuning_param='loss_fn')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab2af3-2ed8-4070-9b5b-3c44a1b11597",
   "metadata": {},
   "source": [
    "## Model Architecture  \n",
    "We explore different model architectures to evaluate whether we can improve recall or achieve comparable performance with simpler, more efficient designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac1ad5-03b2-4053-9e37-ddc7d0e5fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_variant(n_timesteps, n_features, \n",
    "                       lstm_units=256, \n",
    "                       dropout_rate=0.3, \n",
    "                       bidirectional=True, \n",
    "                       num_lstm_layers=2, \n",
    "                       dense_width=512):\n",
    "    \n",
    "    def lstm_layer(return_sequences=False):\n",
    "        base = LSTM(lstm_units, return_sequences=return_sequences)\n",
    "        return Bidirectional(base) if bidirectional else base\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_timesteps, n_features)))\n",
    "    \n",
    "    model.add(lstm_layer(return_sequences=(num_lstm_layers == 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    if num_lstm_layers == 2:\n",
    "        model.add(lstm_layer(return_sequences=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(dense_width, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(dense_width, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8667f-62cf-4a39-9240-d812b9a3c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# architecture grid\n",
    "lstm_units = 256\n",
    "\n",
    "architectures = list(itertools.product(\n",
    "    [256, 512],      # Dense width\n",
    "    [True, False],   # Bidirectional\n",
    "    [1, 2]           # LSTM layers\n",
    "))\n",
    "\n",
    "n_trials = 3\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for dense_width, bidirectional, num_lstm_layers in architectures:\n",
    "    for i in range(n_trials):\n",
    "        config_name = f\"lstm{lstm_units}_dense{dense_width}_{'bi' if bidirectional else 'uni'}_{num_lstm_layers}L\"\n",
    "        print(f\"Trial {i+1}/{n_trials} â€” {config_name}\")\n",
    "\n",
    "        model = create_rnn_variant(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            lstm_units=lstm_units,\n",
    "            dense_width=dense_width,\n",
    "            bidirectional=bidirectional,\n",
    "            num_lstm_layers=num_lstm_layers\n",
    "        )\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        results = evaluate_and_save(\n",
    "            model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            var=('architecture', config_name),\n",
    "            trial=trial,\n",
    "            results=results\n",
    "        )\n",
    "        trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fd430-9923-405f-b1c7-e3451cc64f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_results(results, tuning_param='architecture')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3434e6-834c-4802-8f3e-a1aebf8c72f7",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "Based on our experimentation, our final model architecture should be as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5499a52-52eb-498b-b821-767a98401e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug in final model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb04dff-c0ff-46cc-97bf-5bfe41e475e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model\n",
    "loss, accuracy, auc, precision, recall = final_model.evaluate(X_test, y_test)\n",
    "print(f\"Final Test Loss: {loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Final Test AUC: {auc:.4f}\")\n",
    "print(f\"Final Test Precision: {precision:.4f}\")\n",
    "print(f\"Final Test Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
