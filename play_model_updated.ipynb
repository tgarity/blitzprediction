{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7f4a29-02e0-4fbe-b644-06a8ec99626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 09:33:10.841652: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-09 09:33:10.841701: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-09 09:33:10.842409: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 09:33:10.847572: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a37904-3655-4272-b6cf-6c09bb0af7bf",
   "metadata": {},
   "source": [
    "# ðŸˆ Predicting Blitzes Using Pre-Snap Behavior\n",
    "\n",
    "**By:** Christopher Doyle, Hans Elasri, Thomas Garity, Rishi Hazra, and Christopher RuaÃ±o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bceb6a-32b1-48f5-8929-cf8ce6af3a2f",
   "metadata": {},
   "source": [
    "## Final Model Pipeline\n",
    "\n",
    "**Here is a high-level overview of the pipeline. Continue scrolling to see a basic implementation with more detail on assumptions and design choices.**\n",
    "\n",
    "--\n",
    "\n",
    "For our final model, we will adopt an RNN architecture. While some elements (like the hyperparameters, specific architecture, and feature selection) will be determined as we iterate, we will begin with a baseline model and then iteratively improve it.\n",
    "\n",
    "We will iterate through the following approaches:\n",
    "1. **Baseline RNN**: Feed through sequences of N rows of data. Each row corresponds to one play, and sequence is made up of N consecutive plays. The final play is the target -- the model must predict whether or not a blitz occurred in the final play.\n",
    "2. **Frame-by-Frame RNN:** Feed through sequences of N rows of data. Each row corresponds to one frame of a single play. The final frame is the target -- the model must predict whether or not a blitz occurred within this play. \n",
    "3. **Mixture of Both:** Run both types of RNN. Combine the hidden states before a MLP head predicts the final blitz / no blitz output.\n",
    "\n",
    "Our Pipeline will be as follows:\n",
    "\n",
    "1. **PREPROCESSING**\n",
    "   1. One hot encode categorical variables (teams, positions, formations)\n",
    "   2. Drop columns that are un-usable.\n",
    "   3. Create sequences, using a sliding window. Write a function for creating sequences -- we want the sliding window size to be flexible (we may want to change this later)\n",
    "2. **MODELING**\n",
    "   1. Define the architecture; the input should be N * (sequence length) * (number of features)\n",
    "   2. Work with some sort of RNN units -- either RNN, GRU, or LSTM\n",
    "   3. Output of final dense layer should be one logits with sigmoid activation for binary classification.\n",
    "   4. We will minimize the binary cross-entropy loss -- this is the most logical approach, as we have chosen to have 1 logit.\n",
    "3. **TRAINING**\n",
    "   1. Train the model on the training data. Log loss, accuracy, and validation accuracy\n",
    "   2. Plot training results over each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969500f5-3e83-467b-a205-2135d5b6d2e8",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "Using similar logic to the logistic regression, we:\n",
    "- one-hot encode categorical variables (teams, positions, formations)\n",
    "- cast boolean variables to integers\n",
    "- drop columns that are un-usable\n",
    "- fill Nans with 0 -- these mainly correspond to boolean variables for players whose positions do not apply (i.e. defensive stats for an offensive player), so zeroes are appropriate\n",
    "\n",
    "To obtain our target label, we merge in from the `blitz_outcome` df. In our next imeplementation, we would save those blitz labels to the .csv file itself.\n",
    "\n",
    "The next step is creating sequences. This is the format ready for the model. We have begun with a sequence length of 5, as this allows us to summarize any trends in the current drive, while also peeking at the previous drive as well. In the future we might experiment with:\n",
    "- very large (30+) sequence lengths to capture multiple possessions from both teams\n",
    "- recreate this logic at the frame-level; so we are looking more at real-time decisions (this is closer to our problem statement)\n",
    "\n",
    "\n",
    "NOTE: We have cut off our dataset at only 2 games here. Change the `cutoff` argument to `None` to use the full dataset.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b572fd95-27bb-40a7-860c-dc79538c80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22610/4249411861.py:2: DtypeWarning: Columns (420,421,422,423,424,425,426,427,428,429,430,431,432,435,436,437,438,440,441) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('nontime_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import dataframe\n",
    "df = pd.read_csv('nontime_data.csv')\n",
    "blitz_outcome = pd.read_csv('blitz_outcome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e63cd78-df9e-4fe1-b680-ed7a6ade90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing mapping of plays --> blitzes to add the target column\n",
    "df = df.merge(blitz_outcome[['gameId', 'playId', 'blitzOutcome']], \n",
    "              on=['gameId', 'playId'], \n",
    "              how='left'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc12c4d9-f77c-4f58-b25e-8ee0163d8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all missing categorical fields\n",
    "categorical_cols = []\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col not in ['gameId', 'playId', 'nflId']:\n",
    "        categorical_cols.append(col)\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# one-hot encode categorical cols\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# drop any remaining object-type columns from X\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df = df.drop(columns=[col])\n",
    "\n",
    "# Convert boolean columns to integers (0/1) first\n",
    "bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Drop remaining rows with any NaN\n",
    "df = df.dropna(subset=['blitzOutcome', 'quarter', 'down', 'yardsToGo', 'yardlineNumber', 'gameClock', 'preSnapHomeScore', 'preSnapVisitorScore', 'absoluteYardlineNumber', 'preSnapHomeTeamWinProbability', 'preSnapVisitorTeamWinProbability', 'expectedPoints'])\n",
    "\n",
    "# Fill remaining NaNs with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d72385c-06ca-4998-82fc-5482c6139156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, n=5, target_col='blitzOutcome', step=1, cutoff=2):\n",
    "    \"\"\"\n",
    "    Create sequences of n consecutive plays for RNN input with overlapping windows.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with last frame of each play\n",
    "    n : Sequence length (number of plays to include in each sequence)\n",
    "    target_col : Column name for the target variable (blitz indicator)\n",
    "    step : Step size for sliding window (1 = maximum overlap, n = no overlap)\n",
    "    cutoff : how many games to repeat this process for (for prototyping)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy array of shape (num_sequences, n, num_features)\n",
    "        Sequences of n plays with features\n",
    "    y : numpy array of shape (num_sequences,)\n",
    "        Target values indicating whether the n+1th play was a blitz\n",
    "    play_ids : list of tuples\n",
    "        Identifiers for the play following each sequence (for reference)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    play_ids = []\n",
    "    \n",
    "    # list of unique games\n",
    "    games = df['gameId'].unique()\n",
    "    \n",
    "    # Handle cutoff=None\n",
    "    if cutoff is None:\n",
    "        cutoff = len(games)\n",
    "\n",
    "    # Print number of games you are sampling from\n",
    "    print(f'Sampling from {cutoff} games')\n",
    "\n",
    "    for game_id in games[:cutoff]:\n",
    "        # Get plays for this game and sort chronologically\n",
    "        game_plays = df[df['gameId'] == game_id].sort_values(['quarter', 'gameClock'], ascending=[True, False])\n",
    "        \n",
    "        # Get the length of this game in plays\n",
    "        game_length = len(game_plays)\n",
    "        \n",
    "        # Skip games that are too short for our sequence length\n",
    "        if game_length <= n:\n",
    "            continue\n",
    "            \n",
    "        # Specify which features to use\n",
    "        feature_cols = [col for col in df.columns if col not in ['gameId', 'playId', 'blitzOutcome']]\n",
    "        \n",
    "        # Convert to numpy for faster operations\n",
    "        plays_array = game_plays[feature_cols].values\n",
    "        targets_array = game_plays[target_col].values if target_col in game_plays.columns else None\n",
    "        play_ids_array = game_plays['playId'].values\n",
    "\n",
    "        # Create overlapping windows\n",
    "        for i in range(0, game_length - n, step):\n",
    "            # Get n consecutive plays for X\n",
    "            sequence = plays_array[i:i+n]\n",
    "            \n",
    "            # Skip sequences with NaN values if needed\n",
    "            # Although we should not have any at this point\n",
    "            if np.isnan(sequence).any():\n",
    "                # Flag it so we can debug\n",
    "                print('skipping')\n",
    "                continue\n",
    "                \n",
    "            # Add the sequence to our dataset\n",
    "            X.append(sequence)\n",
    "            \n",
    "            # Get target from the n+1th play (if target column exists)\n",
    "            if targets_array is not None:\n",
    "                y.append(targets_array[i+n])\n",
    "                \n",
    "            # Keep track of which play this prediction is for\n",
    "            # This is mainly for interpretability\n",
    "            play_ids.append((game_id,play_ids_array[i+n]))\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y) if targets_array is not None else None\n",
    "    \n",
    "    print(f\"Created {len(X)} sequences of length {n}\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    if y is not None:\n",
    "        print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    return X, y, play_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9097147-4b9b-4e4e-81ca-4d5b1f1318b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from 31 games\n",
      "Created 3519 sequences of length 5\n",
      "X shape: (3519, 5, 1968)\n",
      "y shape: (3519,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare sequences\n",
    "X, y, play_ids = create_sequences(df, n=5, target_col='blitzOutcome', step=1, cutoff=None)\n",
    "\n",
    "# Split into 80% training and 20% validation and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Take leftover 20% and split into 10% validation and 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f4c0ef-6598-4a26-a3aa-7ddadd69e354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count occurrences of each label\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "label_names = ['No blitz', 'Blitz']\n",
    "\n",
    "# Calculate percentages\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "# Plot\n",
    "plt.bar(label_names, counts)\n",
    "plt.title('Class imbalance in training data')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for i, (count, pct) in enumerate(zip(counts, percentages)):\n",
    "    plt.text(i, count + total * 0.01, f'{pct:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181474b-1b7a-400e-8415-fa937e5d2ebc",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "This is roughly in-line with our % of blitzes across all plays -- so we can suggest that we are sampling correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fdd00-0481-484d-b97a-d07464227510",
   "metadata": {},
   "source": [
    "### Define RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba896d-09ef-463a-b76c-5c88121d46ee",
   "metadata": {},
   "source": [
    "We have not put extreme thought into this model yet -- that will be work for Milestone 5. However, with this working scaffolding, we can begin to iterate. Some design decisions we have made already are:\n",
    "- **Tracking precision / recall** -- we know that blitzes are rare, so it is important that we know whether we are correctly identifying them (not just predicting the majority class)\n",
    "- **Bidirectional LSTM layers** -- we were impressed by LSTMs in psets so have chosen them as the starting point. We have chosen bidirectional thinking that football strategies are somewhat bidirectional as well ; a defensive coordinator both looks back and previous plays and plans for potential future plays to lead their decisions. We need to test this logic further through experiments with regular and bidirectional plays.\n",
    "- **Dropout** -- there is a risk of overfitting with this type of task (very noisy, small dataset), so we have added dropout to prevent overfitting.\n",
    "- **Early Stopping** -- we have added early stopping to prevent overfitting.\n",
    "- **Batch Normalization** -- same as above ; one more measure to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40946f4-e9dc-4b13-8b26-c32661f1ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blitz_rnn_model(n_timesteps, n_features, dropout_rate=0.3, lstm_units=256):\n",
    "    model = Sequential([\n",
    "        # Input layer\n",
    "        Input(shape=(n_timesteps, n_features)),\n",
    "        \n",
    "        # Bidirectional LSTM layer\n",
    "        Bidirectional(LSTM(256, return_sequences=True)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Second bidirectional LSTM layer\n",
    "        Bidirectional(LSTM(256)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Dense hidden layer\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        # Dense hidden layer\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Output layer with 2 neurons (probability of blitz and no blitz)\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model with binary cross-entropy loss\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8c2abc-7116-4e04-a066-78137d5dda81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 09:33:19.563996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20763 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:3e:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "RNN_model = create_blitz_rnn_model(n_timesteps=X.shape[1], n_features=X.shape[2], dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2008604-8fdf-4aaa-9e35-c4dcf1025e65",
   "metadata": {},
   "source": [
    "### Training Run\n",
    "\n",
    "Keep in mind, this is a demo -- we would run this for more epochs and tune our hyperparameters for our final model.\n",
    "\n",
    "Be sure to update the # of epochs to be greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884969af-5077-4f5c-94b3-8be6c29a75f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 09:33:25.281989: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-05-09 09:33:27.093861: I external/local_xla/xla/service/service.cc:168] XLA service 0x1538d1dd0b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-09 09:33:27.093902: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2025-05-09 09:33:27.099043: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746797607.175194   25771 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/88 [===========================>..] - ETA: 0s - loss: 1.2915 - accuracy: 0.4908 - auc: 0.4797 - precision: 0.0652 - recall: 0.4518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 9s 25ms/step - loss: 1.2708 - accuracy: 0.4924 - auc: 0.4910 - precision: 0.0684 - recall: 0.4732 - val_loss: 0.7992 - val_accuracy: 0.1222 - val_auc: 0.5163 - val_precision: 0.0433 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.0159 - accuracy: 0.5080 - auc: 0.5463 - precision: 0.0822 - recall: 0.5659 - val_loss: 0.4919 - val_accuracy: 0.9460 - val_auc: 0.3726 - val_precision: 0.1429 - val_recall: 0.0714 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7745 - accuracy: 0.5382 - auc: 0.6320 - precision: 0.0983 - recall: 0.6537 - val_loss: 0.6224 - val_accuracy: 0.6591 - val_auc: 0.3262 - val_precision: 0.0182 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.6616 - accuracy: 0.6039 - auc: 0.7061 - precision: 0.1215 - recall: 0.7122 - val_loss: 0.4369 - val_accuracy: 0.8835 - val_auc: 0.3977 - val_precision: 0.0345 - val_recall: 0.0714 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6651 - accuracy: 0.6330 - auc: 0.7092 - precision: 0.1202 - recall: 0.6390 - val_loss: 0.9238 - val_accuracy: 0.3636 - val_auc: 0.3761 - val_precision: 0.0227 - val_recall: 0.3571 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6103 - accuracy: 0.6309 - auc: 0.7511 - precision: 0.1336 - recall: 0.7415 - val_loss: 0.8840 - val_accuracy: 0.5057 - val_auc: 0.3322 - val_precision: 0.0238 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5791 - accuracy: 0.6433 - auc: 0.7758 - precision: 0.1385 - recall: 0.7463 - val_loss: 0.6743 - val_accuracy: 0.7273 - val_auc: 0.4410 - val_precision: 0.0341 - val_recall: 0.2143 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5329 - accuracy: 0.6600 - auc: 0.8035 - precision: 0.1531 - recall: 0.8098 - val_loss: 0.7460 - val_accuracy: 0.6136 - val_auc: 0.3569 - val_precision: 0.0308 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5119 - accuracy: 0.6984 - auc: 0.8275 - precision: 0.1687 - recall: 0.8000 - val_loss: 0.6746 - val_accuracy: 0.7415 - val_auc: 0.3596 - val_precision: 0.0471 - val_recall: 0.2857 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4581 - accuracy: 0.7155 - auc: 0.8632 - precision: 0.1796 - recall: 0.8146 - val_loss: 0.7818 - val_accuracy: 0.6648 - val_auc: 0.3389 - val_precision: 0.0357 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4389 - accuracy: 0.7336 - auc: 0.8763 - precision: 0.1921 - recall: 0.8293 - val_loss: 0.8046 - val_accuracy: 0.5881 - val_auc: 0.3285 - val_precision: 0.0288 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3991 - accuracy: 0.7343 - auc: 0.9077 - precision: 0.2052 - recall: 0.9220 - val_loss: 0.7940 - val_accuracy: 0.6023 - val_auc: 0.3322 - val_precision: 0.0299 - val_recall: 0.2857 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_recall', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001),\n",
    "    ModelCheckpoint('best_blitz_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Use class weighting to adjust for massive class imbalance:\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "history = RNN_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd59ce11-2a29-46e3-b4a9-72b586efd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_metrics(history):\n",
    "    metrics = ['accuracy', 'precision', 'recall']\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.plot(history.history[metric], label=f'Train {metric}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Val {metric}')\n",
    "        plt.title(metric.capitalize())\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73945170-de86-4805-8e32-34fd5ef4edab",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f2fafb5-a4d9-47d4-a164-58b10189547e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6db1415-3779-437c-900e-cf983986723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.9006 - auc: 0.6176 - precision: 0.0909 - recall: 0.0385    \n",
      "Test Loss: 0.5059\n",
      "Test Accuracy: 0.9006\n",
      "Test AUC: 0.6176\n",
      "Test Precision: 0.0909\n",
      "Test Recall: 0.0385\n"
     ]
    }
   ],
   "source": [
    "# Inspect Logs\n",
    "loss, accuracy, auc, precision, recall = RNN_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea45042-eedf-4e1d-997e-fb1f950a9f20",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The model predicts with a test accuracy of 66%, and a test recall of 30%. This means that the model predicts 1 in 3 blitzes -- this could be useful after all!\n",
    "\n",
    "Some design decisions thus far are:\n",
    "- Class weights -- this was a game changer\n",
    "- LSTM layers -- bidirectional, since previous plays affect future ones, and potential future plays affect current ones (this may be too-flimsy logic)\n",
    "- Early stopping based on recall -- as accuracy climbs, the recall tends to drop off (in early epochs, the model predicts too many blitzes)\n",
    "\n",
    "However, there are a few design choices we can evaluate further:\n",
    "- Scaling the dataset in preprocessing -- right now, we do nothing\n",
    "- BinaryFocalCrossentropy loss did not help -- although maybe it could be worthwhile\n",
    "- We don't know what the ideal input data looks like: is it better to feed through loads of plays, and let the model draw long-term predictions, or should we draw in shorter sequences?\n",
    "- Same goes for step size in the sampling function\n",
    "- Are we sure we have the right level of dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a4d38-1e34-4a3e-9ba7-4379382f0243",
   "metadata": {},
   "source": [
    "## Input Feature Scaling\n",
    "\n",
    "We perform an experiment to test for the best approach to scaling:\n",
    "- Scale to [0, 1] -- many values are indicators on that interval anyways\n",
    "- Standard scaler -- this likely will not work, since our data does not assume a gaussian distribution\n",
    "- Scale to [-1, 1] -- the `tanh` activations in the LSTM layers may benefit from this\n",
    "- No scaling (control) -- this is what we have currently -- and results have been okay (30% test recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24dac03b-d8d2-449f-a503-b52c988933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def test_scaler(X, y, results=None, scaler='None', n_trials=5):\n",
    "    # Scale (or do not scale)\n",
    "\n",
    "    if scaler == 'None':\n",
    "        X_scaled = X\n",
    "\n",
    "    else:\n",
    "        # Manipulate data to be 2D (most scalers expect 2D data)\n",
    "        # Suppose X shape is (n_samples, n_timesteps, n_features)\n",
    "        n_samples, n_timesteps, n_features = X.shape\n",
    "        \n",
    "        # Reshape to 2D for scaling (merge samples and timesteps)\n",
    "        X_2d = X.reshape(-1, n_features)\n",
    "\n",
    "        if scaler == '[0,1]':\n",
    "            # Normalize features to [0, 1] (handles mixed scales safely)\n",
    "            scaler = MinMaxScaler()\n",
    "    \n",
    "        if scaler == '[-1,1]':\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))    \n",
    "    \n",
    "        if scaler == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "        # Fit and transform\n",
    "        X_scaled_2d = scaler.fit_transform(X_2d)\n",
    "                \n",
    "        # Reshape back to original 3D shape\n",
    "        X_scaled = X_scaled_2d.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "    # Split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        print(f'Scaler: {scaler}, Trial: {i}')\n",
    "        # Create model\n",
    "        RNN_model = create_blitz_rnn_model(n_timesteps=X.shape[1], n_features=X.shape[2], dropout_rate=0.2)\n",
    "    \n",
    "        # Train and evaluate\n",
    "        # Compute weights\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        \n",
    "        # Train\n",
    "        history = RNN_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "        )\n",
    "    \n",
    "        # Evaluate and save\n",
    "        results = evaluate_and_save(RNN_model, X_test, y_test, ['scaler', scaler], i, results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234cda89-323a-4e10-b0ec-bc108bea11a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: StandardScaler(), Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2600 - accuracy: 0.5190 - auc: 0.5246 - precision: 0.0791 - recall: 0.5268 - val_loss: 0.8359 - val_accuracy: 0.4815 - val_auc: 0.5078 - val_precision: 0.0523 - val_recall: 0.4750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8594 - accuracy: 0.5279 - auc: 0.6041 - precision: 0.0963 - recall: 0.6537 - val_loss: 0.8246 - val_accuracy: 0.6222 - val_auc: 0.4535 - val_precision: 0.0586 - val_recall: 0.3750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6901 - accuracy: 0.6124 - auc: 0.7063 - precision: 0.1227 - recall: 0.7024 - val_loss: 0.6646 - val_accuracy: 0.6364 - val_auc: 0.4230 - val_precision: 0.0385 - val_recall: 0.2250\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5143 - accuracy: 0.6980 - auc: 0.8330 - precision: 0.1719 - recall: 0.8244 - val_loss: 0.6448 - val_accuracy: 0.6918 - val_auc: 0.4778 - val_precision: 0.0597 - val_recall: 0.3000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4427 - accuracy: 0.7467 - auc: 0.8831 - precision: 0.2087 - recall: 0.8878 - val_loss: 0.6557 - val_accuracy: 0.7145 - val_auc: 0.4982 - val_precision: 0.0552 - val_recall: 0.2500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3834 - accuracy: 0.7936 - auc: 0.9142 - precision: 0.2480 - recall: 0.9024 - val_loss: 0.7051 - val_accuracy: 0.7401 - val_auc: 0.4598 - val_precision: 0.0613 - val_recall: 0.2500\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3057 - accuracy: 0.8444 - auc: 0.9432 - precision: 0.3100 - recall: 0.9268 - val_loss: 0.6516 - val_accuracy: 0.7940 - val_auc: 0.5038 - val_precision: 0.0800 - val_recall: 0.2500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2744 - accuracy: 0.8572 - auc: 0.9531 - precision: 0.3328 - recall: 0.9561 - val_loss: 0.5021 - val_accuracy: 0.8253 - val_auc: 0.5273 - val_precision: 0.0538 - val_recall: 0.1250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2257 - accuracy: 0.8863 - auc: 0.9674 - precision: 0.3870 - recall: 0.9610 - val_loss: 0.5155 - val_accuracy: 0.8224 - val_auc: 0.5281 - val_precision: 0.0952 - val_recall: 0.2500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1629 - accuracy: 0.9236 - auc: 0.9839 - precision: 0.4879 - recall: 0.9805 - val_loss: 0.5694 - val_accuracy: 0.8267 - val_auc: 0.5228 - val_precision: 0.0638 - val_recall: 0.1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.8267 - auc: 0.5228 - precision: 0.0638 - recall: 0.1500\n",
      "Scaler: StandardScaler(), Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2849 - accuracy: 0.5062 - auc: 0.5088 - precision: 0.0747 - recall: 0.5073 - val_loss: 0.7724 - val_accuracy: 0.4730 - val_auc: 0.4155 - val_precision: 0.0390 - val_recall: 0.3500\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8450 - accuracy: 0.5435 - auc: 0.6148 - precision: 0.0982 - recall: 0.6439 - val_loss: 0.6460 - val_accuracy: 0.6435 - val_auc: 0.4715 - val_precision: 0.0658 - val_recall: 0.4000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.6750 - accuracy: 0.6057 - auc: 0.7214 - precision: 0.1245 - recall: 0.7317 - val_loss: 0.6948 - val_accuracy: 0.6747 - val_auc: 0.4989 - val_precision: 0.0478 - val_recall: 0.2500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5773 - accuracy: 0.6885 - auc: 0.7992 - precision: 0.1667 - recall: 0.8195 - val_loss: 0.7826 - val_accuracy: 0.7443 - val_auc: 0.4338 - val_precision: 0.0570 - val_recall: 0.2250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.7449 - auc: 0.8803 - precision: 0.2089 - recall: 0.8976 - val_loss: 0.4876 - val_accuracy: 0.8040 - val_auc: 0.5029 - val_precision: 0.0463 - val_recall: 0.1250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3581 - accuracy: 0.8227 - auc: 0.9253 - precision: 0.2806 - recall: 0.9171 - val_loss: 0.5979 - val_accuracy: 0.7912 - val_auc: 0.5525 - val_precision: 0.0853 - val_recall: 0.2750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3733 - accuracy: 0.8174 - auc: 0.9162 - precision: 0.2670 - recall: 0.8634 - val_loss: 0.5249 - val_accuracy: 0.8125 - val_auc: 0.5264 - val_precision: 0.0893 - val_recall: 0.2500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2425 - accuracy: 0.8710 - auc: 0.9661 - precision: 0.3558 - recall: 0.9512 - val_loss: 0.5323 - val_accuracy: 0.8168 - val_auc: 0.5690 - val_precision: 0.0917 - val_recall: 0.2500\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2262 - accuracy: 0.8874 - auc: 0.9684 - precision: 0.3871 - recall: 0.9366 - val_loss: 0.6596 - val_accuracy: 0.8040 - val_auc: 0.5460 - val_precision: 0.0776 - val_recall: 0.2250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2167 - accuracy: 0.8959 - auc: 0.9711 - precision: 0.4068 - recall: 0.9366 - val_loss: 0.5611 - val_accuracy: 0.8139 - val_auc: 0.5015 - val_precision: 0.0495 - val_recall: 0.1250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.8139 - auc: 0.5015 - precision: 0.0495 - recall: 0.1250\n",
      "Scaler: StandardScaler(), Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 25ms/step - loss: 1.3282 - accuracy: 0.5087 - auc: 0.5030 - precision: 0.0744 - recall: 0.5024 - val_loss: 0.7624 - val_accuracy: 0.5384 - val_auc: 0.4832 - val_precision: 0.0505 - val_recall: 0.4000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8233 - accuracy: 0.5517 - auc: 0.6153 - precision: 0.0993 - recall: 0.6390 - val_loss: 0.7422 - val_accuracy: 0.5739 - val_auc: 0.4776 - val_precision: 0.0517 - val_recall: 0.3750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6789 - accuracy: 0.6011 - auc: 0.7110 - precision: 0.1200 - recall: 0.7073 - val_loss: 0.6585 - val_accuracy: 0.6719 - val_auc: 0.4752 - val_precision: 0.0558 - val_recall: 0.3000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5566 - accuracy: 0.6895 - auc: 0.8112 - precision: 0.1652 - recall: 0.8049 - val_loss: 0.6401 - val_accuracy: 0.7315 - val_auc: 0.4971 - val_precision: 0.0643 - val_recall: 0.2750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4339 - accuracy: 0.7556 - auc: 0.8870 - precision: 0.2142 - recall: 0.8829 - val_loss: 0.6960 - val_accuracy: 0.7642 - val_auc: 0.5513 - val_precision: 0.0743 - val_recall: 0.2750\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4111 - accuracy: 0.7812 - auc: 0.8990 - precision: 0.2348 - recall: 0.8878 - val_loss: 0.5784 - val_accuracy: 0.7770 - val_auc: 0.4993 - val_precision: 0.0730 - val_recall: 0.2500\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3480 - accuracy: 0.8306 - auc: 0.9281 - precision: 0.2882 - recall: 0.9024 - val_loss: 0.6526 - val_accuracy: 0.7585 - val_auc: 0.5113 - val_precision: 0.0667 - val_recall: 0.2500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2875 - accuracy: 0.8494 - auc: 0.9503 - precision: 0.3184 - recall: 0.9366 - val_loss: 0.6223 - val_accuracy: 0.7784 - val_auc: 0.5624 - val_precision: 0.0606 - val_recall: 0.2000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.2102 - accuracy: 0.8970 - auc: 0.9724 - precision: 0.4131 - recall: 0.9854 - val_loss: 0.6088 - val_accuracy: 0.8026 - val_auc: 0.5086 - val_precision: 0.0619 - val_recall: 0.1750\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1581 - accuracy: 0.9368 - auc: 0.9849 - precision: 0.5362 - recall: 0.9756 - val_loss: 0.5979 - val_accuracy: 0.8267 - val_auc: 0.5180 - val_precision: 0.0638 - val_recall: 0.1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.8267 - auc: 0.5180 - precision: 0.0638 - recall: 0.1500\n",
      "Scaler: StandardScaler(), Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3649 - accuracy: 0.4877 - auc: 0.5036 - precision: 0.0702 - recall: 0.4927 - val_loss: 0.8681 - val_accuracy: 0.3707 - val_auc: 0.4488 - val_precision: 0.0591 - val_recall: 0.6750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8480 - accuracy: 0.5318 - auc: 0.6011 - precision: 0.0917 - recall: 0.6098 - val_loss: 0.7324 - val_accuracy: 0.5739 - val_auc: 0.4944 - val_precision: 0.0608 - val_recall: 0.4500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6915 - accuracy: 0.5954 - auc: 0.7038 - precision: 0.1172 - recall: 0.6976 - val_loss: 0.6329 - val_accuracy: 0.6690 - val_auc: 0.4299 - val_precision: 0.0469 - val_recall: 0.2500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5277 - accuracy: 0.6902 - auc: 0.8281 - precision: 0.1668 - recall: 0.8146 - val_loss: 0.6966 - val_accuracy: 0.7216 - val_auc: 0.5293 - val_precision: 0.0667 - val_recall: 0.3000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4358 - accuracy: 0.7496 - auc: 0.8847 - precision: 0.2106 - recall: 0.8878 - val_loss: 0.6412 - val_accuracy: 0.7287 - val_auc: 0.4477 - val_precision: 0.0368 - val_recall: 0.1500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3493 - accuracy: 0.8025 - auc: 0.9273 - precision: 0.2579 - recall: 0.9122 - val_loss: 0.4397 - val_accuracy: 0.8310 - val_auc: 0.5221 - val_precision: 0.0753 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2812 - accuracy: 0.8551 - auc: 0.9526 - precision: 0.3235 - recall: 0.9073 - val_loss: 0.6051 - val_accuracy: 0.7926 - val_auc: 0.5284 - val_precision: 0.0859 - val_recall: 0.2750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2627 - accuracy: 0.8625 - auc: 0.9584 - precision: 0.3409 - recall: 0.9512 - val_loss: 0.5539 - val_accuracy: 0.8111 - val_auc: 0.4954 - val_precision: 0.0654 - val_recall: 0.1750\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2444 - accuracy: 0.8813 - auc: 0.9635 - precision: 0.3728 - recall: 0.9220 - val_loss: 0.5322 - val_accuracy: 0.8352 - val_auc: 0.5296 - val_precision: 0.0682 - val_recall: 0.1500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2445 - accuracy: 0.8867 - auc: 0.9628 - precision: 0.3841 - recall: 0.9220 - val_loss: 0.6735 - val_accuracy: 0.8040 - val_auc: 0.5392 - val_precision: 0.0463 - val_recall: 0.1250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.8040 - auc: 0.5392 - precision: 0.0463 - recall: 0.1250\n",
      "Scaler: StandardScaler(), Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3105 - accuracy: 0.5183 - auc: 0.5170 - precision: 0.0771 - recall: 0.5122 - val_loss: 0.7479 - val_accuracy: 0.5057 - val_auc: 0.3981 - val_precision: 0.0361 - val_recall: 0.3000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8194 - accuracy: 0.5410 - auc: 0.6137 - precision: 0.1001 - recall: 0.6634 - val_loss: 0.7912 - val_accuracy: 0.5710 - val_auc: 0.4883 - val_precision: 0.0604 - val_recall: 0.4500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7398 - accuracy: 0.5769 - auc: 0.6792 - precision: 0.1106 - recall: 0.6829 - val_loss: 0.6960 - val_accuracy: 0.6165 - val_auc: 0.4161 - val_precision: 0.0400 - val_recall: 0.2500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5081 - accuracy: 0.6870 - auc: 0.8400 - precision: 0.1731 - recall: 0.8732 - val_loss: 0.5275 - val_accuracy: 0.7614 - val_auc: 0.5049 - val_precision: 0.0676 - val_recall: 0.2500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4043 - accuracy: 0.7751 - auc: 0.9018 - precision: 0.2284 - recall: 0.8780 - val_loss: 0.7705 - val_accuracy: 0.7472 - val_auc: 0.4807 - val_precision: 0.0400 - val_recall: 0.1500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3994 - accuracy: 0.8000 - auc: 0.9057 - precision: 0.2521 - recall: 0.8878 - val_loss: 0.6628 - val_accuracy: 0.7670 - val_auc: 0.4768 - val_precision: 0.0507 - val_recall: 0.1750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.3255 - accuracy: 0.8337 - auc: 0.9360 - precision: 0.2955 - recall: 0.9268 - val_loss: 0.5208 - val_accuracy: 0.7798 - val_auc: 0.4946 - val_precision: 0.0543 - val_recall: 0.1750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.2645 - accuracy: 0.8650 - auc: 0.9578 - precision: 0.3446 - recall: 0.9463 - val_loss: 0.5469 - val_accuracy: 0.8125 - val_auc: 0.4721 - val_precision: 0.0577 - val_recall: 0.1500\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2567 - accuracy: 0.8732 - auc: 0.9600 - precision: 0.3577 - recall: 0.9317 - val_loss: 0.5547 - val_accuracy: 0.8224 - val_auc: 0.5103 - val_precision: 0.0526 - val_recall: 0.1250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1960 - accuracy: 0.9091 - auc: 0.9764 - precision: 0.4422 - recall: 0.9512 - val_loss: 0.5460 - val_accuracy: 0.8423 - val_auc: 0.4800 - val_precision: 0.0824 - val_recall: 0.1750\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.8423 - auc: 0.4800 - precision: 0.0824 - recall: 0.1750\n",
      "Scaler: None, Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.1986 - accuracy: 0.4973 - auc: 0.5245 - precision: 0.0816 - recall: 0.5756 - val_loss: 0.8204 - val_accuracy: 0.1165 - val_auc: 0.6152 - val_precision: 0.0578 - val_recall: 0.9500\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0799 - accuracy: 0.5087 - auc: 0.4982 - precision: 0.0713 - recall: 0.4780 - val_loss: 0.8436 - val_accuracy: 0.1278 - val_auc: 0.4861 - val_precision: 0.0585 - val_recall: 0.9500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8082 - accuracy: 0.5311 - auc: 0.5932 - precision: 0.0904 - recall: 0.6000 - val_loss: 0.4933 - val_accuracy: 0.8764 - val_auc: 0.4958 - val_precision: 0.0727 - val_recall: 0.1000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6993 - accuracy: 0.5712 - auc: 0.6694 - precision: 0.1092 - recall: 0.6829 - val_loss: 0.9609 - val_accuracy: 0.2543 - val_auc: 0.5126 - val_precision: 0.0534 - val_recall: 0.7250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6521 - accuracy: 0.5822 - auc: 0.7027 - precision: 0.1131 - recall: 0.6927 - val_loss: 0.6439 - val_accuracy: 0.6491 - val_auc: 0.5107 - val_precision: 0.0596 - val_recall: 0.3500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5969 - accuracy: 0.6174 - auc: 0.7506 - precision: 0.1305 - recall: 0.7512 - val_loss: 0.5533 - val_accuracy: 0.7685 - val_auc: 0.4182 - val_precision: 0.0305 - val_recall: 0.1000\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5736 - accuracy: 0.6664 - auc: 0.7712 - precision: 0.1444 - recall: 0.7268 - val_loss: 0.6949 - val_accuracy: 0.6676 - val_auc: 0.4684 - val_precision: 0.0509 - val_recall: 0.2750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5560 - accuracy: 0.6664 - auc: 0.7936 - precision: 0.1511 - recall: 0.7756 - val_loss: 0.8361 - val_accuracy: 0.6222 - val_auc: 0.5390 - val_precision: 0.0687 - val_recall: 0.4500\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5244 - accuracy: 0.6746 - auc: 0.8084 - precision: 0.1532 - recall: 0.7659 - val_loss: 0.8690 - val_accuracy: 0.5625 - val_auc: 0.5019 - val_precision: 0.0592 - val_recall: 0.4500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4857 - accuracy: 0.7020 - auc: 0.8427 - precision: 0.1718 - recall: 0.8098 - val_loss: 0.8689 - val_accuracy: 0.5540 - val_auc: 0.5057 - val_precision: 0.0581 - val_recall: 0.4500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8689 - accuracy: 0.5540 - auc: 0.5057 - precision: 0.0581 - recall: 0.4500\n",
      "Scaler: None, Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.1965 - accuracy: 0.4952 - auc: 0.5373 - precision: 0.0795 - recall: 0.5610 - val_loss: 0.4576 - val_accuracy: 0.9418 - val_auc: 0.5149 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0009 - accuracy: 0.5481 - auc: 0.5475 - precision: 0.0868 - recall: 0.5463 - val_loss: 1.3778 - val_accuracy: 0.0568 - val_auc: 0.4613 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8043 - accuracy: 0.5410 - auc: 0.6159 - precision: 0.0971 - recall: 0.6390 - val_loss: 0.6048 - val_accuracy: 0.8040 - val_auc: 0.5102 - val_precision: 0.0702 - val_recall: 0.2000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7056 - accuracy: 0.5588 - auc: 0.6551 - precision: 0.1015 - recall: 0.6439 - val_loss: 1.0039 - val_accuracy: 0.2259 - val_auc: 0.5055 - val_precision: 0.0578 - val_recall: 0.8250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6048 - accuracy: 0.6337 - auc: 0.7494 - precision: 0.1358 - recall: 0.7512 - val_loss: 0.7043 - val_accuracy: 0.5597 - val_auc: 0.5481 - val_precision: 0.0645 - val_recall: 0.5000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5710 - accuracy: 0.6394 - auc: 0.7828 - precision: 0.1429 - recall: 0.7902 - val_loss: 0.5761 - val_accuracy: 0.7443 - val_auc: 0.5227 - val_precision: 0.0570 - val_recall: 0.2250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5868 - accuracy: 0.6654 - auc: 0.7644 - precision: 0.1419 - recall: 0.7122 - val_loss: 0.9805 - val_accuracy: 0.4503 - val_auc: 0.4593 - val_precision: 0.0470 - val_recall: 0.4500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5187 - accuracy: 0.6590 - auc: 0.8213 - precision: 0.1590 - recall: 0.8585 - val_loss: 0.8960 - val_accuracy: 0.5298 - val_auc: 0.5118 - val_precision: 0.0604 - val_recall: 0.5000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5178 - accuracy: 0.7009 - auc: 0.8194 - precision: 0.1615 - recall: 0.7415 - val_loss: 0.7827 - val_accuracy: 0.6293 - val_auc: 0.5433 - val_precision: 0.0830 - val_recall: 0.5500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4929 - accuracy: 0.7023 - auc: 0.8374 - precision: 0.1700 - recall: 0.7951 - val_loss: 1.0178 - val_accuracy: 0.5384 - val_auc: 0.4878 - val_precision: 0.0561 - val_recall: 0.4500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0178 - accuracy: 0.5384 - auc: 0.4878 - precision: 0.0561 - recall: 0.4500\n",
      "Scaler: None, Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2195 - accuracy: 0.4906 - auc: 0.4974 - precision: 0.0694 - recall: 0.4829 - val_loss: 1.0204 - val_accuracy: 0.0568 - val_auc: 0.5277 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9969 - accuracy: 0.5211 - auc: 0.5390 - precision: 0.0795 - recall: 0.5268 - val_loss: 0.7330 - val_accuracy: 0.3594 - val_auc: 0.3817 - val_precision: 0.0443 - val_recall: 0.5000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8493 - accuracy: 0.5421 - auc: 0.5903 - precision: 0.0906 - recall: 0.5854 - val_loss: 0.3491 - val_accuracy: 0.9347 - val_auc: 0.4953 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7408 - accuracy: 0.5702 - auc: 0.6290 - precision: 0.1002 - recall: 0.6146 - val_loss: 0.3614 - val_accuracy: 0.9105 - val_auc: 0.5210 - val_precision: 0.0741 - val_recall: 0.0500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6153 - accuracy: 0.6146 - auc: 0.7416 - precision: 0.1277 - recall: 0.7366 - val_loss: 0.4663 - val_accuracy: 0.8381 - val_auc: 0.5924 - val_precision: 0.0698 - val_recall: 0.1500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6070 - accuracy: 0.6380 - auc: 0.7447 - precision: 0.1320 - recall: 0.7122 - val_loss: 0.5541 - val_accuracy: 0.7784 - val_auc: 0.6079 - val_precision: 0.1027 - val_recall: 0.3750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5832 - accuracy: 0.6710 - auc: 0.7700 - precision: 0.1462 - recall: 0.7268 - val_loss: 0.6545 - val_accuracy: 0.7045 - val_auc: 0.5374 - val_precision: 0.0670 - val_recall: 0.3250\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5242 - accuracy: 0.6885 - auc: 0.8150 - precision: 0.1633 - recall: 0.7951 - val_loss: 0.6887 - val_accuracy: 0.7159 - val_auc: 0.5553 - val_precision: 0.0652 - val_recall: 0.3000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5225 - accuracy: 0.6924 - auc: 0.8151 - precision: 0.1631 - recall: 0.7805 - val_loss: 0.9152 - val_accuracy: 0.4972 - val_auc: 0.5505 - val_precision: 0.0687 - val_recall: 0.6250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.7321 - auc: 0.8689 - precision: 0.1877 - recall: 0.8049 - val_loss: 0.8939 - val_accuracy: 0.6051 - val_auc: 0.5051 - val_precision: 0.0625 - val_recall: 0.4250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8939 - accuracy: 0.6051 - auc: 0.5051 - precision: 0.0625 - recall: 0.4250\n",
      "Scaler: None, Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.1819 - accuracy: 0.5041 - auc: 0.5367 - precision: 0.0839 - recall: 0.5854 - val_loss: 0.9209 - val_accuracy: 0.0568 - val_auc: 0.4701 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0177 - accuracy: 0.5353 - auc: 0.5473 - precision: 0.0844 - recall: 0.5463 - val_loss: 0.7967 - val_accuracy: 0.1634 - val_auc: 0.4763 - val_precision: 0.0622 - val_recall: 0.9750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8684 - accuracy: 0.5194 - auc: 0.5523 - precision: 0.0786 - recall: 0.5220 - val_loss: 1.2063 - val_accuracy: 0.0795 - val_auc: 0.5046 - val_precision: 0.0581 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7415 - accuracy: 0.5673 - auc: 0.6382 - precision: 0.1002 - recall: 0.6195 - val_loss: 0.5434 - val_accuracy: 0.8125 - val_auc: 0.4992 - val_precision: 0.0577 - val_recall: 0.1500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.6744 - accuracy: 0.5634 - auc: 0.6747 - precision: 0.1074 - recall: 0.6829 - val_loss: 0.5109 - val_accuracy: 0.7969 - val_auc: 0.4749 - val_precision: 0.0442 - val_recall: 0.1250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5990 - accuracy: 0.6025 - auc: 0.7383 - precision: 0.1260 - recall: 0.7512 - val_loss: 0.3723 - val_accuracy: 0.8764 - val_auc: 0.5737 - val_precision: 0.0392 - val_recall: 0.0500\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5612 - accuracy: 0.6401 - auc: 0.7785 - precision: 0.1380 - recall: 0.7512 - val_loss: 0.9172 - val_accuracy: 0.4602 - val_auc: 0.5160 - val_precision: 0.0641 - val_recall: 0.6250\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5552 - accuracy: 0.6774 - auc: 0.7880 - precision: 0.1551 - recall: 0.7707 - val_loss: 0.7115 - val_accuracy: 0.6136 - val_auc: 0.5191 - val_precision: 0.0469 - val_recall: 0.3000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5531 - accuracy: 0.6817 - auc: 0.7892 - precision: 0.1521 - recall: 0.7366 - val_loss: 0.9062 - val_accuracy: 0.5014 - val_auc: 0.5069 - val_precision: 0.0570 - val_recall: 0.5000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5047 - accuracy: 0.6924 - auc: 0.8275 - precision: 0.1645 - recall: 0.7902 - val_loss: 0.9100 - val_accuracy: 0.4943 - val_auc: 0.4920 - val_precision: 0.0537 - val_recall: 0.4750\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9100 - accuracy: 0.4943 - auc: 0.4920 - precision: 0.0537 - recall: 0.4750\n",
      "Scaler: None, Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2819 - accuracy: 0.4959 - auc: 0.5164 - precision: 0.0749 - recall: 0.5220 - val_loss: 0.7641 - val_accuracy: 0.1392 - val_auc: 0.4642 - val_precision: 0.0550 - val_recall: 0.8750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.0059 - accuracy: 0.5115 - auc: 0.5201 - precision: 0.0797 - recall: 0.5415 - val_loss: 1.0586 - val_accuracy: 0.1193 - val_auc: 0.4477 - val_precision: 0.0525 - val_recall: 0.8500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8251 - accuracy: 0.5240 - auc: 0.5887 - precision: 0.0897 - recall: 0.6049 - val_loss: 0.5496 - val_accuracy: 0.8707 - val_auc: 0.5133 - val_precision: 0.1077 - val_recall: 0.1750\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7234 - accuracy: 0.5389 - auc: 0.6237 - precision: 0.0888 - recall: 0.5756 - val_loss: 0.8336 - val_accuracy: 0.3509 - val_auc: 0.4972 - val_precision: 0.0535 - val_recall: 0.6250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.6568 - accuracy: 0.5805 - auc: 0.7010 - precision: 0.1127 - recall: 0.6927 - val_loss: 0.7930 - val_accuracy: 0.4744 - val_auc: 0.4688 - val_precision: 0.0565 - val_recall: 0.5250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5988 - accuracy: 0.6043 - auc: 0.7424 - precision: 0.1241 - recall: 0.7317 - val_loss: 0.6435 - val_accuracy: 0.5994 - val_auc: 0.4769 - val_precision: 0.0519 - val_recall: 0.3500\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5581 - accuracy: 0.6657 - auc: 0.7882 - precision: 0.1489 - recall: 0.7610 - val_loss: 0.7826 - val_accuracy: 0.6207 - val_auc: 0.4416 - val_precision: 0.0478 - val_recall: 0.3000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5522 - accuracy: 0.6583 - auc: 0.7862 - precision: 0.1433 - recall: 0.7415 - val_loss: 0.7854 - val_accuracy: 0.6236 - val_auc: 0.5302 - val_precision: 0.0623 - val_recall: 0.4000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5460 - accuracy: 0.6792 - auc: 0.7994 - precision: 0.1524 - recall: 0.7463 - val_loss: 0.7125 - val_accuracy: 0.6676 - val_auc: 0.5023 - val_precision: 0.0550 - val_recall: 0.3000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4946 - accuracy: 0.7055 - auc: 0.8386 - precision: 0.1702 - recall: 0.7854 - val_loss: 0.8414 - val_accuracy: 0.5611 - val_auc: 0.4912 - val_precision: 0.0561 - val_recall: 0.4250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8414 - accuracy: 0.5611 - auc: 0.4912 - precision: 0.0561 - recall: 0.4250\n",
      "Scaler: MinMaxScaler(), Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.1956 - accuracy: 0.5222 - auc: 0.5217 - precision: 0.0778 - recall: 0.5122 - val_loss: 0.8742 - val_accuracy: 0.2940 - val_auc: 0.4425 - val_precision: 0.0475 - val_recall: 0.6000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9122 - accuracy: 0.5265 - auc: 0.5798 - precision: 0.0901 - recall: 0.6049 - val_loss: 0.8517 - val_accuracy: 0.3977 - val_auc: 0.4378 - val_precision: 0.0514 - val_recall: 0.5500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7638 - accuracy: 0.5510 - auc: 0.6242 - precision: 0.0986 - recall: 0.6341 - val_loss: 0.7792 - val_accuracy: 0.5327 - val_auc: 0.4547 - val_precision: 0.0554 - val_recall: 0.4500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7005 - accuracy: 0.5936 - auc: 0.6658 - precision: 0.1136 - recall: 0.6732 - val_loss: 0.5940 - val_accuracy: 0.6634 - val_auc: 0.4992 - val_precision: 0.0622 - val_recall: 0.3500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6437 - accuracy: 0.6242 - auc: 0.7280 - precision: 0.1314 - recall: 0.7415 - val_loss: 0.5001 - val_accuracy: 0.7543 - val_auc: 0.5099 - val_precision: 0.0654 - val_recall: 0.2500\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5264 - accuracy: 0.6966 - auc: 0.8210 - precision: 0.1712 - recall: 0.8244 - val_loss: 0.6089 - val_accuracy: 0.7188 - val_auc: 0.5082 - val_precision: 0.0659 - val_recall: 0.3000\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4983 - accuracy: 0.7002 - auc: 0.8443 - precision: 0.1750 - recall: 0.8390 - val_loss: 0.6131 - val_accuracy: 0.7003 - val_auc: 0.4869 - val_precision: 0.0615 - val_recall: 0.3000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4121 - accuracy: 0.7581 - auc: 0.8935 - precision: 0.2180 - recall: 0.8976 - val_loss: 0.5599 - val_accuracy: 0.7401 - val_auc: 0.5408 - val_precision: 0.0769 - val_recall: 0.3250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3554 - accuracy: 0.8071 - auc: 0.9232 - precision: 0.2659 - recall: 0.9366 - val_loss: 0.3728 - val_accuracy: 0.8608 - val_auc: 0.6001 - val_precision: 0.1375 - val_recall: 0.2750\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2851 - accuracy: 0.8664 - auc: 0.9516 - precision: 0.3437 - recall: 0.9171 - val_loss: 0.5127 - val_accuracy: 0.8054 - val_auc: 0.5576 - val_precision: 0.0855 - val_recall: 0.2500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8054 - auc: 0.5576 - precision: 0.0855 - recall: 0.2500\n",
      "Scaler: MinMaxScaler(), Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 20ms/step - loss: 1.3218 - accuracy: 0.5037 - auc: 0.4892 - precision: 0.0687 - recall: 0.4634 - val_loss: 0.9415 - val_accuracy: 0.1918 - val_auc: 0.5208 - val_precision: 0.0614 - val_recall: 0.9250\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8698 - accuracy: 0.5204 - auc: 0.5863 - precision: 0.0931 - recall: 0.6390 - val_loss: 0.7226 - val_accuracy: 0.5597 - val_auc: 0.4903 - val_precision: 0.0617 - val_recall: 0.4750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7617 - accuracy: 0.5591 - auc: 0.6108 - precision: 0.0953 - recall: 0.5951 - val_loss: 0.6284 - val_accuracy: 0.6761 - val_auc: 0.4970 - val_precision: 0.0648 - val_recall: 0.3500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.6419 - accuracy: 0.6192 - auc: 0.7136 - precision: 0.1240 - recall: 0.6976 - val_loss: 0.7119 - val_accuracy: 0.6009 - val_auc: 0.4828 - val_precision: 0.0618 - val_recall: 0.4250\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6260 - accuracy: 0.6469 - auc: 0.7479 - precision: 0.1391 - recall: 0.7415 - val_loss: 0.4926 - val_accuracy: 0.7685 - val_auc: 0.5394 - val_precision: 0.0816 - val_recall: 0.3000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5567 - accuracy: 0.6760 - auc: 0.8036 - precision: 0.1565 - recall: 0.7854 - val_loss: 0.6506 - val_accuracy: 0.6875 - val_auc: 0.4820 - val_precision: 0.0545 - val_recall: 0.2750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4555 - accuracy: 0.7293 - auc: 0.8709 - precision: 0.1970 - recall: 0.8829 - val_loss: 0.5437 - val_accuracy: 0.7486 - val_auc: 0.5419 - val_precision: 0.0848 - val_recall: 0.3500\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4136 - accuracy: 0.7780 - auc: 0.8957 - precision: 0.2280 - recall: 0.8585 - val_loss: 0.4164 - val_accuracy: 0.8253 - val_auc: 0.6173 - val_precision: 0.1048 - val_recall: 0.2750\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.3321 - accuracy: 0.8220 - auc: 0.9351 - precision: 0.2804 - recall: 0.9220 - val_loss: 0.5797 - val_accuracy: 0.7699 - val_auc: 0.5378 - val_precision: 0.0704 - val_recall: 0.2500\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2896 - accuracy: 0.8590 - auc: 0.9509 - precision: 0.3316 - recall: 0.9220 - val_loss: 1.0661 - val_accuracy: 0.6278 - val_auc: 0.5295 - val_precision: 0.0560 - val_recall: 0.3500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0661 - accuracy: 0.6278 - auc: 0.5295 - precision: 0.0560 - recall: 0.3500\n",
      "Scaler: MinMaxScaler(), Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3557 - accuracy: 0.4913 - auc: 0.4738 - precision: 0.0664 - recall: 0.4585 - val_loss: 1.0130 - val_accuracy: 0.0767 - val_auc: 0.4829 - val_precision: 0.0567 - val_recall: 0.9750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8588 - accuracy: 0.5105 - auc: 0.5698 - precision: 0.0802 - recall: 0.5463 - val_loss: 0.8933 - val_accuracy: 0.4673 - val_auc: 0.5191 - val_precision: 0.0627 - val_recall: 0.6000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7821 - accuracy: 0.5560 - auc: 0.6217 - precision: 0.1002 - recall: 0.6390 - val_loss: 0.6968 - val_accuracy: 0.5440 - val_auc: 0.4658 - val_precision: 0.0453 - val_recall: 0.3500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.6938 - accuracy: 0.5691 - auc: 0.6683 - precision: 0.1111 - recall: 0.7024 - val_loss: 0.7492 - val_accuracy: 0.5043 - val_auc: 0.4926 - val_precision: 0.0522 - val_recall: 0.4500\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6090 - accuracy: 0.6266 - auc: 0.7486 - precision: 0.1347 - recall: 0.7610 - val_loss: 0.6600 - val_accuracy: 0.6378 - val_auc: 0.4639 - val_precision: 0.0502 - val_recall: 0.3000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5984 - accuracy: 0.6632 - auc: 0.7710 - precision: 0.1445 - recall: 0.7366 - val_loss: 0.5160 - val_accuracy: 0.7386 - val_auc: 0.5246 - val_precision: 0.0610 - val_recall: 0.2500\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4849 - accuracy: 0.7087 - auc: 0.8496 - precision: 0.1767 - recall: 0.8195 - val_loss: 0.5905 - val_accuracy: 0.7514 - val_auc: 0.5196 - val_precision: 0.0807 - val_recall: 0.3250\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4245 - accuracy: 0.7417 - auc: 0.8886 - precision: 0.2048 - recall: 0.8829 - val_loss: 0.5291 - val_accuracy: 0.7812 - val_auc: 0.5490 - val_precision: 0.0615 - val_recall: 0.2000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.3374 - accuracy: 0.8163 - auc: 0.9334 - precision: 0.2759 - recall: 0.9366 - val_loss: 0.4215 - val_accuracy: 0.8281 - val_auc: 0.5646 - val_precision: 0.0449 - val_recall: 0.1000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8309 - auc: 0.9371 - precision: 0.2879 - recall: 0.8976 - val_loss: 0.8863 - val_accuracy: 0.5852 - val_auc: 0.5409 - val_precision: 0.0743 - val_recall: 0.5500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8863 - accuracy: 0.5852 - auc: 0.5409 - precision: 0.0743 - recall: 0.5500\n",
      "Scaler: MinMaxScaler(), Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2862 - accuracy: 0.4803 - auc: 0.4750 - precision: 0.0709 - recall: 0.5073 - val_loss: 0.8339 - val_accuracy: 0.2983 - val_auc: 0.5273 - val_precision: 0.0635 - val_recall: 0.8250\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9215 - accuracy: 0.5151 - auc: 0.5527 - precision: 0.0845 - recall: 0.5756 - val_loss: 0.6645 - val_accuracy: 0.5455 - val_auc: 0.4790 - val_precision: 0.0570 - val_recall: 0.4500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8015 - accuracy: 0.5293 - auc: 0.5730 - precision: 0.0882 - recall: 0.5854 - val_loss: 0.5151 - val_accuracy: 0.7457 - val_auc: 0.4410 - val_precision: 0.0516 - val_recall: 0.2000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7223 - accuracy: 0.5606 - auc: 0.6489 - precision: 0.1043 - recall: 0.6634 - val_loss: 0.6020 - val_accuracy: 0.7003 - val_auc: 0.4594 - val_precision: 0.0570 - val_recall: 0.2750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6319 - accuracy: 0.6139 - auc: 0.7200 - precision: 0.1244 - recall: 0.7122 - val_loss: 0.6744 - val_accuracy: 0.5938 - val_auc: 0.4977 - val_precision: 0.0607 - val_recall: 0.4250\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5241 - accuracy: 0.6597 - auc: 0.8210 - precision: 0.1562 - recall: 0.8341 - val_loss: 0.4690 - val_accuracy: 0.7912 - val_auc: 0.4988 - val_precision: 0.0427 - val_recall: 0.1250\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4710 - accuracy: 0.7233 - auc: 0.8618 - precision: 0.1880 - recall: 0.8439 - val_loss: 0.5010 - val_accuracy: 0.7713 - val_auc: 0.5639 - val_precision: 0.0884 - val_recall: 0.3250\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4088 - accuracy: 0.7744 - auc: 0.9000 - precision: 0.2272 - recall: 0.8732 - val_loss: 0.4913 - val_accuracy: 0.7756 - val_auc: 0.5298 - val_precision: 0.0597 - val_recall: 0.2000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.8167 - auc: 0.9331 - precision: 0.2737 - recall: 0.9171 - val_loss: 0.3813 - val_accuracy: 0.8636 - val_auc: 0.5272 - val_precision: 0.1000 - val_recall: 0.1750\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2882 - accuracy: 0.8512 - auc: 0.9514 - precision: 0.3199 - recall: 0.9268 - val_loss: 0.4288 - val_accuracy: 0.8239 - val_auc: 0.5960 - val_precision: 0.1182 - val_recall: 0.3250\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8239 - auc: 0.5960 - precision: 0.1182 - recall: 0.3250\n",
      "Scaler: MinMaxScaler(), Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 21ms/step - loss: 1.3298 - accuracy: 0.5080 - auc: 0.4958 - precision: 0.0687 - recall: 0.4585 - val_loss: 0.7468 - val_accuracy: 0.4659 - val_auc: 0.5631 - val_precision: 0.0692 - val_recall: 0.6750\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8708 - accuracy: 0.5407 - auc: 0.5803 - precision: 0.0916 - recall: 0.5951 - val_loss: 0.7920 - val_accuracy: 0.4588 - val_auc: 0.4022 - val_precision: 0.0379 - val_recall: 0.3500\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7795 - accuracy: 0.5460 - auc: 0.6017 - precision: 0.0933 - recall: 0.6000 - val_loss: 0.5295 - val_accuracy: 0.7145 - val_auc: 0.5045 - val_precision: 0.0552 - val_recall: 0.2500\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7060 - accuracy: 0.5719 - auc: 0.6589 - precision: 0.1082 - recall: 0.6732 - val_loss: 0.5866 - val_accuracy: 0.6733 - val_auc: 0.4773 - val_precision: 0.0343 - val_recall: 0.1750\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6225 - accuracy: 0.6075 - auc: 0.7414 - precision: 0.1293 - recall: 0.7659 - val_loss: 0.6118 - val_accuracy: 0.6946 - val_auc: 0.4573 - val_precision: 0.0603 - val_recall: 0.3000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5050 - accuracy: 0.6909 - auc: 0.8353 - precision: 0.1672 - recall: 0.8146 - val_loss: 0.5453 - val_accuracy: 0.7386 - val_auc: 0.4792 - val_precision: 0.0385 - val_recall: 0.1500\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4447 - accuracy: 0.7290 - auc: 0.8787 - precision: 0.1974 - recall: 0.8878 - val_loss: 0.5018 - val_accuracy: 0.7869 - val_auc: 0.4558 - val_precision: 0.0565 - val_recall: 0.1750\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4155 - accuracy: 0.7780 - auc: 0.8939 - precision: 0.2280 - recall: 0.8585 - val_loss: 0.8704 - val_accuracy: 0.6080 - val_auc: 0.5471 - val_precision: 0.0725 - val_recall: 0.5000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3670 - accuracy: 0.7954 - auc: 0.9187 - precision: 0.2497 - recall: 0.9024 - val_loss: 0.4732 - val_accuracy: 0.8168 - val_auc: 0.5126 - val_precision: 0.0841 - val_recall: 0.2250\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.2588 - accuracy: 0.8643 - auc: 0.9616 - precision: 0.3450 - recall: 0.9610 - val_loss: 0.2798 - val_accuracy: 0.9304 - val_auc: 0.5276 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.9304 - auc: 0.5276 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 0\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.2127 - accuracy: 0.4831 - auc: 0.4983 - precision: 0.0678 - recall: 0.4780 - val_loss: 1.0466 - val_accuracy: 0.0568 - val_auc: 0.5613 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9759 - accuracy: 0.5162 - auc: 0.5370 - precision: 0.0817 - recall: 0.5512 - val_loss: 0.8740 - val_accuracy: 0.0568 - val_auc: 0.5114 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9602 - accuracy: 0.5126 - auc: 0.4935 - precision: 0.0732 - recall: 0.4878 - val_loss: 1.1166 - val_accuracy: 0.0568 - val_auc: 0.5182 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8751 - accuracy: 0.5101 - auc: 0.5057 - precision: 0.0759 - recall: 0.5122 - val_loss: 1.4566 - val_accuracy: 0.0568 - val_auc: 0.5269 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8541 - accuracy: 0.4959 - auc: 0.4831 - precision: 0.0695 - recall: 0.4780 - val_loss: 0.2263 - val_accuracy: 0.9432 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8142 - accuracy: 0.4959 - auc: 0.4702 - precision: 0.0614 - recall: 0.4146 - val_loss: 0.2528 - val_accuracy: 0.9432 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7480 - accuracy: 0.5108 - auc: 0.5023 - precision: 0.0747 - recall: 0.5024 - val_loss: 1.1235 - val_accuracy: 0.0568 - val_auc: 0.5157 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7521 - accuracy: 0.4924 - auc: 0.5179 - precision: 0.0797 - recall: 0.5659 - val_loss: 1.2532 - val_accuracy: 0.0568 - val_auc: 0.5046 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7661 - accuracy: 0.4977 - auc: 0.4685 - precision: 0.0691 - recall: 0.4732 - val_loss: 0.3834 - val_accuracy: 0.9432 - val_auc: 0.5303 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7267 - accuracy: 0.5012 - auc: 0.5107 - precision: 0.0733 - recall: 0.5024 - val_loss: 0.5934 - val_accuracy: 0.9432 - val_auc: 0.4824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.9432 - auc: 0.4824 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 21ms/step - loss: 1.2151 - accuracy: 0.4998 - auc: 0.5267 - precision: 0.0755 - recall: 0.5220 - val_loss: 0.8993 - val_accuracy: 0.0568 - val_auc: 0.5155 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.0101 - accuracy: 0.5094 - auc: 0.5050 - precision: 0.0714 - recall: 0.4780 - val_loss: 0.7425 - val_accuracy: 0.2244 - val_auc: 0.5276 - val_precision: 0.0577 - val_recall: 0.8250\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9064 - accuracy: 0.5318 - auc: 0.5207 - precision: 0.0813 - recall: 0.5268 - val_loss: 0.3100 - val_accuracy: 0.9432 - val_auc: 0.5066 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9098 - accuracy: 0.4902 - auc: 0.4797 - precision: 0.0644 - recall: 0.4439 - val_loss: 0.9725 - val_accuracy: 0.0568 - val_auc: 0.4655 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8204 - accuracy: 0.5108 - auc: 0.5110 - precision: 0.0772 - recall: 0.5220 - val_loss: 1.1143 - val_accuracy: 0.0568 - val_auc: 0.4985 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7731 - accuracy: 0.4877 - auc: 0.5143 - precision: 0.0714 - recall: 0.5024 - val_loss: 0.3077 - val_accuracy: 0.9432 - val_auc: 0.5259 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7592 - accuracy: 0.5293 - auc: 0.5358 - precision: 0.0833 - recall: 0.5463 - val_loss: 2.0422 - val_accuracy: 0.0568 - val_auc: 0.4982 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7586 - accuracy: 0.5037 - auc: 0.5072 - precision: 0.0755 - recall: 0.5171 - val_loss: 0.8949 - val_accuracy: 0.0568 - val_auc: 0.4764 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7094 - accuracy: 0.5275 - auc: 0.5674 - precision: 0.0885 - recall: 0.5902 - val_loss: 0.6794 - val_accuracy: 0.9432 - val_auc: 0.4783 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7543 - accuracy: 0.5044 - auc: 0.4717 - precision: 0.0688 - recall: 0.4634 - val_loss: 0.3515 - val_accuracy: 0.9432 - val_auc: 0.5226 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.9432 - auc: 0.5226 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 2\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.4009 - accuracy: 0.4899 - auc: 0.4717 - precision: 0.0729 - recall: 0.5122 - val_loss: 0.8162 - val_accuracy: 0.0568 - val_auc: 0.4088 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9692 - accuracy: 0.4991 - auc: 0.5213 - precision: 0.0801 - recall: 0.5610 - val_loss: 0.5645 - val_accuracy: 0.9432 - val_auc: 0.5027 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9236 - accuracy: 0.5190 - auc: 0.5238 - precision: 0.0773 - recall: 0.5122 - val_loss: 0.7968 - val_accuracy: 0.0597 - val_auc: 0.5237 - val_precision: 0.0570 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8465 - accuracy: 0.5204 - auc: 0.5334 - precision: 0.0756 - recall: 0.4976 - val_loss: 0.2194 - val_accuracy: 0.9432 - val_auc: 0.5613 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8231 - accuracy: 0.5066 - auc: 0.5100 - precision: 0.0753 - recall: 0.5122 - val_loss: 1.6008 - val_accuracy: 0.0568 - val_auc: 0.4385 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7367 - accuracy: 0.5187 - auc: 0.5884 - precision: 0.0910 - recall: 0.6244 - val_loss: 1.0875 - val_accuracy: 0.1094 - val_auc: 0.4993 - val_precision: 0.0586 - val_recall: 0.9750\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7237 - accuracy: 0.5254 - auc: 0.5929 - precision: 0.0887 - recall: 0.5951 - val_loss: 0.3724 - val_accuracy: 0.9432 - val_auc: 0.5101 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6925 - accuracy: 0.5343 - auc: 0.6098 - precision: 0.0952 - recall: 0.6341 - val_loss: 0.9745 - val_accuracy: 0.1264 - val_auc: 0.5193 - val_precision: 0.0570 - val_recall: 0.9250\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6540 - accuracy: 0.5332 - auc: 0.6705 - precision: 0.1065 - recall: 0.7317 - val_loss: 0.5919 - val_accuracy: 0.9432 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6268 - accuracy: 0.5545 - auc: 0.7004 - precision: 0.1163 - recall: 0.7756 - val_loss: 0.7921 - val_accuracy: 0.0980 - val_auc: 0.5136 - val_precision: 0.0579 - val_recall: 0.9750\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7921 - accuracy: 0.0980 - auc: 0.5136 - precision: 0.0579 - recall: 0.9750\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 3\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 21ms/step - loss: 1.1812 - accuracy: 0.4991 - auc: 0.5313 - precision: 0.0772 - recall: 0.5366 - val_loss: 0.7281 - val_accuracy: 0.1094 - val_auc: 0.4810 - val_precision: 0.0600 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9909 - accuracy: 0.5133 - auc: 0.5236 - precision: 0.0776 - recall: 0.5220 - val_loss: 1.1336 - val_accuracy: 0.0568 - val_auc: 0.5130 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8579 - accuracy: 0.5428 - auc: 0.5561 - precision: 0.0851 - recall: 0.5415 - val_loss: 0.8545 - val_accuracy: 0.0568 - val_auc: 0.3654 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9037 - accuracy: 0.5055 - auc: 0.4871 - precision: 0.0702 - recall: 0.4732 - val_loss: 0.2379 - val_accuracy: 0.9432 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8264 - accuracy: 0.4991 - auc: 0.4884 - precision: 0.0718 - recall: 0.4927 - val_loss: 0.5583 - val_accuracy: 0.9432 - val_auc: 0.5012 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8034 - accuracy: 0.4988 - auc: 0.4766 - precision: 0.0693 - recall: 0.4732 - val_loss: 0.3854 - val_accuracy: 0.9432 - val_auc: 0.5447 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7570 - accuracy: 0.4881 - auc: 0.5086 - precision: 0.0773 - recall: 0.5512 - val_loss: 0.8471 - val_accuracy: 0.0852 - val_auc: 0.5671 - val_precision: 0.0585 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7432 - accuracy: 0.5005 - auc: 0.5087 - precision: 0.0702 - recall: 0.4780 - val_loss: 1.4703 - val_accuracy: 0.0568 - val_auc: 0.5000 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7411 - accuracy: 0.5083 - auc: 0.4906 - precision: 0.0713 - recall: 0.4780 - val_loss: 0.8354 - val_accuracy: 0.0568 - val_auc: 0.5357 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.7237 - accuracy: 0.4952 - auc: 0.5092 - precision: 0.0724 - recall: 0.5024 - val_loss: 0.7078 - val_accuracy: 0.0568 - val_auc: 0.4575 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.0568 - auc: 0.4575 - precision: 0.0568 - recall: 1.0000\n",
      "Scaler: MinMaxScaler(feature_range=(-1, 1)), Trial: 4\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 7s 20ms/step - loss: 1.3106 - accuracy: 0.4785 - auc: 0.5172 - precision: 0.0713 - recall: 0.5122 - val_loss: 0.6708 - val_accuracy: 0.8679 - val_auc: 0.5115 - val_precision: 0.0182 - val_recall: 0.0250\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.9851 - accuracy: 0.5279 - auc: 0.5284 - precision: 0.0812 - recall: 0.5317 - val_loss: 0.6823 - val_accuracy: 0.6861 - val_auc: 0.5276 - val_precision: 0.0542 - val_recall: 0.2750\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.0129 - accuracy: 0.4806 - auc: 0.4562 - precision: 0.0632 - recall: 0.4439 - val_loss: 1.0723 - val_accuracy: 0.0568 - val_auc: 0.5000 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.8571 - accuracy: 0.4984 - auc: 0.5084 - precision: 0.0717 - recall: 0.4927 - val_loss: 1.2181 - val_accuracy: 0.0568 - val_auc: 0.4390 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7964 - accuracy: 0.5105 - auc: 0.5336 - precision: 0.0826 - recall: 0.5659 - val_loss: 0.3602 - val_accuracy: 0.9432 - val_auc: 0.5362 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7831 - accuracy: 0.5066 - auc: 0.4978 - precision: 0.0710 - recall: 0.4780 - val_loss: 0.2960 - val_accuracy: 0.9432 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7765 - accuracy: 0.5094 - auc: 0.4999 - precision: 0.0751 - recall: 0.5073 - val_loss: 0.3405 - val_accuracy: 0.9432 - val_auc: 0.4989 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7546 - accuracy: 0.5012 - auc: 0.4904 - precision: 0.0684 - recall: 0.4634 - val_loss: 1.3424 - val_accuracy: 0.0568 - val_auc: 0.5360 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7612 - accuracy: 0.4796 - auc: 0.4501 - precision: 0.0673 - recall: 0.4780 - val_loss: 0.8175 - val_accuracy: 0.0568 - val_auc: 0.4841 - val_precision: 0.0568 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7346 - accuracy: 0.5002 - auc: 0.4941 - precision: 0.0732 - recall: 0.5024 - val_loss: 0.6709 - val_accuracy: 0.9418 - val_auc: 0.4347 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.9418 - auc: 0.4347 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "# Run the experiment for each type of scaler 5 times\n",
    "for scaler in ['standard', 'None', '[0,1]', '[-1,1]']:\n",
    "    # Run experiment\n",
    "    results = test_scaler(X, y, results=results, scaler=scaler, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8133b0aa-62e6-4d05-be0b-cd8817ce399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7wklEQVR4nOzdd3iN9//H8dfJRsQWQuwtVbPEqFpRtUlrtfYqLYIiVK3atWrXrK2xqZVqba1Ztapqr1hBJCHjnPv3h1/ON6lUVR1H4vm4rl517nPf93mfJPc59+v+jNtkGIYhAAAAAADwwjnYuwAAAAAAAJIrQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAIMmaP3++TCaT9T8nJydlzZpVTZs21ZkzZ+xdniQpV65cat26tfXxhQsXZDKZNH/+/Kdut337dplMJq1YscK2BUr65Zdf1LBhQ+XIkUOurq7y9PSUr6+vevXqZbPXjPvdXbhwwWavIT3++cf/G/m7//7p9wEAwPNysncBAAD8V/PmzVOhQoX06NEj7dmzR8OHD9dPP/2k33//XenSpbN3ea+077//XvXq1dM777yjMWPGKGvWrLp+/boOHjyoZcuWady4cfYu8T9ZvXq1oqKirI9nz56tOXPmaPPmzUqTJo11ed68ee1RHgDgNUDoBgAkeT4+PipdurQk6Z133pHZbNagQYO0Zs0atWnTxs7VvdrGjBmj3Llza8uWLXJy+t9pQdOmTTVmzBg7VvbvREZGKmXKlE8sL1GiRILHmzdvliSVKlVKGTNmfCm1AQBeb3QvBwAkO3EB/MaNGwmWHzx4UPXq1VP69Onl5uamEiVK6Lvvvnti+6tXr6pjx47y9vaWi4uLvLy85O/vb93fo0eP1KtXLxUvXlxp0qRR+vTp5evrq7Vr177w9/Lo0SP17NlTWbJkUYoUKVS5cmUdOXLE+vzChQtlMpm0b9++J7YdOnSonJ2dde3atb/d/507d5QxY8YEgTuOg8OTpwlLliyRr6+v3N3d5e7uruLFi2vOnDnW54ODg1W/fn1lz55dbm5uypcvnzp16qTbt28/0/v94YcfVK1aNXl4eChlypSqUKGCtm3blmCdwYMHy2Qy6fDhw/L391e6dOmeu6V62LBhcnJy0uXLl594rm3btsqQIYMePXok6XFX9Tp16mj16tUqVqyY3NzclCdPHn399ddPbBsWFqbevXsrd+7ccnFxUbZs2dSjRw9FREQ8V50AgKSL0A0ASHbOnz8vSSpQoIB12U8//aQKFSro3r17mjFjhtauXavixYurSZMmCcbzXr16VWXKlNHq1avVs2dPbdq0SRMnTlSaNGl09+5dSVJUVJRCQ0PVu3dvrVmzRkuXLlXFihXVqFEjLViw4IW+l/79++vcuXOaPXu2Zs+erWvXrumdd97RuXPnJElNmjRRlixZNHXq1ATbxcbGaubMmWrYsKG8vLz+dv++vr765Zdf1K1bN/3yyy+KiYn523W/+OILtWjRQl5eXpo/f75Wr16tVq1a6eLFi9Z1zp49K19fX02fPl1bt27VF198oV9++UUVK1Z86r4ladGiRfLz85OHh4e+/fZbfffdd0qfPr1q1qz5RPCWpEaNGilfvnwKCgrSjBkznrrvv9OpUyc5OTlp5syZCZaHhoZq2bJlateundzc3KzLf/31V/Xo0UMBAQFavXq1ypcvr+7du+urr76yrhMZGanKlSvr22+/Vbdu3bRp0yb17dtX8+fPV7169WQYxnPVCgBIogwAAJKoefPmGZKMn3/+2YiJiTEePHhgbN682ciSJYvx9ttvGzExMdZ1CxUqZJQoUSLBMsMwjDp16hhZs2Y1zGazYRiG0bZtW8PZ2dk4efLkM9cRGxtrxMTEGO3atTNKlCiR4LmcOXMarVq1sj4+f/68IcmYN2/eU/f5008/GZKMkiVLGhaLxbr8woULhrOzs9G+fXvrskGDBhkuLi7GjRs3rMuWL19uSDJ27Njx1Ne5ffu2UbFiRUOSIclwdnY2ypcvb4wcOdJ48OCBdb1z584Zjo6ORosWLZ66v/gsFosRExNjXLx40ZBkrF271vpc3O/u/PnzhmEYRkREhJE+fXqjbt26CfZhNpuNN99803jrrbcSvF9JxhdffPHMtfx121u3blmXtWrVysicObMRFRVlXTZ69GjDwcHBWp9hPP5dmkwm49dff02wzxo1ahgeHh5GRESEYRiGMXLkSMPBwcE4cOBAgvVWrFhhSDI2btz4r+sGACRdtHQDAJK8cuXKydnZWalTp9a7776rdOnSae3atdYu03/++ad+//13tWjRQtLjVuC4/9577z1dv35dp0+fliRt2rRJVapUUeHChZ/6mkFBQapQoYLc3d3l5OQkZ2dnzZkzR6dOnXqh76158+YymUzWxzlz5lT58uX1008/WZd9/PHHkqRZs2ZZl02ZMkVvvPGG3n777afuP0OGDNq1a5cOHDigUaNGqX79+vrjjz8UGBioN954w9otPDg4WGazWV27dn3q/m7evKnOnTvL29vb+nPJmTOnJD31Z7N3716FhoaqVatWCX4/FotF7777rg4cOPBE1+zGjRs/tZZn1b17d928eVNBQUGSJIvFounTp6t27drKlStXgnWLFi2qN998M8Gy5s2bKywsTIcPH5YkbdiwQT4+PipevHiC91KzZk2ZTCZt3779hdQNAEgaCN0AgCRvwYIFOnDggH788Ud16tRJp06dUrNmzazPx43F7t27t5ydnRP816VLF0myhstbt24pe/bsT329VatW6YMPPlC2bNm0aNEi7du3TwcOHFDbtm2t439flCxZsiS67M6dO9bHnp6eatKkiWbOnCmz2azffvtNu3bt0ieffPLMr1O6dGn17dtXQUFBunbtmgICAnThwgXrZGq3bt2SpKf+bCwWi/z8/LRq1Sr16dNH27Zt0/79+/Xzzz9Lkh4+fPi328b9jvz9/Z/4HY0ePVqGYSg0NDTBNlmzZn3m9/c0JUqUUKVKlaxd9Dds2KALFy4k+vP7u9+HJOvv5MaNG/rtt9+eeB+pU6eWYRjPPL4dAJA8MHs5ACDJK1y4sHXytCpVqshsNmv27NlasWKF/P39rbNUBwYGqlGjRonuo2DBgpKkTJky6cqVK099vUWLFil37txavnx5glbo+LemelFCQkISXZYhQ4YEy7p3766FCxdq7dq12rx5s9KmTWtt2f+3nJ2dNWjQIE2YMEHHjx+X9PjnIklXrlyRt7d3otsdP35cR48e1fz589WqVSvr8j///PMfXzPudzR58mSVK1cu0XU8PT0TPI7/s/+vunXrpvfff1+HDx/WlClTVKBAAdWoUeOJ9f7u9yHJ+jvJmDGjUqRIoblz5yb6WsyaDgCvF0I3ACDZGTNmjFauXKkvvvhCjRo1UsGCBZU/f34dPXpUI0aMeOq2tWrV0sKFC3X69GlrEP8rk8kkFxeXBKEvJCTEJrOXL126VD179rS+1sWLF7V37161bNkywXqlSpVS+fLlNXr0aB0/flwdO3ZUqlSp/nH/169fT7TFOK4reNwkbH5+fnJ0dNT06dPl6+ub6L7ianR1dU2w/K+TlCWmQoUKSps2rU6ePPmvWuhflIYNGypHjhzq1auXduzYoQkTJiQa6k+cOKGjR48m6GK+ZMkSpU6dWiVLlpQk1alTRyNGjFCGDBmUO3ful/YeAACvJkI3ACDZSZcunQIDA9WnTx8tWbJEH374oWbOnKlatWqpZs2aat26tbJly6bQ0FCdOnVKhw8fto7nHTp0qDZt2qS3335b/fv31xtvvKF79+5p8+bN6tmzpwoVKqQ6depo1apV6tKli/z9/XX58mUNGzZMWbNm1ZkzZ17oe7l586YaNmyoDh066P79+xo0aJDc3NwUGBj4xLrdu3dXkyZNZDKZrN3m/0nNmjWVPXt21a1bV4UKFZLFYtGvv/6qcePGyd3dXd27d5f0+HZZ/fv317Bhw/Tw4UM1a9ZMadKk0cmTJ3X79m0NGTJEhQoVUt68edWvXz8ZhqH06dNr/fr1Cg4O/sc63N3dNXnyZLVq1UqhoaHy9/dX5syZdevWLR09elS3bt3S9OnT/90P719wdHRU165d1bdvX6VKlUqtW7dOdD0vLy/Vq1dPgwcPVtasWbVo0SIFBwdr9OjR1vuE9+jRQytXrtTbb7+tgIAAFStWTBaLRZcuXdLWrVvVq1cvlS1b1mbvBQDwirHzRG4AADy3uBmw/zpLtGEYxsOHD40cOXIY+fPnN2JjYw3DMIyjR48aH3zwgZE5c2bD2dnZyJIli1G1alVjxowZCba9fPmy0bZtWyNLliyGs7Oz4eXlZXzwwQcJZgcfNWqUkStXLsPV1dUoXLiwMWvWLOvM2PH919nLFy5caHTr1s3IlCmT4erqalSqVMk4ePBgottERUUZrq6uxrvvvvvUfce3fPlyo3nz5kb+/PkNd3d3w9nZ2ciRI4fx0UcfJTqD+4IFC4wyZcoYbm5uhru7u1GiRIkE7+XkyZNGjRo1jNSpUxvp0qUz3n//fePSpUuGJGPQoEHW9f46e3mcHTt2GLVr1zbSp09vODs7G9myZTNq165tBAUFWddJbAbyZ/W0bS9cuGBIMjp37pzotjlz5jRq165trFixwihatKjh4uJi5MqVyxg/fvwT64aHhxuff/65UbBgQcPFxcVIkyaN8cYbbxgBAQFGSEjIv64bAJB0mQyDm0UCAJAcrF+/XvXq1dP333+v9957z97lJDmTJ09Wt27ddPz4cRUtWvSJ53PlyiUfHx9t2LDBDtUBAJIqupcDAJDEnTx5UhcvXlSvXr1UvHhx1apVy94lJSlHjhzR+fPnNXToUNWvXz/RwA0AwPMidAMAkMR16dJFe/bsUcmSJfXtt9++0Fm9XwcNGzZUSEiIKlWqpBkzZti7HABAMkP3cgAAAAAAbMTB3gUAAAAAAJBcEboBAAAAALARQjcAAAAAADby2k2kZrFYdO3aNaVOnZqJZgAAAAAAz8UwDD148EBeXl5ycPj79uzXLnRfu3ZN3t7e9i4DAAAAAJAMXL58WdmzZ//b51+70J06dWpJj38wHh4edq4GAAAAAJAUhYWFydvb25ox/85rF7rjupR7eHgQugEAAAAA/8k/DVtmIjUAAAAAAGyE0A0AAAAAgI3YPXRPmzZNuXPnlpubm0qVKqVdu3Y9df3FixfrzTffVMqUKZU1a1a1adNGd+7ceUnVAgAAAADw7OwaupcvX64ePXpowIABOnLkiCpVqqRatWrp0qVLia6/e/dutWzZUu3atdOJEycUFBSkAwcOqH379i+5cgAAAAAA/pldQ/f48ePVrl07tW/fXoULF9bEiRPl7e2t6dOnJ7r+zz//rFy5cqlbt27KnTu3KlasqE6dOungwYMvuXIAAAAAAP6Z3UJ3dHS0Dh06JD8/vwTL/fz8tHfv3kS3KV++vK5cuaKNGzfKMAzduHFDK1asUO3atV9GyQAAAAAA/Ct2u2XY7du3ZTab5enpmWC5p6enQkJCEt2mfPnyWrx4sZo0aaJHjx4pNjZW9erV0+TJk//2daKiohQVFWV9HBYWJkmKiYlRTEzMC3gnAAAAAPDPDMNQRESE9XGqVKn+8XZTeHU9a560+326//pHZhjG3/7hnTx5Ut26ddMXX3yhmjVr6vr16/rss8/UuXNnzZkzJ9FtRo4cqSFDhjyxfOvWrUqZMuV/fwMAAAAA8AyioqI0c+ZM6+NOnTrJ1dXVjhXhv4iMjHym9UyGYRg2riVR0dHRSpkypYKCgtSwYUPr8u7du+vXX3/Vjh07ntjmo48+0qNHjxQUFGRdtnv3blWqVEnXrl1T1qxZn9gmsZZub29v3b59Wx4eHi/4XQEAAABA4sLDw+Xv7299vGLFCrm7u9uxIvwXYWFhypgxo+7fv//UbGm3lm4XFxeVKlVKwcHBCUJ3cHCw6tevn+g2kZGRcnJKWLKjo6Okxy3kiXF1dU306pGzs7OcnZ2ft3wAAAAA+Ff+mj/IJEnbs/7u7Dp7ec+ePTV79mzNnTtXp06dUkBAgC5duqTOnTtLkgIDA9WyZUvr+nXr1tWqVas0ffp0nTt3Tnv27FG3bt301ltvycvLy15vAwAAAACARNl1THeTJk10584dDR06VNevX5ePj482btyonDlzSpKuX7+e4J7drVu31oMHDzRlyhT16tVLadOmVdWqVTV69Gh7vQUAAAAAAP6W3cZ020tYWJjSpEnzj/3uAQAAAOBFCg8PTzCUdu3atYzpTsKeNVvatXs5AAAAAADJGaEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGzE7qF72rRpyp07t9zc3FSqVCnt2rXrqetHRUVpwIABypkzp1xdXZU3b17NnTv3JVULAAAAAMCzc7Lniy9fvlw9evTQtGnTVKFCBc2cOVO1atXSyZMnlSNHjkS3+eCDD3Tjxg3NmTNH+fLl082bNxUbG/uSKwcAAAAA4J/ZNXSPHz9e7dq1U/v27SVJEydO1JYtWzR9+nSNHDnyifU3b96sHTt26Ny5c0qfPr0kKVeuXC+zZAAAAAAAnpndQnd0dLQOHTqkfv36JVju5+envXv3JrrNunXrVLp0aY0ZM0YLFy5UqlSpVK9ePQ0bNkwpUqRIdJuoqChFRUVZH4eFhUmSYmJiFBMT84LeDQAAAAA83V/zB5kkaXvW353dQvft27dlNpvl6emZYLmnp6dCQkIS3ebcuXPavXu33NzctHr1at2+fVtdunRRaGjo347rHjlypIYMGfLE8q1btyplypT//Y0AAAAAwDOI3xgoScHBwXJ1dbVTNfivIiMjn2k9u3YvlySTyZTgsWEYTyyLY7FYZDKZtHjxYqVJk0bS4y7q/v7+mjp1aqKt3YGBgerZs6f1cVhYmLy9veXn5ycPD48X+E4AAAAA4O+Fh4dr5syZ1sc1atSQu7u7HSvCfxHXi/qf2C10Z8yYUY6Ojk+0at+8efOJ1u84WbNmVbZs2ayBW5IKFy4swzB05coV5c+f/4ltXF1dE7165OzsLGdn5//4LgAAAADg2fw1f5BJkrZn/d3Z7ZZhLi4uKlWqlIKDgxMsDw4OVvny5RPdpkKFCrp27ZrCw8Oty/744w85ODgoe/bsNq0XAAAAAIB/y6736e7Zs6dmz56tuXPn6tSpUwoICNClS5fUuXNnSY+7hrds2dK6fvPmzZUhQwa1adNGJ0+e1M6dO/XZZ5+pbdu2fzuRGgAAAAAA9mLXMd1NmjTRnTt3NHToUF2/fl0+Pj7auHGjcubMKUm6fv26Ll26ZF3f3d1dwcHB+vTTT1W6dGllyJBBH3zwgb788kt7vQUAAAAAAP6WyTAMw95FvExhYWFKkyaN7t+/z0RqAAAAAF6a8PBw1a9f3/p47dq1TKSWhD1rtrRr93IAAAAAAJIzQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADbi9Kwrrlu37pl3Wq9evecqBgAAAACA5OSZQ3eDBg2eaT2TySSz2fy89QAAAAAAkGw8c+i2WCy2rAMAAAAAgGTnmUM3AABPYxiGIiIirI9TpUolk8lkx4oAAADs75lD99dff/3MO+3WrdtzFQMASLoiIiJUv3596+O1a9fK3d3djhUBAADY3zOH7gkTJjzTeiaTidANAAAAAID+Reg+f/68LesAAAAAACDZYUw3AABAMsVcCwBgf88duq9cuaJ169bp0qVLio6OTvDc+PHj/3NhAAAA+G+YawEA7O+5Qve2bdtUr1495c6dW6dPn5aPj48uXLggwzBUsmTJF10jAPwnpT5bYO8SXgum2Giliff4nYHLZDi52K2e18WhsS3tXQIAAHgKh+fZKDAwUL169dLx48fl5uamlStX6vLly6pcubLef//9F10jAAAAAABJ0nOF7lOnTqlVq1aSJCcnJz18+FDu7u4aOnSoRo8e/UILBAAAAAAgqXqu0J0qVSpFRUVJkry8vHT27Fnrc7dv334xlQEAAAAAkMQ915jucuXKac+ePSpSpIhq166tXr166dixY1q1apXKlSv3omsEAAAAACBJeq7QPX78eIWHh0uSBg8erPDwcC1fvlz58uXThAkTXmiBAAAAAAAkVc8VuvPkyWP9d8qUKTVt2rQXVhAAIGkyHJ11v1izBI8BAABed88Vug8cOCCLxaKyZcsmWP7LL7/I0dFRpUuXfiHFAQCSEJOJW4QBAAD8xXNNpNa1a1ddvnz5ieVXr15V165d/9W+pk2bpty5c8vNzU2lSpXSrl27nmm7PXv2yMnJScWLF/9XrwcAAAAAwMvyXKH75MmTKlmy5BPLS5QooZMnTz7zfpYvX64ePXpowIABOnLkiCpVqqRatWrp0qVLT93u/v37atmypapVq/avawcAAAAA4GV5rtDt6uqqGzduPLH8+vXrcnJ69h7r48ePV7t27dS+fXsVLlxYEydOlLe3t6ZPn/7U7Tp16qTmzZvL19f3X9cOAAAAAMDL8lyhu0aNGgoMDNT9+/ety+7du6f+/furRo0az7SP6OhoHTp0SH5+fgmW+/n5ae/evX+73bx583T27FkNGjToeUoHAAAAAOClea6J1MaNG6e3335bOXPmVIkSJSRJv/76qzw9PbVw4cJn2sft27dlNpvl6emZYLmnp6dCQkIS3ebMmTPq16+fdu3a9cwt6lFRUYqKirI+DgsLkyTFxMQoJibmmfYBIGlzcbR3BYDt8F2Gp/nr3wfnP4B9cUwmL8/6u3uu0J0tWzb99ttvWrx4sY4ePaoUKVKoTZs2atasmZyd/90tYkwmU4LHhmE8sUySzGazmjdvriFDhqhAgQLPvP+RI0dqyJAhTyzfunWrUqZM+a9qBZA09fNNY+8SAJvZuHGjvUvAKyx+w4MkBQcHy9XV1U7VAOCYTF4iIyOfaT2TYRiGjWtJVHR0tFKmTKmgoCA1bNjQurx79+769ddftWPHjgTr37t3T+nSpZOj4/+arCwWiwzDkKOjo7Zu3aqqVas+8TqJtXR7e3vr9u3b8vDwsME7A/CqeXvgUnuXANjMzmHN/nklvLbCw8Pl7+9vfbxixQq5u7vbsSK8qviufElio5XyyP9+1pElmkncbtPmbPVdGRYWpowZM+r+/ftPzZbP1dItSQsXLtTMmTN17tw57du3Tzlz5tSECROUJ08e1a9f/x+3d3FxUalSpRQcHJwgdAcHBye6vYeHh44dO5Zg2bRp0/Tjjz9qxYoVyp07d6Kv4+rqmujVI2dn53/dKg8gaYo227sCwHb4LsPT/PXvg/Mf/B2+K18O019+zjFmyXiyky9eMFt97j3rfp9rIrXp06erZ8+eqlWrlu7evSuz+fFfT7p06TRx4sRn3k/Pnj01e/ZszZ07V6dOnVJAQIAuXbqkzp07S5ICAwPVsmXLx4U6OMjHxyfBf5kzZ5abm5t8fHyUKlWq53krAAAAAADYzHOF7smTJ2vWrFkaMGBAggnNSpcu/URr9NM0adJEEydO1NChQ1W8eHHt3LlTGzduVM6cOSU9vgXZP92zGwAAAACAV9VzdS8/f/68ddby+FxdXRUREfGv9tWlSxd16dIl0efmz5//1G0HDx6swYMH/6vXAwAAAADgZXmulu7cuXPr119/fWL5pk2bVLhw4f9aEwAAAAAAycJztXR/9tln6tq1qx49eiTDMLR//34tXbpUI0aM0Jw5c150jQAAAAAAJEnPFbrbtGmj2NhY9enTR5GRkWrevLmyZcumyZMnq1KlSi+6RgAAAAAAkqTn6l4uSR06dNDFixd18+ZNhYSEaP/+/Tpy5Ijy5cv3IusDAAAAACDJ+leh+969e2rRooUyZcokLy8vff3110qfPr2mTp2qfPny6eeff9bcuXNtVSsAAAAAAEnKv+pe3r9/f+3cuVOtWrXS5s2bFRAQoM2bN+vRo0fauHGjKleubKs6AQAAAABIcv5V6P7+++81b948Va9eXV26dFG+fPlUoEABTZw40UblAQAAAACQdP2r7uXXrl1TkSJFJEl58uSRm5ub2rdvb5PCAAAAAABI6v5V6LZYLHJ2drY+dnR0VKpUqV54UQAAAAAAJAf/qnu5YRhq3bq1XF1dJUmPHj1S586dnwjeq1atenEVAgAAAACQRP2r0N2qVasEjz/88MMXWgwAAAAAAMnJvwrd8+bNs1UdAAAAAAAkO/9qTDcAAAAAAHh2hG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGzEyd4FAACA10+pzxbYu4TXgik2WmniPX5n4DIZTi52q+d1cGhsS3uXAOAVQ0s3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABuxe+ieNm2acufOLTc3N5UqVUq7du3623VXrVqlGjVqKFOmTPLw8JCvr6+2bNnyEqsFAAAAAODZ2TV0L1++XD169NCAAQN05MgRVapUSbVq1dKlS5cSXX/nzp2qUaOGNm7cqEOHDqlKlSqqW7eujhw58pIrBwAAAADgn9k1dI8fP17t2rVT+/btVbhwYU2cOFHe3t6aPn16outPnDhRffr0UZkyZZQ/f36NGDFC+fPn1/r1619y5QAAAAAA/DO7he7o6GgdOnRIfn5+CZb7+flp7969z7QPi8WiBw8eKH369LYoEQAAAACA/8TJXi98+/Ztmc1meXp6Jlju6empkJCQZ9rHuHHjFBERoQ8++OBv14mKilJUVJT1cVhYmCQpJiZGMTExz1E5gKTGxdHeFQC2k1S/yzguXxIj4UNnR0n87G2KYxJPxTFpF7Y6Lp91v3YL3XFMJlOCx4ZhPLEsMUuXLtXgwYO1du1aZc6c+W/XGzlypIYMGfLE8q1btyplypT/vmAASU4/3zT2LgGwmY0bN9q7hOfCcflyREVFaWa8qW8C3vKQq6ur/Qp6DXBM4mk4Ju3DVsdlZGTkM61nt9CdMWNGOTo6PtGqffPmzSdav/9q+fLlateunYKCglS9evWnrhsYGKiePXtaH4eFhcnb21t+fn7y8PB4/jcAIMl4e+BSe5cA2MzOYc3sXcJz4bh8SWKjFb+JYcL+MMnJxW7lvA44JvFUHJN2YavjMq4X9T+xW+h2cXFRqVKlFBwcrIYNG1qXBwcHq379+n+73dKlS9W2bVstXbpUtWvX/sfXcXV1TfTqkbOzs5ydnZ+veABJSrTZ3hUAtpNUv8s4Ll8O019+zjFmyfjnDoX4Dzgm8TQck/Zhq+PyWfdr1+7lPXv21EcffaTSpUvL19dX33zzjS5duqTOnTtLetxKffXqVS1YsEDS48DdsmVLTZo0SeXKlbO2kqdIkUJp0tAlBgAAAADwarFr6G7SpInu3LmjoUOH6vr16/Lx8dHGjRuVM2dOSdL169cT3LN75syZio2NVdeuXdW1a1fr8latWmn+/Pkvu3wAAAAAAJ7K7hOpdenSRV26dEn0ub8G6e3bt9u+IAAAAAAAXhC73acbAAAAAIDkjtANAAAAAICNELoBAAAAALARu4/pBp6HYRiKiIiwPk6VKpVMJu63AAAAAODVQuhGkhQREZHgfu5r166Vu7u7HSsCAAAAgCfRvRwAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjTCR2gtW6rMF9i7htWCKjVaaeI/fGbhMhpOL3ep5XRwa29LeJQAAAABJCi3dAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0wezmSJMPRWfeLNUvwGAAAJMT3JQDYH6EbSZPJxC3CAAD4J3xfAoDd0b0cAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGzE7qF72rRpyp07t9zc3FSqVCnt2rXrqevv2LFDpUqVkpubm/LkyaMZM2a8pEoBAAAAAPh37Bq6ly9frh49emjAgAE6cuSIKlWqpFq1aunSpUuJrn/+/Hm99957qlSpko4cOaL+/furW7duWrly5UuuHAAAAACAf2bX0D1+/Hi1a9dO7du3V+HChTVx4kR5e3tr+vTpia4/Y8YM5ciRQxMnTlThwoXVvn17tW3bVl999dVLrhwAAAAAgH/mZK8Xjo6O1qFDh9SvX78Ey/38/LR3795Et9m3b5/8/PwSLKtZs6bmzJmjmJgYOTs7P7FNVFSUoqKirI/v378vSQoNDVVMTMx/fRtPcIh9+ML3Cbwq7ty5Y+8SngvHJZIzjkvg1cIxiaeKjVZsbKz1oSn2oUwy27Gg14OtjssHDx5IkgzDeOp6dgvdt2/fltlslqenZ4Llnp6eCgkJSXSbkJCQRNePjY3V7du3lTVr1ie2GTlypIYMGfLE8ty5c/+H6oHXU8aJne1dAoC/4LgEXi0ck/hXdu60dwWvBVsflw8ePFCaNGn+9nm7he44JpMpwWPDMJ5Y9k/rJ7Y8TmBgoHr27Gl9bLFYFBoaqgwZMjz1dfDqCwsLk7e3ty5fviwPDw97lwNAHJfAq4jjEni1cEwmH4Zh6MGDB/Ly8nrqenYL3RkzZpSjo+MTrdo3b958ojU7TpYsWRJd38nJSRkyZEh0G1dXV7m6uiZYljZt2ucvHK8cDw8PPrCAVwzHJfDq4bgEXi0ck8nD01q449htIjUXFxeVKlVKwcHBCZYHBwerfPnyiW7j6+v7xPpbt25V6dKlEx3PDQAAAACAPdl19vKePXtq9uzZmjt3rk6dOqWAgABdunRJnTs/7nMfGBioli1bWtfv3LmzLl68qJ49e+rUqVOaO3eu5syZo969e9vrLQAAAAAA8LfsOqa7SZMmunPnjoYOHarr16/Lx8dHGzduVM6cOSVJ169fT3DP7ty5c2vjxo0KCAjQ1KlT5eXlpa+//lqNGze211uAHbm6umrQoEFPDB8AYD8cl8Crh+MSeLVwTL5+TMY/zW8OAAAAAACei127lwMAAAAAkJwRugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAIAky2KxSJJe1TnC7XrLMCC5sVgscnDgWhYAAADwMnz11Ve6fv26OnToIC8vL3l4eNi7pCeQDoD/KCoqStu2bZMka+COu9oGAABe3dYnAElbTEyMTCaT7t+/rzp16qhr164KCgqyd1lP4D7dwHMyDEMmk0ljx45VUFCQzGazmjVrprp166pgwYL2Lg94pcQdLwBeH1FRUZo3b56KFSsmX19f62cAnwcAXgSz2SxHR0fr440bNyo4OFjffPONPvvsMw0ePNh+xf0FoRt4TnEnDQ8ePFDq1Kk1fPhwHT58WDt27NDkyZP1wQcfJPggAF5XccfKjh07FBwcrPPnz6tu3bqqVq2aMmXKZO/yANjImjVrtGHDBq1cuVINGjRQsWLFFBAQYO+yACQz0dHRcnFxkSSFhYVp1apV6ty5szp37qyJEyfat7j/R/dy4DlER0fr448/1q1bt5QyZUpJ0oABAzR58mR98sknatGihYYPH66wsDA7VwrYn8lk0urVq9WwYUOdP39enp6e+vDDD9WvXz+FhITYuzwAL1hMTIwkqUGDBpo9e7Y2b96s3Llz66uvvlKdOnV0+fJlO1cIIClr27at3n//fX3++ee6e/euNXBLkoeHh1q3bq3ly5dr6tSpGj9+vB0r/R9CN/AcLl++rFOnTslkMsnR0dF6guHl5aXBgwdr1qxZGjx4sObMmSOJMd54vZ0/f16BgYEaNWqUFi9erPHjx8vV1VWZM2dWlixZ7F0egBfIbDarffv22rp1q6THPV3Kli2rfv36adOmTTp16pQaNmyoY8eO2blSAElVv379VKVKFR0+fFhFixbVyJEjE3ymGIah+vXr66uvvtLXX3+t7du326/Y/0foBp5D3rx5FRsbq4EDB0qSnJ2dE0wS065dO02aNEm9e/fW3r17mdEcr7XY2FilTZtWHTt21JkzZ5Q9e3a1aNFCI0eOlCSdOHHCzhUCeFEiIiIUGhpq7ekVd9HZxcVFxYoV06+//qrIyEh9/PHHr/wtfgC8egzDUIECBdSlSxdt3LhRPXr00JYtW9SrVy/99NNPkmSdM6Ju3boqV66c9u/fL8m+jWAkAeBfMpvNkqTAwED9/vvv2rNnjyQlmCBGkj755BO1adNGQ4cOVWhoqH2KBV4Bt27d0qVLl7Rnzx69++67eu+99zR9+nRJ0oEDB/TFF1/ojz/+sHOVAF4EDw8PVa1aVV988YWuX7+eYG4Ts9ms1KlT68cff9Sff/6pTz75RJKYVA3AM/vr+XafPn3Ur18/pU2bVr1799auXbus6+bJk0fvvPOOvv76a927d8+ujWCEbuBfiD9LYtmyZRUVFaUFCxbo/v371nXiPgxMJpPef/99hYWF6fbt23apF3jZ4r4E47dclS1bVm+99ZbeeecdlS5dWt988431OFq9erVCQkKUJk0au9QL4MWJa0WqV6+evL29tXbtWuvwK0lydHSUxWJRlixZNHnyZB06dEg///yzvcoFkISEh4dL+t/njMlksp5rvPvuu+rRo4dy5cqlqVOnJpg3onPnzipXrpx+++23l190PIRu4BkZhmENCgMHDlRUVJRGjRqluXPnaty4cYqOjrauG/eBULNmTXl4eOjrr7+2S83AyxQ3S/nOnTs1bNgwjRkzRpcuXZKjo6Nat26t4sWL69atW9q/f7+2bdum3r17a+rUqZo+fbo8PT3tXT6A/8BsNltbkfLmzasSJUpo4sSJT4zdjlunXLlycnNz05EjR156rQCSlnnz5ilfvnw6fvy4HBwcEg3e5cuXV9OmTXXixAlrd/LY2FhZLBa99957Sp8+vd3ql7hlGPBM4rdw9+7dW8HBwVq5cqXy5cunRYsWqVWrVgoICNDHH3+svHnzSpIePXokNzc3bd26VefOnVPHjh0Z241kb+PGjapXr56qV6+u7du3q3Tp0urbt6/q1q2rNWvWaNasWQoODlbBggWVJk0aTZ06VW+++aa9ywbwH8S/73abNm1UrVo1ffjhh6pQoYLCwsK0cuVKFShQ4Il1Z82apTlz5mjLli30dgGQqODgYLVs2dIatoODg+Xj4yOLxWI9r47/udK9e3dt3rxZp06dsj4ff117IQEAzyAucO/evVt37tzR5MmTlS9fPknShx9+qFWrVmnhwoXq37+/Zs6cKUlyc3OTJJUqVUr+/v52P9gBW4m7dnvjxg0FBQVpxowZ2rx5s65evaqUKVNq1KhRWrt2rRo0aKDvv/9ehw4d0vbt27VhwwYCN5DEmc1m68nuxIkT9euvv8rX11fS44twLi4uqlOnjr7//nvdu3dPJpPJ2uW8atWqatmypfXWmwAQ371797Rp0yY1aNBAGzduVNmyZfXOO+8k2uId9++hQ4cqe/bs2rt3r6TH5yivwjm4/SsAkoh58+apatWqWrduXYJJHCwWi+rXr6/NmzfL29tbkyZNUuXKlTVhwgTdunVLGTJkUMaMGe1cPWA7JpNJe/bsUdu2bfXnn3+qZMmSkqQMGTJo0aJFSp06tcaMGaPvvvtOFotFb7zxhjJkyKC0adPat3AA/1ncRenly5fr5MmT6tGjh/UOH2nSpNHBgwdVpEgRDRs2TD179tSxY8es36F58+ZVixYt5OzsbM+3AOAVlTZtWlWpUkUtWrTQm2++qenTp6tChQoJgnfchf+4YJ0iRQq5u7vr999/l/TqTNRI6Ab+xl9HXrRp00bdunVTeHi4NmzYoNDQUOuBbLFYVKJECY0ePVr79+9Xw4YNlT59eutM50BylyVLFp07d0579+5NMIYzc+bMWrRokdKlS6dhw4ZpzZo19isSgE2cPHlSrVu31uzZs3X16lVJkpOTk2JiYmQymbRmzRp98skncnFxUbVq1dS9e3cFBwdLEt3KASQq7jy8bt26qlixoiQpa9asmj59uipWrKjKlSvr+PHjMplMunnzpjZu3Kj79+/LxcVFkyZNsg5peVUwphtIRPwx3GazWREREfLw8JAkde3aVRs3blSfPn3UvHlzpUmTxjqWJP6YEuB1c+HCBTVs2FBp06bVoEGD9M4771ifu3nzprp27aqxY8cqV65cdqsRwH+X2PjI3bt3q2XLlsqRI4fGjBmjt956S5IUExOToCV7//79io6OVv78+ZlAEcAzi3+Ofe3aNXXp0kV79uzRihUr1K9fP6VOnVpbtmx5Zc/DCd3AX8QP3P3799dvv/2mR48eqUyZMho5cqSkx7cf+OGHH9S7d281a9aMK/V4rcR98Z0+fVqXL19W2rRplSVLFmXPnl1//PGH/P39lTVrVgUGBiYI3q/CRCYA/pv435GXLl2SJKVLl856/+22bduqUqVK6tWrl4oXLy6JYx/AixcSEqL27dtr48aNeuONN3Tw4EE5Ozu/sg1gTvYuAHjVxJ1MNGrUSH/++afatWunjBkz6qOPPlJUVJTGjx+vGTNm6OOPP9a4ceMUHh6url27KkWKFHauHLC9uC+zlStXqnv37tYvODc3N33zzTd6++23tWLFCvn7+2vs2LGKjo6Wn5+fJHHSDSRxFovF+h3ZqVMnHTp0SA8fPpSDg4N13pO5c+eqXbt2cnBwUEBAgIoXL86xD+CFM5lMunr1qsqWLatdu3bJyclJsbGxcnJ6NeMtn4LA/4ub9VCSNm/erLNnz2rdunXq3r27QkNDlSZNGr377rvWdaZPn66SJUsqJCSEwI3XQmxsrEwmk/bv3682bdpo4MCB2r17t7799luVKVNGNWvW1K5du1SgQAGtWrVKx44d08yZMxUZGWnv0gG8AHHhuVmzZtq1a5cmTpyodevW6c6dO+rcubNCQ0NVtWpVzZkzRzt37tTnn39ubQ0HgBclOjpaEyZM0MOHD7Vz585XPnBLtHTjNffw4UO1adNG33zzjTw8PKxd4C5duqR06dIpV65cGj16tEaPHq3ly5fLz89PFy5c0OHDh9WoUSMtX77cuq9XtTsL8F9dvHhROXLkkJOTk8xms44dO6bSpUurQ4cOcnBwULZs2VSwYEFZLBZ1795dGzduVL58+bRz505ZLBZuBwQkUfG7ksc5e/asLl26pO+++04+Pj4aN26cYmNj9eWXXyp9+vSKjY1V1apVNXnyZP3444/KkSOHnaoHkFy5uLiofv36Gj58uBwdHV/5wC3R0o3X3LVr17Rjxw5VrVpV4eHh1qv4OXLkkJubm3r37q3Ro0dr2bJl1i6yv/76q5YsWaKLFy9a90PgRnIVFRWlpk2bKk+ePDIMQ46OjgoLC9Ovv/6qsLAwSY///rNkyaLmzZvr9u3bunv3riQpV65cypMnjz3LB/CcYmJiVKZMGX3zzTcJll+/fl2nT5+Wj4+PJk2apOHDh2vRokV69913FRISoi+//FIPHjxQnTp1NH78eElP3g0EAP4rX19fOTo6ymKxvPKBWyJ04zWXN29e/fDDD4qJiVGlSpUUHh4uSfL09NSNGzc0depUjR492hq4r1+/rqFDhyp37tzKmTOndT8EbiRXLi4uGjt2rNzd3VWyZEkZhqH69esra9asmjdvnu7fv2/9+8+fP7+cnZ314MEDO1cN4L+KjY1VpUqV9Mknn2jRokXW5QUKFFCZMmXUtGlTDRo0SCtXrrR+R168eFG7d+/WyZMnE+yL70gAf+e/XpRLKnNGJI0qARsqWrSoFi9eLLPZrIoVKyo8PFwlSpRQ3759lTFjRm3evFkjR47UlClTVL16dWXLlk1jx46VxNV7JH8mk0nly5fXrFmz9PDhQ5UtW1Z58uRRw4YNNW/ePM2aNUs3btxQeHi45s6dKwcHB24JBiQDKVKk0IgRI9S3b1+1bNnSGrzd3d2VIUMGrVy5Up988omqVKkiSbp69ao6duyo3Llzq2zZsvYsHcAr7scff9SKFSusc8X83fl0/OVJ/ZybW4bhtZRYd/Bjx46pRYsWkqS9e/fK3d1dK1as0ObNm7Vx40aVLVtWefPm1VdffSWJW6Ag+QoJCdGFCxdUrlw567KYmBgdOXJETZs2lbe3t3bs2KGBAwdqzZo1+vPPP1W8eHGdPXtWW7ZsUYkSJexYPYAXKSIiQiNHjtSIESM0b948tWrVSqGhoXr//fcVGhqqTJkyKXfu3Nq5c6fy5cun9evXS2LYFYDEBQUFqUmTJnrzzTc1ePBg1a5dW05OTk98ZiT2GZKUP1cI3Xjt/HVimJiYGDk7O8tisejkyZNq1qyZTCaTNXibzWaFh4crderU1pBN4EZydfnyZZUoUUKhoaGqXLmyfH19Vb16dZUpU0apU6fWgQMH1K5dO3l4eGj37t0KCQnRxo0blS5dOpUsWTLBsAsASU/c91v8k9v79+9r7NixGjFihObMmaM2bdro7t27Wrp0qXbt2qXMmTMrd+7c6tGjR4J9AEB8p06dUqtWrVStWjUdOHBAYWFh6t+/v+rUqZNo8JakTz/9VOnSpdPQoUPtVPWLQejGayV+4B46dKjOnj2rBw8eKCAgQJUqVZIkHT9+XM2aNZOTk5N27dold3f3BPtIylfZgH9y8eJFNWjQQA8fPlTq1KlVtGhRLV++XIUKFZKPj4/q1q0rk8mkwMBA5cmTR1u2bOF4AJKJ+N+R9+/fV3R0tDJlyiRJevDggUaPHq0RI0Zo7ty5at26daL7IHAD+DunT5/WrFmz1LFjR+XKlUvvvffeU4N3eHi4hg4dqm3btmnDhg3KmjWrnd/B8+NTEa+NuJmXJalx48YKCgqSh4eHMmfOrCpVqmjJkiWSJB8fHy1btkxms1kFCxZUVFRUgv0QMJCc5cyZU0FBQSpSpIiyZcumjz/+WKdPn1bfvn11/vx5jRs3Tq1atVKKFCn0ww8/qFGjRpKS/lgr4HUXP3B369ZN7777rqpWrar27dtLklKnTq3AwEAFBgaqQ4cOWrhwYaL7IXAD+Dt58uRR7969VaBAAbm4uGjNmjVKnTq1RowYofXr18tsNstkMlknZHV3d1fr1q2td05Jymjpxmtn2LBhCgoK0g8//KDMmTNr8uTJ6t69u5ycnDRlyhR17NhRknTkyBEFBQVpxIgRdq4YePlOnz6t7t27y2KxaPjw4SpTpowk6d69e1q/fr1Onz6tTZs2afbs2YzhBpKR999/X6dPn1bPnj2VOXNm1a1bV02bNtWECROUOXPmBGO8d+/erfLly9u7ZABJUNzwzoiICNWrV08PHjzQ559/rlKlSqlLly6qWrWqunfvLkn66aefrJM2JlWEbiR78bup3Lt3T9OmTVPRokVVv359TZw4UUOHDtXy5cu1bds2ff3115o5c6Y++uijBPuguxxeR2fOnNGnn34qSQoMDFTlypUTPB8bG5sk7o0J4NnMnTtX06dP18qVK5UjRw5NnjxZn3/+uRwcHFSmTBktWrRImTNnVnh4uDZv3ix/f397lwzgFfUs585xwTsyMlL169fX3bt3FRoaKldXVx07duyJc4ykPMST0I1k7a+TpknS77//rkyZMuncuXP68MMPNXr0aDVo0EAbNmxQvXr1JEk//PCDqlatao+SgVfKmTNn1K1bNxmGoS+++IJWLSAZiX9SbLFYtHLlSkVGRqpVq1aaNm2aBg8erKVLl8rd3V2VKlWSv7+/xo8fryxZsiS6DwCQpLt37ypdunRPLI8LzWFhYfLw8JD0v3P18+fPK2/evCpXrpx27NghZ2fnRM/jkyo+JZFsxT9Qe/bsqX79+kmSChUqpAwZMuj8+fNKmzatdQK1VKlSaeDAgfr+++8J3MD/y58/v77++ms5OzurV69e+vnnn+1dEoAXwGw2W8Py5cuX5eDgoHr16qlOnTq6du2aZs+erTFjxqhatWpKnz69vL29tWzZMs2bNy/BfgjcAOKbNm2aWrZsKYvF8sR9tk0mk9atW6cBAwbo7t27kiRHR0fdvn1b/v7+KlKkiHbu3ClnZ2fFxsYmm8AtEbqRjMUdqA0aNNCPP/6oPHny6Pbt29bnDcPQgQMHtG/fPu3du1cBAQF68OCBatWqJenx1XsAj4P32LFjlT17dnl5edm7HAD/UfyL0u3bt1fbtm31+++/y9XVVRkyZFBISIhu376tt956S9LjYF21alWdO3dOgYGB9iwdwCsue/bsMgxDDg4OMplM1uBtMpm0YsUKNWnSRMWLF0/QEu7o6KgSJUro8OHDcnJySpbD1+hejmRt2rRpmjhxorZt2yZvb29JCceDdOzYUbNnz1bOnDn15ptvas2aNXasFni1RUdHy8XFxd5lAHhB/P399ccff2jcuHEqVqyYPD09JUm3b99WgQIF5Ofnp5o1a2rs2LEqUaKEFi9eLIku5QD+3sOHD1W4cGF17NhR/fv3l/T43PvKlSsqUqSIRo0apa5du/7t9skxcEuEbiQDiU2qEHdC0KNHD12/fl3Lly+3Lvvr+vv375ezs7N1BmZOJgAAyd2WLVvUo0cPrVy5UkWKFJH0+PvUYrHI0dFRP/zwgzp06KBMmTKpYMGC1luEJeWJjADYVlwvmilTpmjz5s0aNGiQ9e4nkvTnn38qX758dqzQfkgWSNLif/lv2LBBmzdvlqQEE8Ncu3ZNUVFRCQJ3WFiYFi1aJEl66623CNwAgGQnfrtK3JCpuP9fuHBBUVFRyps3r3Vdk8kkR0dHRUdHq3r16jp27JjWrVtnDdwWi4XADeBvxQ1bqVixoq5du6YFCxbo2rVr1udf18AtEbqRhMUP3IMGDVL//v21dOlSXblyxbpOsWLFdO7cOW3YsEGRkZEJbh02duxYrV27NsE+CdwAgOQg/nfkokWLNHToUEVERFi/5zw9PeXk5KRTp05Jejze0mw2KzY2VlOnTtWBAwfk7u5unak8bowmACQm/kW+4sWLa+DAgZozZ44mTpyoixcvWp97XedMSn4d5vHaiDuZGDBggObMmaPFixerWLFiypQpk3Wd9u3ba8OGDQoICNDFixdVunRpxcbGqlu3bipcuLDq169vr/IBALCJ+IG7f//+WrlypWrVqqWzZ8+qWLFikqQCBQooPDxcM2fOVN++fZUrVy45Ojrq1q1bmj9/viwWS4JuobRwA/g7cd3Kr1y5otjYWOXMmVMNGzbU3Llz9fHHH+vOnTtq1KiRateunaA36ut0IY8x3UjSfvzxR3Xq1Enz5s1TxYoVEzx39uxZa7e5gIAA7d69W4cOHVKJEiVUqFAhJoQBACRrgwcP1syZMxUUFKTSpUvLzc0twfNr1qxR69atVa1aNRUrVkxZs2bV+PHjVbBgwSd6ggFAYuIC97Fjx1SmTBnNnTtXzZs3tz6/efNmzZgxQ9euXVPJkiXVrVs35ciRQ+7u7nas+uUjdCNJmzNnjmbMmKF9+/bJyclJhmFozpw5Wrt2rbZt26YSJUpoyJAhql69um7fvq0rV67Iw8NDefLkkUTgBgAkT6dPn1bz5s315ZdfWm+FKUn379/XwYMHlSNHDuXPn18///yzpk6dqt27dytfvnwqVKiQJk+eLInvSABPFz9w16hRQ02bNtXEiRNlGIauXr2qbNmyyWQy6fLlyzp//rwCAwPl6emp/Pnza/DgwUqRIoW938JLQ/dyJCmRkZEKCQmxhmYPDw/dunVLW7ZsUYUKFdSiRQuFhYXJy8tLixYt0vDhw9W/f3/5+voqY8aMypgxo3VfjE8DACRXd+7c0blz55Q7d25Jj7/zRo8erc2bN2vXrl1yc3NTly5dNGbMGJUuXVpRUVEyDMPa+kTgBvA08QN31apV9dFHH2n8+PGyWCwqUqSI2rVrp169eslkMsnb21ve3t7auXOnQkNDde/evdcqcEtMpIYk5tNPP1Xx4sV18uRJSY8naihTpoxatWqlnDlz6v79++rXr59mz56tRo0aaebMmTp06JBOnDjxxL4YnwYASG7iOjBmzZpVefLk0aRJk/TLL7+oYsWKWrdunUqXLq3Tp09r+PDhmjp1qvbs2SMnJyelSpXKGri5KA3gaeIC9/Hjx58I3L6+vvL29lanTp0SfI7E3Y4wU6ZMyp8/v6SEk68ld3QvR5ISGhqqxo0b68qVK1q7dq2KFCmic+fO6caNG7p58+YTE6Nt3LhRQ4YM0bJly6xX+wEASI7iToSlxyezY8aM0ZIlS3T9+nWVLl1agwcPlo+Pj1KmTKmYmBjlypVLw4cPV+vWre1bOIAkI26ixqNHj8rPz08tWrSwBu633npLGTNmVFBQkFKnTm3vUl8phG4kGTExMXJ2dtaDBw/UoEEDhYSEKCgoSEWKFEl0/WvXrqlu3boqU6aMZsyY8ZKrBQDAPgYPHqyWLVvKy8tLDx8+VEhIiAoXLpxgnaNHj+qjjz7SpEmTVKVKFTtVCiApunnzpt555x1VrVpVU6ZMIXA/A0I3koT4V+8nT56s0NBQDRkyRMWLF9eiRYsSBO/Lly9rx44dGj9+vLJly6b169dLSngLFQAAkqMLFy4oX7582r17t8qVKycp4fef2WzWlStXVL9+fb3xxhtauHChPcsF8IqL+/yI/zly+fJlHT9+XLVq1ZLZbFa5cuWUIUMGAvdTELqRpPj7++uPP/5QQECALl++rJUrVyoyMlJr1qxR0aJFFRERoaFDh+rkyZMqUKCAxo0bJ4kJYQAAyVP8i9LS415hpUuX1vDhw1WnTp0E654/f14rVqzQ8uXLlT17dq1Zs0YSF6UBJC7++fPVq1fl4OCgtGnTWidBMwxDNWvWVHR0tNavX0/gfgpCN15p8U8EDhw4oPr162vVqlXWq/fXrl2Tv7+/QkNDtXLlShUtWlQXLlzQo0ePVKhQIUkEbgBA8nfs2DG98cYbkqQaNWrozTff1FdffSXpcTCXpBkzZujw4cPKlSuXBg4cKInvSACJi38OPmzYMK1Zs0YPHz6U2WzW+PHjVaVKFUVGRur7779X48aNX7v7bv9bhG68suJfvY+JidHvv/+ucuXK6eTJk8qZM6f1+d9++02VKlVS4cKFNWPGDBUvXty6D67eAwCSu379+mnGjBny8vKSi4uLUqRIocyZM+vjjz9WmTJl5ObmplSpUkmS7t69q3Tp0kkicAP4Z0OHDtWUKVM0a9Ys+fr6qlGjRrp8+bJ++ukn6y188c/4pMUryTAMa+D28/NTjx49VKhQIWXNmlWTJk2SJOvznp6eKlCggI4dO/bE2DQCNwAgufvwww/166+/auDAgfL395ezs7PWr1+vL774QoUKFdIbb7yhihUrKjg42Bq4uS0YgH9y7949/fTTT5o+fbrq16+v/fv368SJE+rXr1+CwG2xWOxYZdLgZO8CgL+Kf+V98+bNio2NVY8ePeTg4KCOHTtq5cqVGj58uAYMGCDpcYt49uzZ9d1333FbMABAsvbXMdyS5OPjI0nKlSuXJKlw4cL6448/9N133+ncuXO6evWqrl69qho1ali34aI0gH9y//59/f7776pcubK2bdumZs2aaezYsercubMiIiI0adIkffrpp4zlfgaEbrxy4gL3xIkTtWnTJpUoUUL58+eXJH300Ue6ffu2vv32W33//fcqUaKENm3apDfeeMMauOlSDgBIjuIH7qCgIN25c0cZM2ZUnTp15ObmpqioKLm6uqpgwYJKlSqVUqRIoapVqybYB13KATyrnDlzqkSJEvr444+1adMmTZo0Se3atZMk3blzRxs3blThwoXVsGFDO1f66mNMN15JISEh+vjjj7Vr1y5VqVJFQUFB1ufu3LmjI0eOaMaMGXJzc1PWrFk1duxYSQRuAEDyFD8s+/v76/Tp0zKbzcqUKZNSpkyplStXKmXKlJKkiIgI5c2bVxMmTFCzZs3sWTaAJCD+58vIkSNlsVj02WefydHRUV9++aUmT56satWqafny5ZIef8Z88MEHio6O1ubNm5/ofYMn0dKNV8Jfw3KWLFk0duxYjRw5Ups2bdKUKVP0ySefSJIyZMig6tWrq3r16gn2wdV7AEByFff91rVrV50+fVqbN29WtmzZ1LlzZ33zzTeqUqWKtm3bJnd3dzk4OCh16tSKiYmxc9UAXnXxz59Pnz6t06dPa8GCBUqbNq26du2qgIAAXbhwQYcPH1aVKlWUP39+nThxQuHh4Tp48KAcHR0THfaChEgosDuz2WwN3GFhYYqJiVFsbKzy5cunvn37qmbNmlqyZIlmzpxp3eavJxJMCAMASC7id0KMjo62/vvkyZO6cOGC5syZo2zZsmnSpElavny5Ro4cqXv37ql27dqKiIhQihQpNHnyZLVs2dIe5QNIQuLOn/v06aPGjRvLZDLJx8dH3bp106hRo+Th4aFJkyapb9++ypYtmywWi959910dOnRIzs7Oio2NJXA/A7qXw67iXxnr2bOnjh49qujoaFWrVk3dunVT+vTpderUKY0ZM0ZnzpxRy5Yt1bFjRztXDQCA7Y0ePVqGYahLly7y8PCQJK1fv946qVH37t01e/Zs+fn56eOPP9bMmTOVI0cO/f7773Jzc5NELzAA/2zdunX68MMP9cMPP6h06dJ68OCBZs6cqX79+mnUqFHq06dPotvRwv3s6F4Ou4l/WzB/f38dP35c/fv31/nz57V8+XIdP35cM2bMUOHChdWnTx+NHTtWY8eOVf78+VWlShU7Vw8AgO1s27ZNgYGBkiRnZ2d16NBBHh4eqlu3riRp9+7dqlu3rvz8/CRJuXPnVseOHZU3b15r4JZE4Abwj+7cuaM8efKoRIkSMplMSpMmjfr06aPIyEgFBgYqderU6tix4xMBm8D97PgkxksVExNj7TYX16V83Lhxunjxonbs2KGWLVvK3d1dFy9e1KlTp9S6dWuFhoaqcOHC6tGjh/r27UvgBgAke++8847q16+vkiVLqk+fPpowYYIiIyOtz1+9elX79u2TYRgKCQnRunXrVKZMGX322WeSuG8ugGeXLl06HT9+XOfPn5fJZJLZbJYkvffee3J0dNSnn36q2bNnS0o4/AXPjtCNlyY2NlblypVTv379EpwMZM2aVQ0aNJCnp6cmTJigMWPGKCgoSF26dNH27dvVvn173bhxQ8WKFVP79u0lccADAJIvs9ksi8WiggULys/PT8uWLdOQIUM0duxYRURESJLatGmjqKgoeXt7y9fXVx4eHtZb+TDPCYDExD//jj8/0jvvvKOqVasqICBAf/zxh7UFO0OGDOrUqZOGDRumbt266fDhw9wl6Dkxphsv1eTJk9W7d28NHDhQ/fr1k5PT4xEO9+7d0/3799WwYUP17t1bzZs31/nz51W9enVFR0fr008//dvxJAAAJFVPu9Xl8ePHVbZsWW3evFnXr19X06ZNNXjwYPXv318Wi0WHDh3S3r17rV0/JcZwA0hc/M+aKVOm6PDhw/Lw8FDHjh1VpEgRrV+/XhMnTtSjR4/0+eefK2XKlBo9erScnZ319ddfq1KlShoyZIjatGlj53eSNDGmGy9NbGysPv30U6VMmVIdO3aUs7OzevToIVdXV6VNm1a//vqrrl69qlKlSkmSbt++rbfeeksdO3akSzkAIFmKOwkeNmyYIiIiVLZsWTVs2FCS5OPjo4CAAK1atUoTJkzQ3bt39fHHH0uSAgMD5evrK19fX+u+CNwAEhM/cI8YMUIjR45U06ZNtWTJEu3bt099+/ZVo0aNlCJFCs2ePVt16tRRvnz5lC5dOu3Zs0cWi0Vp0qSRu7u7nd9J0sUnM16K2NhYa6t2sWLF9MEHHygwMFCTJ09WbGysJClz5szKli2bRo8erQ0bNqhVq1bKkCGDNXDTKQMAkBxt375dgwYN0owZM/T555/Lz89Pq1ev1q1bt+Tn56c1a9bo2rVr6tSpk7755hsNGTJE/fv316NHjxLsh8ANIDFxgfvUqVM6ceKENm3apFmzZunixYvKmDGjxowZoxUrVqhatWpatmyZjh8/rh9//FH79u2To6OjPv/8cz169EjlypWz8ztJuvh0xksRF7gbNmyoTz/9VO7u7qpQoYL69OmjUaNGSZLy58+vZs2a6ciRI+revbtKlCihKVOmSHp69zsAAJKyd955R927d1dkZKS6dOkiLy8vLV68WBUrVtSDBw/k5uamkSNHKiYmRu3bt9eECRN08+bNBLOUA8DTzJ49W02aNNHp06eVLVs2SVKKFCm0cOFCZcyYUePHj9fSpUsVGxurwoULK1u2bNq3b5+6du2qOXPm6LvvvpO3t7ed30XSxZhuvDRz585VYGCgDhw4oBw5cigyMlJz5sxRjx49NGTIEH3++eeKjY1VZGSkbt26pbx580qiuxwAIPmK3xOsbdu22rRpk6ZOnarSpUtr/fr1CgoK0v79+1WzZk199913cnZ2TrA9F6UBPIsLFy7ogw8+0IkTJzRnzhw1bdrU+tzdu3fVunVrnTp1SlOmTLHeivDMmTNas2aN6tevrwIFCtir9GSB0I2XZsKECVq0aJEOHTqU4LZhgwcP1pdffqmvvvpKn3zyifXkQ+JkAgCQPP3dBeVWrVpp9erV+uabb9S0aVPdunVLv//+uwoWLKjMmTPzvQjgH/3d58vVq1dVv359pU6dWp9//rmqVatmfe7OnTsaPXq0Ro4cmeD+22azmftxvwCEbthEYicFq1atUvPmzXX48GEVKVLE+oEQHBysWrVqyWKxaPXq1apfv76dqgYAwPbin8QeO3ZMzs7OKlCggPUkuW3btlq2bJnmzp2rRo0aycXFRRI9vwD8s/ifEydOnNDdu3dVtGhRubm5KUWKFLpw4YIaNWqkdOnSqX///gmCdxyC9ovHJzdeOLPZbA3ccfcTlaS3335bVapUUZ8+fXTixAnrB0L69OkVEBCg7du3E7gBAMmaYRjWk1l/f3/5+/vLx8dHn3zyifbu3Svp8XCspk2bqmPHjlq9erV1wjQCN4CnMQzD+jkxYMAA1a9fX40aNVLFihU1depUXb16Vbly5dKqVat07949jR49Whs3bnxiPwTuF49Pb7xQ8U8mevXqpSZNmujDDz/UgQMHlDFjRn366aeKiopS8+bNNWvWLC1atEitWrXS3bt39fbbb0t6fIUOAIDkxDCMBBelx40bp/Pnz2vOnDmaN2+etm3bpgkTJujHH3+U9Dh4v//++2rWrJmOHj1qz9IBJBFxny9ffvml5s2bp6lTp+rmzZsqVKiQJk2apMmTJ+vKlSvW4H3y5Elt2bLFzlW/HrhPN16Y+N1ZOnbsqK1bt+qjjz7S0qVL9fvvv6t3795q2rSp0qZNqwULFuizzz5Trly59Oabb2r27NmSEl6hAwAgqYuJiZGDg4McHR2tF6VXr16tP//8U1988YUqVqyoihUrKk+ePPrkk080bdo0mUwmValSRXPmzJGvr6/Kli1r53cB4FUW/xz8zJkzCg4O1rRp01SzZk1t2bJFwcHBqlixohYvXixJ+uSTT5QzZ04dPHhQmTJlsmfprw3GdOOF++WXXzRlyhR98cUXyp8/v8xms/z9/XXlyhUFBASoSZMmcnR01LVr1+Tm5qb06dNLYqwaACB5efjwoZo1a6ZOnTqpVq1aMgxDhw4dkq+vr8xms6ZOnaqPP/7Yuv7evXv16aefKnfu3GrXrp1q1aplfY7vSACJiT+P0u+//66MGTNq9+7dqlatmn777Tf5+/tr8ODB6tSpk+rXr6/Dhw+rdu3aGjx4sLJkySKJMdwvA5/eeKGGDBmixo0b69ixY0qdOrWkx+NCFi5cqOzZs2vy5MlatGiRoqKi5OXlZQ3ctHADAJKbmJgYVa1a1RqeLRaL9VZgXl5e2rp1q44fP25dv3z58po8ebL27dunP//8M8G++I4E8FfxA3e3bt3UsmVLxcbGqmrVqkqdOrUWL16sunXrql27dpIkb29vpU2bVg4ODvL09LTuh8Bte3yC44Xq0KGD8ufPrwsXLmjHjh3W8dnu7u5auHChsmbNqqFDh+rAgQMJtuP2JwCA5CYsLEzdunWTJA0ePFhjx45VTEyM3n33XU2dOlUHDx7U119/rZMnT1q3KV++vLZv365PP/3UXmUDSCLizp/v3r2rixcvauzYscqSJYs8PDysy8PDwxUdHS1JunXrlkaPHq2pU6fKZDKJDs8vD6Ebz81sNj+xzMvLS999950KFy6sKVOmKDg42HpAu7u7a8GCBerevbsqVqz4sssFAOClGT58uCpXrqxFixZJko4ePWq9/3ZMTIzq16+vSZMmafPmzZo0aVKC4J0/f35JTCwK4J9NmDBBFSpUUGRkpAoVKpTgufz58+vo0aNq0qSJ3nrrLf3222+qWbOmTCaTLBYLjV4vEROp4bnEH/uxc+dO3bhxQ76+vvLw8FCmTJm0atUqNWjQQCNGjJAk+fn5yWQyyd3d3XrVP7F7eQMAkNRduXJFc+fO1YMHDxQUFKQ0adJo+fLl6tKlixYsWCCLxaLOnTurUaNGMplM6t69u+7evauJEyfKy8vLuh+6lAP4J0WKFFFsbKyOHj1qvVAXGxsrJycnDR06VA4ODgoJCVG2bNk0ZcoUOTo6MobbDphIDf9a/MlcmjRpoiNHjig8PFweHh5q0aKFPvroI+XKlUvXr19Xo0aN5OrqqoCAAO7BDQB4bfTp00ezZ89W9erVdefOHfXs2VM1atRQ586ddeLECX344Yfq3LmznJ2dtWTJEu3fv18TJ060d9kAkhiz2axdu3apefPmKlWqlNavXy9Jio6OlouLyxPrxwVyvFxcQsW/Fhe427dvr99//13r16/XtWvXlCNHDs2YMUOTJ0/WhQsXlDVrVq1atUqXLl1KMFEMAADJxV/bLuLGTnbp0kV+fn4qX7680qZNqxEjRig4OFgzZsxQ0aJFtWTJEs2cOVPR0dFq3ry5NXDTFgLg33B0dLQOZfnll1/UqFEjSZKLi4tiY2OfWJ/AbR+Ebjyz+GO4Dx48qIsXL2rmzJkqWLCgJk2apIMHD6p69epavHixpk6dqvPnzytr1qw6cuSIBgwYYMfKAQCwjbhhUnGzjce1LGXIkEGPHj3S/fv39c033yhLliwaOXKkNXgXKVJE48eP144dOxLdHwA8K5PJpCpVqmjZsmXas2eP3n//fUkE7FcJ3cvxt+KPuY6JiZGzs7P1305OTtqyZYtq1KihFStWqFevXpozZ45q1qyp9957T8eOHVPNmjU1YsQIZc6c+Yn9AQCQXHz55ZeaNGmSatasqb59+ypz5szy9PTU/v371bhxY33//fdKlSqV+vTpozt37qhPnz6qVq2aFi5cqPbt29u7fADJhGEY2r59u6pVq6Z+/fpZ51aC/RG68Y+mTZumUqVKqWzZsqpZs6by5cunqVOn6tGjR3Jzc1Pz5s2VPXt2jRkzRpLUtm1bnTlzRu+++y4t3ACAZO3evXuqUqWKbty4oZiYGL399tt68OCBOnfuLF9fXw0bNkw+Pj7q0qWLjh07piFDhujEiRNatmyZ3nzzTUlclAbw4hiGoSNHjujNN99ksrRXCKEbT4j/5W+xWPTmm2/qwYMHypYtm0JDQ7Vv3z6lTZtW0uMu5/Xr11e2bNn01VdfyWQyqWHDhho0aJD1tmCcTAAAkrMzZ86of//+kqTSpUsrffr0GjJkiGrVqqXvv/9erq6uOnLkiNKmTavffvtN27dvt97JAwASE3/i4r/6N+fWT9sPXh5CNxKIfxAfOHBABQoUUJo0aZQ+fXo9fPhQK1eu1HvvvZdgm4EDB2r58uXKnDmzrly5osKFC2vTpk1P7A8AgOTq9OnT6t27t2JiYjR16lS5uLjop59+0uTJkxUREaG9e/cqTZo0Cb4T+Y4EkJj4QXnTpk26ePGi0qVLp0KFCll7yPzTdidPnlSRIkVeSr34Z4RuWMX/8h8+fLhWr16txo0bq3r16urfv79CQ0P14MEDzZkzRxUqVEhw1WzSpEm6efOmUqVKZb3az8kEAOB18scff+jTTz+V9Hicd5kyZWQYhsLCwpQmTRpanAD8K3379tXSpUtVsGBBPXr0SHfv3tUXX3yhDz744Il14593T58+Xd9++62WLl2q3Llzv+yykQhCN57Qp08fLVy4UJMnT1bx4sWVL18+63PlypXTzZs3tWDBAvn6+srR0VEWi0Vms9k60ZpEVxYAwOvpzJkz1uAdGBioypUrS+J7EcC/s3jxYvXp00dBQUEqX768Jk2apL59+2rRokXy9/dPsG78wP3NN9+oV69emjdv3hPrwX749EcCy5Yt08qVK7V+/Xr5+/tbA3fctZmff/5Z+fLlU6tWrfTDDz/owoUL8vHx0ZdffplgP5xYAABeR/nz59fkyZPl6OioUaNG6ccff5TE9yKAp7NYLJL+d8596tQpvffeeypfvrxWrVqlgQMHatKkSfL391dERITOnDljXT8ucM+cOVOfffaZvv32WwL3K4ZvACRw4sQJlSpVSj4+PpIeT5S2bt06dejQQZUqVVLv3r21detWFS1aVO3atVOlSpWUN29eDRkyxM6VAwDwasifP78mTpyoO3fu6NChQ/YuB8ArzjAM64W57du3KyIiQg8fPlSePHkUHBysVq1aaezYserUqZMsFovWrl2rTZs2KTIyMkGX8n79+mnu3Llq1KiRPd8OEsEd0yHpf1fVzp07p7CwMElSVFSU2rRpo8uXL8swDBUsWFBLlizRvXv3tG7dOq1fv14mk0l16tSRRNc5AADi5M+fX+vWrVOWLFnsXQqAV1j88+e+ffvq22+/1dGjR5UrVy51795dLi4umjlzplq1aiVJioiI0Pz581WqVCmlTJlSkrRu3Tr1799fs2bNUuPGje32XvD3GNONBPbt26cKFSqoaNGiunDhggoXLqyePXvK399fTk5OGjVqlL755hsdOXJEadKksW5H4AYAIHFMLArgn9y+fVvDhw/Xe++9pxo1akiSunTponnz5un7779Xzpw5ZTab9emnn+rOnTv6+eef5eT0uP1069atcnNz09tvv23Pt4CnoKUbCfj6+urIkSPatm2bUqVKpfbt28vBwcF6spAuXTrlyJFDf71WQ+AGACBxBG4AT7No0SK1bNlSBQsWVOvWra3LP//8c0VERKhBgwZKkSKFcuTIoRQpUmjfvn1ycnJSbGysnJyc5OfnZ7/i8Uxo6cYzu379umrXrq1q1app7Nix9i4HAAAASHL+2kP07Nmz+uyzz7R+/Xr98MMPqly5coIeMnv27FFkZKTSpEmj0qVLy8HBwRq4kTQQuvGPrl69qgsXLqhLly7KlSuX1q5dK4nucgAAAMDz2rZtm8qWLSt3d3edP39eHTp00KlTp7R3717lzJnzb4M1wzqTHkI3nio8PFzNmjXTjRs3VKJECc2cOVMSBzsAAADwvE6fPq3ChQurW7duGj58uFKlSqWLFy+qVatWOnfunHbv3q0cOXLIbDbL0dHR3uXiPyJ04x+dOnVKV69eVfXq1SURuAEAAID/asWKFfrwww/VtWtXDR061Bq8W7durQsXLmjbtm3KkyePvcvEC0Doxr9Cl3IAAADgv4k7p165cqWaNGmi7t27a8iQIXJ3d9fFixdVu3ZtFShQQKtWrbJ3qXgBCN0AAAAAYGMjR46UYRjq379/guUrVqxQkyZN1LdvX/Xt21dp0qRRSEiIMmXKRNfyZII+wgAAAABgQ48ePZKrq6s+//xzTZo0ybrcYrHI399fn3zyicaMGaP+/fvr4cOHypIlixwdHWU2m+1YNV4U5pkHAAAAgBdo27Zt8vb2VoECBTRgwABlz55dPXv2lJOTk3r06CGLxaIePXpY50ny9PRU9erVdezYMbm6ulr3Q0t38kDoBgAAAIAX5Nq1axo+fLgiIiJUtGhRLViwQEeOHJEkdevWTYZhqFevXrJYLGrWrJkyZcqkQ4cOKSAgQDVr1pTExMXJDWO6AQAAAOAF2rFjh1q0aKFbt24pKChI9erVU0xMjJydnSVJM2fOVJcuXVSoUCFFRUUpZcqUOnz4sJycnJi4OBkidAMAAADACxDXQv3rr7+qQ4cOcnJykrOzs2bOnKnChQvLbDbLZDLJwcFBO3fu1JEjR2Q2m9WtWzc5OTlxX+5kitANAAAAAP/BX1unIyMjZbFY9PPPP+urr75SWFiY5s6dq0KFClnXid/yLYnAnYwxUAAAAAAAnpPFYrEG7t9//12nT5/WjRs35O7ururVq6tr167y8PBQhw4ddOrUKUlSixYttGTJkgT7IXAnX7R0AwAAAMBziN/CPWjQIK1bt04hISEqWLCgmjRpoo8//liStH79es2YMUP79+9XgQIFdPnyZZ09ezZBSzeSL2YvBwAAAIDnEBe4Bw8erOnTp2vRokXKkiWLxowZo08++UQRERHq3bu36tatKy8vL+3Zs0c3b97U4MGDGcP9GiF0AwAAAMBz+uWXX7RlyxYFBQWpcuXK2rJli9atW6c6depo8ODBcnR0VEBAgEqVKqVSpUpZtyNwvz4Y0w0AAAAAzyl//vx677339NZbb2nbtm1q3bq1vvrqK82dO1elS5dWr169NGTIkCe2I3C/PhjTDQAAAADPIO6WYH/18OFDpUiRQu3atZOHh4fGjBkjZ2dnderUSceOHVO6dOm0YcMG7r/9mqJ7OQAAAAD8g/iBe/v27bp69arSp0+vokWLKkeOHIqIiNDhw4dVsWJFOTs7KyIiQqGhoerRo4c++OADSU/eWgyvB0I3AAAAADyFYRjWwN2nTx+tXr1aKVOmlKenp86ePavVq1erWLFi8vf314wZMxQdHa0TJ07o4cOHaty4sXUfBO7XE2O6AQAAACARO3bsUFRUlDUsz549W99++60WLlyoo0ePqkaNGjp//rz+/PNPSdIHH3yg9u3b688//1S+fPn0888/y9HRUWazmcD9GmNMNwAAAAD8RcmSJZUzZ06tXLlS0uPbgwUEBMjDw0NDhw7V2rVr9eGHH2r8+PHq0KGDIiIiFBsbqzRp0iSYmTw2NlZOTnQwfp3R0g0AAAAA8SxdulSPHj3SkiVL5ODgIJPJJJPJpLt37ypt2rTasGGDPvzwQ40dO1YdOnSQxWLRd999p0WLFunRo0fWwG0YBoEbhG4AAAAAiM/R0VF//vmnYmJi9Omnn6p27dqSpGzZsmn8+PFq3ry5xo4dq86dO0uS7t27p2XLlun+/ftyc3Oz7ocu5ZDoXg4AAAAACURHR6tJkyb66aef5ODgoMOHDytXrlyyWCyqVq2ajh8/rs2bN8vLy0vR0dHq3Lmz7ty5o71799KyjSfQ0g0AAADgtffZZ59p3759kiQXFxd5eXkpLCxMJpNJadKkkSQ5ODho+fLlyp07t95//3298cYbatq0qe7du6c9e/bIyclJZrPZnm8DryAuwwAAAAB4rd2/f19//vmnIiMjJUmhoaHKkiWLNmzYoMmTJ6tgwYI6ePCgcuTIocyZM2v//v3aunWrQkND5eXlpQoVKsjR0ZFJ05AoupcDAAAAeO316dNHP/30k3bv3i1XV1frDOSnTp1St27ddPToUWvwTkz8GcuB+OheDgAAAOC1ZbFYJEkdOnSQh4eHli1bJovFYg3QhQsX1pQpU/Tmm2/qrbfe0uXLlyU9vhVYfARu/B1CNwAAAIDXksVikYPD40iUN29e5c6dW7Nnz9b58+cTrFewYEFr8M6ZM6du3LhBN3I8M7qXAwAAAHitjRo1SsWLF1fFihXl4+OjIkWK6Ntvv1WmTJkSrHfixAnNmjVL48aNo2Ubz4yWbgAAAACvlbgu5ZI0f/58TZkyRR4eHnJ3d9fWrVt1+PBhNWvWTAcPHkzQjbxo0aKaMGGCHB0dmaUcz4yWbgAAAACvpV9++UXLly9X4cKF1aFDB+vs41euXFHt2rWVLl06Va5cWb1791bq1KntXS6SKFq6AQAAALx2jhw5osqVK2vq1Kl68OCBJMnJyUmxsbHKnj279u7dqxo1aujgwYMqUqSIBg0apMOHD9u5aiRFtHQDAAAASPYMw5DJZLL+X5IWLlyoHj16qHz58ho7dqwKFSokSdYW77h142Y09/Ly0jvvvGPHd4GkiNANAAAAIFmLP0t5eHi4TCaTUqVKJUmaO3euPv/8czVr1kxdu3ZVnjx5ntgG+C+Y5x4AAABAshU/PI8bN07BwcGKiIhQhgwZNH/+fLVt21aGYWjQoEEymUzq2rWrcufOTeDGC0PoBgAAAJBsxYXn/v37a86cORo6dKhy5MihFi1aqFatWtqyZYvatWsnSRo6dKju37+vIUOGyMvLy55lIxkhdAMAAABIduK3cJ89e1abNm3S4sWLVb16dW3cuFFms1mtWrWSh4eHJKldu3YKCwvTjh07lDVrVnuWjmSGPhMAAAAAko3mzZtrx44dcnBwsN6P+86dOwoNDVX16tX1/fffq0mTJhozZow6d+6sBw8e6JtvvpEkBQQEaPXq1TKZTAnu5Q38F4RuAAAAAMlCWFiY7t+/r7p162rfvn3Wlu7s2bMrT548GjBggJo2barx48erU6dOkqTz589r9erV2rdvn3U/hmEwphsvDH9JAAAAAJIFDw8PzZ8/Xw0aNFCNGjWsQdrV1VWpU6fW6NGj1aFDB3Xo0EGS9OjRIwUGBsrFxUVly5aVJJlMJustxYAXgVuGAQAAAEhWbt26pYCAAK1Zs0ZbtmxRhQoVdPLkSTVt2lRp06ZVyZIl5e3trfXr1+vOnTs6fPiwnJ2duU0YbILQDQAAACBJMwxDJpPJ+n9JunHjhnr16qXVq1dry5Ytqlixok6cOKF58+bpxx9/VLZs2ZQjRw5NmjRJTk5Oio2NlZMT80zjxSN0AwAAAEiy4rdOG4ahmJgYubi4SJJu3ryZoMW7YsWKMpvNMgwjQcAmcMOW+MsCAAAAkCTFD9xTpkzRjh07FB4eLj8/PwUEBChz5syaNGmSJKlWrVraunWrfH19E+zjrwEceNH46wIAAACQJMUF7sDAQC1YsEDNmjVTpkyZ1KtXL926dUuff/65MmbMqEmTJsnR0VEVKlTQb7/9Jh8fH+s+mDQNtkboBgAAAJBkBQUFKSgoSCtXrlS5cuW0detWOTg4aPTo0bp165a+/vprZcyYUWPHjlXevHlVqFAhe5eM1wyhGwAAAECSEX/StNjYWD18+FA9evRQuXLltHHjRrVo0UIzZ85UhgwZ1LhxY2XIkEEDBw6Up6enBg0aJIkx3Hi5mEgNAAAAQJIQfwx3eHi43N3ddfv2bT148EDu7u5677339MEHH+izzz7Tn3/+qfLly+v27dsaPny4AgMD7Vw9XlfchA4AAADAKy9+4B49erTatWun69evK2PGjMqdO7du3ryp8PBw1ahRQ5Lk5uam999/X7t27dJnn31mz9LxmqNPBQAAAIBXXlzg7tu3rxYuXKiBAwcqPDzc+ryrq6vOnDmjdevW6eHDhxo2bJhiYmJUvnx5mUwmupTDbuheDgAAACBJ2L59u1q2bKmFCxeqcuXK1uVxreCzZs1Sly5dlCdPHqVNm1a7d++Ws7OzdRw4YA9c6gEAAADwSjObzXJ0dNSlS5eUNm1avfXWW9bnDMOwtoJ36NBB1apVU2RkpIoUKSIHBwdauGF3jOkGAAAA8MrZtWuX5s6dK0lydHSUJDk7O+v+/fu6evWqdT3DMGQ2m7Vw4UJdunRJefLkkY+PjxwcHGSxWAjcsDtCNwAAAIBXyrfffqt27dpp69at+vnnn63L8+bNq+joaC1ZskS3bt2S9Hist9ls1pw5c7Rw4cIE+4lrAQfsiTHdAAAAAF4ZCxcuVJcuXTRt2jS99957ypAhQ4Lnx4wZo6FDh6pDhw6qVKmS0qZNq5EjR+rOnTvav38/Ldt45RC6AQAAALwSzp8/r/r16ysgIEBt2rRJ8NzZs2fl7e0tFxcXLVy4ULNmzdLBgwdVuHBhZcyYURs2bJCzs7N1/DfwquAyEAAAAIBXwq1bt3T//n1VqlTJumzRokXauHGjVq9eLU9PT/Xs2VPdunVT/fr1defOHTk6Osrb25vbguGVxSAHAAAAAK+ENGnSyNnZWUFBQXrw4IFat26tiRMnymKxaOnSpfLz89OwYcN07NgxeXh4KHfu3MqRI4dMJhOTpuGVRfdyAAAAAHYTd49tSYqKitKAAQP03XffKSIiQhkzZtSoUaNUvnx5eXp6yjAMpUuXTmPGjFHHjh3tXDnwbLgUBAAAAMBu4gL34sWLVbVqVfXr109t27bVpUuXVL169QSt13/88Yfy5s2rPHny2Ktc4F+jpRsAAACA3RiGoT/++ENvvPGG9u/fr+LFiye6Xnh4uFq0aKGIiAht2bKFydKQZDCmGwAAAMBLZbFYJD0O3JKUP39+FShQQFeuXHli3fv372vJkiV6//33deHCBW3atEmOjo4ym80vtWbgeRG6AQAAALxUcV3Kb9++LZPJJAcHB7m7u2vv3r3Wdcxms2JjYzV//nytWrVKWbNm1aFDh+Ts7KzY2FhaupFk0L0cAAAAwEs3ceJETZgwQUWKFFG6dOkUHh4uT09Pde/eXT4+PjIMQyaTSY8ePdLVq1eVJ08emUwm7sONJIfQDQAAAOCl+/7772U2m3XgwAH9+eef+u2333Tq1CkVK1ZMUVFRypo1q/LmzavWrVurQoUKkmQN4kBSQugGAAAAYFPxbwv2d2bPnq0BAwZoy5Yt+vnnn3X27FndvHlTc+fOpWUbSRqhGwAAAIDNxA/cv/zyiyIjI5UyZUqVLVtW0uN7c7u6uurkyZOqW7eu9u3bp8yZMyfYB13KkZRxn24AAAAANmEYhjVw9+/fX6tXr9a9e/eUO3duvfHGG5o5c6ZcXV0lSRkyZNCdO3e0d+9eNWjQwLq9yWQicCNJY/ZyAAAAADYRN/56xIgRmjNnjmbNmqUzZ86oQoUKmjVrlpo0aWJdN0OGDMqWLZvu3r37xPZAUkboBgAAAPBCxd2HW5JOnTqlH3/8Ud9++60qVqyo3bt3a8aMGerQoYN27typFi1aSJKcnJzUoUMHffTRR/YqG7AJupcDAAAAeGHWr1+vBw8eqFGjRnJzc1PhwoXVpEkTlSxZUnv27FH79u01btw4dezYUTExMZo/f75CQkK0bds29ejRQ5IUGxsrJyeiCpIH/pIBAAAAvBB79+5V/fr15e7uLkdHR9WrV08pUqRQhw4dJD2+N3fNmjXVsmVLSVK+fPlUt25dpUmTJsGEawRuJCd0LwcAAADwQvj4+Oitt96Sh4eH2rVrp++++04xMTHW50+dOqUzZ87Izc1NMTExOnz4sGrWrKkFCxbIwcEhQbd0ILngEhIAAACA/8xsNsvNzU2VK1e2tly3a9dOktSsWTO5uLjoww8/VO/evVW+fHmZzWZFRERo2bJlkhLOdA4kJ4RuAAAAAP+Zo6OjHB0dVb16dTVo0EAHDx6Ug4ODtWt5q1atVL16dY0ZM0ZbtmxR2rRpNWrUKDk5OXEfbiRrJsMwDHsXAQAAACDpWb16tUJDQ/Xmm2+qdOnS1uWffPKJ3N3dNWrUKPXu3Vtff/21Zs2apVatWj2xDyZNQ3LHXzcAAACAf23fvn1q3LixUqdOLW9vb1WuXFmtW7dW8eLFVb16dQ0aNEiDBg3SV199JQcHB3388ceKjIxUu3bt5OLiYt0PgRvJHYMmAAAAAPxrvr6+qlmzpsxms1q1aqWTJ09q6NChqlOnjgoUKKDIyEgNHz5ckjRmzBi1atVKy5cvTxC4gdcB3csBAAAA/Cvxu4RXrlxZYWFhGj16tDJmzKhZs2bp8OHDOnr0qKpWraoVK1YoZcqUkh5PlmYymaz/B14HhG4AAAAAzyR+WI7/7woVKuj69ev69ttvValSJZ04cUL79+9XiRIlVLx48b/dDngdELoBAAAA/COLxWK9pVdISIjc3NyUNm1a6/OVKlXS+fPntWTJElWqVImQDfw/xnQDAAAA+EdxgXvgwIGqX7++fHx8NH78eJ06dUqStGvXLuXJk0cfffSRdu7cKbPZLEkEbrz2CN0AAAAAEmUYhiwWi/Xx3LlzNXv2bHXo0EFNmjTRhAkTNGnSJB0+fFiStHPnTuXNm1d+fn767bff7FU28Ephfn4AAAAAiTKZTNaW6kOHDunEiRP6+uuv9f7770uSSpcurWHDhskwDHXq1EklS5bUjz/+qK5du6pYsWL2LB14ZRC6AQAAACTQrVs31alTR35+fjIMQz///LOqVq0qJycnFS1a1Lpes2bNZDKZNHToUDk4OKh169YqW7aspk6dKkkym81ydHS019sAXgl0LwcAAABgdeXKFcXGxqpq1aqSHrd2+/r6aty4cXJ0dNTOnTt18eJF6/pNmzbVoEGD9N1332nHjh0J9kXgBpi9HAAAAMBfxLVQL168WNHR0WrTpo0kadKkSRozZozatm2rjh07ytvb27rNDz/8oCpVqhC0gb+gezkAAAAASdLRo0eVPXt2ZciQQbdv39aUKVPk6uqqFClSqGnTpurevbtiY2M1YcIESVKnTp2UPXt2SVL16tUl0aUc+Cu6lwMAAADQmjVr5Ovrq0GDBunmzZvKmDGj5s6dK3d3d82ePVtLliyRJPXq1Us9e/bUggULNHbsWN28eTPBfgjcQEKEbgAAAOA1FxUVpfXr1+vRo0c6d+6cvvzyS12/fl2FCxfWV199JWdnZ82dO9cavHv27Km2bdvq4sWLypQpk52rB15tjOkGAAAAoF9++UW1a9eWr6+vHj58KB8fH/Xr109ZsmTR77//roCAAMXGxqpdu3Zq2rSppMf38TaZTNb/A3gSoRsAAAB4jVksFhmGIQcHB/Xu3VsZMmSQxWLRmjVrVKlSJfXt29cavHv37q0rV65o7NixqlGjhuKiBIEb+HtMpAYAAAC8hk6dOiUPDw9ly5bNuix79uxavHix9u7dq1SpUlm7k/fr10+FChXSqFGjNG/ePFWrVk0SYRt4FrR0AwAAAK+ZlStXqlmzZsqWLZtGjBih/Pnzq3Tp0pKkqlWrqmbNmurbt6+GDRumjRs3qnz58urVq5e8vLys+2CWcuDZ0NINAAAAvEaio6O1bds2Zc6cWY6Ojpo5c6ZSp06tdOnS6csvv1T16tV1/vx5SdLAgQPl4OCguXPnKmfOnOrWrZt1/DaBG3g2tHQDAAAAr5mQkBCNHDlSly5dUtasWdW2bVv16tVLGTNm1Llz53T06FEFBQWpcePGkqT58+fro48+ImgDz4FbhgEAAACvmSxZsqhv377Kli2bDh8+rMOHD2vHjh3q1auXatWqJW9vbxUqVMi6fuvWreXo6Ciz2WzHqoGkiZZuAAAA4DV1/fp1jRgxQvv27VOLFi0UEBAgSQoNDVX69OllsVjk4EA7HfBfELoBAACA11hISIiGDx+u/fv3q0GDBgoMDJTERGnAi0LoBgAAAF5zISEhGjFihA4dOqSqVatq2LBh9i4JSDboKwIAAAC85rJkyaL+/fsrb968unHjhmiXA14cWroBAAAASHo8ljtt2rRycHCw3hoMwH9D6AYAAACQABOoAS8OoRsAAAAAABvh8hUAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAACeyTvvvKMePXrYuwwAAJIUQjcAAMnEzZs31alTJ+XIkUOurq7KkiWLatasqX379tm7NAAAXltO9i4AAAC8GI0bN1ZMTIy+/fZb5cmTRzdu3NC2bdsUGhpq79IkSWazWSaTSQ4OXPMHALw++NYDACAZuHfvnnbv3q3Ro0erSpUqypkzp9566y0FBgaqdu3a1nU6duwoT09Pubm5ycfHRxs2bJAk3blzR82aNVP27NmVMmVKvfHGG1q6dOlTXzM6Olp9+vRRtmzZlCpVKpUtW1bbt2+3Pj9//nylTZtWGzZsUJEiReTq6qqLFy/a7GcAAMCriJZuAACSAXd3d7m7u2vNmjUqV66cXF1dEzxvsVhUq1YtPXjwQIsWLVLevHl18uRJOTo6SpIePXqkUqVKqW/fvvLw8ND333+vjz76SHny5FHZsmUTfc02bdrowoULWrZsmby8vLR69Wq9++67OnbsmPLnzy9JioyM1MiRIzV79mxlyJBBmTNntu0PAgCAV4zJMAzD3kUAAID/buXKlerQoYMePnyokiVLqnLlymratKmKFSumrVu3qlatWjp16pQKFCjwTPurXbu2ChcurK+++krS44nUihcvrokTJ+rs2bPKnz+/rly5Ii8vL+s21atX11tvvaURI0Zo/vz5atOmjX799Ve9+eabNnnPAAC86mjpBgAgmWjcuLFq166tXbt2ad++fdq8ebPGjBmj2bNn6+bNm8qePfvfBm6z2axRo0Zp+fLlunr1qqKiohQVFaVUqVIluv7hw4dlGMYT+4uKilKGDBmsj11cXFSsWLEX9yYBAEhi/q+d+3el9o/jOP7SvfhxNrNNiqJMMqDUSVmOMolMfqzKmRQWA0rHf2CxKZlQRmWRxaJIZ6GkDAYL0T3cfe/J/V2+XXdfejyma7iu69N7fPb59BHdAPCNNDY2plwup1wuZ2VlJTMzM1ldXU21Wv3X77a2tlKr1bK9vZ3u7u60tLRkYWEhr6+vn77/8fGRHz9+5OLi4vcR9X+USqXfz01NTWloaPjvgwHAFyW6AeAb6+rqysHBQXp6enJ3d5fr6+tPd7tPT09TqVQyNTWV5FdU39zcpLOz89P/9vb25v39PY+PjxkYGCh0BgD4ytxeDgDfwNPTU4aHh7O7u5vLy8vU6/Xs7e1lc3MzlUolQ0NDGRwczPj4eE5OTlKv13N0dJTj4+MkSXt7e05OTnJ2dparq6vMz8/n4eHhj+t1dHRkcnIy09PT2d/fT71ez/n5eTY2NnJ4ePi3xgaA/z073QDwDZRKpfT19aVWq+X29jZvb29pa2vL7OxslpaWkvy6aK1arWZiYiIvLy9pb2/P+vp6kmR5eTn1ej0jIyNpbm7O3NxcxsbG8vz8/Mc1d3Z2sra2lsXFxdzf36e1tTX9/f0ZHR39KzMDwFfg9nIAAAAoiOPlAAAAUBDRDQAAAAUR3QAAAFAQ0Q0AAAAFEd0AAABQENENAAAABRHdAAAAUBDRDQAAAAUR3QAAAFAQ0Q0AAAAFEd0AAABQENENAAAABfkJjV/3pKWPMxQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize results across different scalers\n",
    "\n",
    "# Sort for consistent plotting\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=results_df, x='scaler', y='recall')\n",
    "plt.title('Recall by Scaler Type')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Scaler')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46a848aa-ee31-4e58-86d1-b99ae2908e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>scaler</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.569353</td>\n",
       "      <td>0.826705</td>\n",
       "      <td>0.522779</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.561071</td>\n",
       "      <td>0.813920</td>\n",
       "      <td>0.501506</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.597876</td>\n",
       "      <td>0.826705</td>\n",
       "      <td>0.518035</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.673487</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.539157</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.545985</td>\n",
       "      <td>0.842330</td>\n",
       "      <td>0.480026</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.868891</td>\n",
       "      <td>0.553977</td>\n",
       "      <td>0.505666</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1.017823</td>\n",
       "      <td>0.538352</td>\n",
       "      <td>0.487782</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.893903</td>\n",
       "      <td>0.605114</td>\n",
       "      <td>0.505139</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.909962</td>\n",
       "      <td>0.494318</td>\n",
       "      <td>0.491999</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0.841369</td>\n",
       "      <td>0.561080</td>\n",
       "      <td>0.491152</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.512692</td>\n",
       "      <td>0.805398</td>\n",
       "      <td>0.557643</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>1.066101</td>\n",
       "      <td>0.627841</td>\n",
       "      <td>0.529499</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.886344</td>\n",
       "      <td>0.585227</td>\n",
       "      <td>0.540870</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.428769</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.596047</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.279772</td>\n",
       "      <td>0.930398</td>\n",
       "      <td>0.527636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.593417</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.482436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.351464</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.522572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.792087</td>\n",
       "      <td>0.098011</td>\n",
       "      <td>0.513592</td>\n",
       "      <td>0.057949</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.707819</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.457530</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>MinMaxScaler(feature_range=(-1, 1))</td>\n",
       "      <td>0.670857</td>\n",
       "      <td>0.941761</td>\n",
       "      <td>0.434695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steps                               scaler      loss  accuracy       auc  \\\n",
       "0       0                     StandardScaler()  0.569353  0.826705  0.522779   \n",
       "1       1                     StandardScaler()  0.561071  0.813920  0.501506   \n",
       "2       2                     StandardScaler()  0.597876  0.826705  0.518035   \n",
       "3       3                     StandardScaler()  0.673487  0.803977  0.539157   \n",
       "4       4                     StandardScaler()  0.545985  0.842330  0.480026   \n",
       "5       0                                 None  0.868891  0.553977  0.505666   \n",
       "6       1                                 None  1.017823  0.538352  0.487782   \n",
       "7       2                                 None  0.893903  0.605114  0.505139   \n",
       "8       3                                 None  0.909962  0.494318  0.491999   \n",
       "9       4                                 None  0.841369  0.561080  0.491152   \n",
       "10      0                       MinMaxScaler()  0.512692  0.805398  0.557643   \n",
       "11      1                       MinMaxScaler()  1.066101  0.627841  0.529499   \n",
       "12      2                       MinMaxScaler()  0.886344  0.585227  0.540870   \n",
       "13      3                       MinMaxScaler()  0.428769  0.823864  0.596047   \n",
       "14      4                       MinMaxScaler()  0.279772  0.930398  0.527636   \n",
       "15      0  MinMaxScaler(feature_range=(-1, 1))  0.593417  0.943182  0.482436   \n",
       "16      1  MinMaxScaler(feature_range=(-1, 1))  0.351464  0.943182  0.522572   \n",
       "17      2  MinMaxScaler(feature_range=(-1, 1))  0.792087  0.098011  0.513592   \n",
       "18      3  MinMaxScaler(feature_range=(-1, 1))  0.707819  0.056818  0.457530   \n",
       "19      4  MinMaxScaler(feature_range=(-1, 1))  0.670857  0.941761  0.434695   \n",
       "\n",
       "    precision  recall  \n",
       "0    0.063830   0.150  \n",
       "1    0.049505   0.125  \n",
       "2    0.063830   0.150  \n",
       "3    0.046296   0.125  \n",
       "4    0.082353   0.175  \n",
       "5    0.058065   0.450  \n",
       "6    0.056075   0.450  \n",
       "7    0.062500   0.425  \n",
       "8    0.053672   0.475  \n",
       "9    0.056106   0.425  \n",
       "10   0.085470   0.250  \n",
       "11   0.056000   0.350  \n",
       "12   0.074324   0.550  \n",
       "13   0.118182   0.325  \n",
       "14   0.000000   0.000  \n",
       "15   0.000000   0.000  \n",
       "16   0.000000   0.000  \n",
       "17   0.057949   0.975  \n",
       "18   0.056818   1.000  \n",
       "19   0.000000   0.000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcfad4-83e7-41ef-9e99-820a5ebc5aa4",
   "metadata": {},
   "source": [
    "## Sequence Tuning\n",
    "\n",
    "Here, we tune the parameters that control how sequences are constructed from the play-level data. This affects how much historical context the model sees, and how densely overlapping the training examples are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2694855-1d62-4ab8-9b53-32f2b997213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in experiments to create a df (first as a dict) of results\n",
    "# var : {string, value} is the independent variable,\n",
    "# where var[0] is a string label for the variable\n",
    "import os\n",
    "\n",
    "def evaluate_and_save(model, X_test, y_test, var, trial, results=None):\n",
    "    # Evaluate\n",
    "    loss, accuracy, auc, precision, recall = model.evaluate(X_test, y_test)\n",
    "\n",
    "    if results is None:\n",
    "        results = {\n",
    "            'steps':[],\n",
    "            var[0]:[],\n",
    "            'loss':[],\n",
    "            'accuracy':[],\n",
    "            'auc':[],\n",
    "            'precision':[],\n",
    "            'recall':[]\n",
    "        }\n",
    "\n",
    "    # Save results\n",
    "    results['steps'].append(trial)\n",
    "    results[var[0]].append(var[1])\n",
    "    results['loss'].append(loss)\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['auc'].append(auc)\n",
    "    results['precision'].append(precision)\n",
    "    results['recall'].append(recall)\n",
    "\n",
    "    # Set up results directory if it doesn't exist\n",
    "    os.makedirs(f'{var[0]}_experiment', exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(f'{var[0]}_experiment/{var[1]}_{var[0]}_trial_{trial}.keras')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d6ca56-81b7-42b7-b442-e886bdb290ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from 31 games\n",
      "Created 3643 sequences of length 1\n",
      "X shape: (3643, 1, 1968)\n",
      "y shape: (3643,)\n",
      "Epoch 1/25\n",
      "92/92 [==============================] - 7s 20ms/step - loss: 1.1866 - accuracy: 0.4914 - auc: 0.5225 - precision: 0.0728 - recall: 0.5369 - val_loss: 0.5809 - val_accuracy: 0.9122 - val_auc: 0.4768 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 1.0392 - accuracy: 0.4942 - auc: 0.5185 - precision: 0.0697 - recall: 0.5074 - val_loss: 0.5458 - val_accuracy: 0.8519 - val_auc: 0.4499 - val_precision: 0.0167 - val_recall: 0.0200 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.8212 - accuracy: 0.5436 - auc: 0.6081 - precision: 0.0914 - recall: 0.6207 - val_loss: 0.6575 - val_accuracy: 0.7449 - val_auc: 0.4728 - val_precision: 0.0584 - val_recall: 0.1800 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7755 - accuracy: 0.5577 - auc: 0.5968 - precision: 0.0855 - recall: 0.5517 - val_loss: 0.7116 - val_accuracy: 0.3484 - val_auc: 0.4786 - val_precision: 0.0654 - val_recall: 0.6400 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7044 - accuracy: 0.5151 - auc: 0.6275 - precision: 0.0867 - recall: 0.6256 - val_loss: 0.6741 - val_accuracy: 0.3951 - val_auc: 0.5042 - val_precision: 0.0722 - val_recall: 0.6600 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.7105 - accuracy: 0.5305 - auc: 0.6109 - precision: 0.0854 - recall: 0.5911 - val_loss: 1.3266 - val_accuracy: 0.2428 - val_auc: 0.5008 - val_precision: 0.0657 - val_recall: 0.7600 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6918 - accuracy: 0.5412 - auc: 0.6249 - precision: 0.0897 - recall: 0.6108 - val_loss: 0.8176 - val_accuracy: 0.7366 - val_auc: 0.4410 - val_precision: 0.0449 - val_recall: 0.1400 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6393 - accuracy: 0.5350 - auc: 0.6611 - precision: 0.0944 - recall: 0.6601 - val_loss: 0.8623 - val_accuracy: 0.3402 - val_auc: 0.4615 - val_precision: 0.0646 - val_recall: 0.6400 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6029 - accuracy: 0.5223 - auc: 0.7116 - precision: 0.1045 - recall: 0.7734 - val_loss: 0.8603 - val_accuracy: 0.3525 - val_auc: 0.4696 - val_precision: 0.0640 - val_recall: 0.6200 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5958 - accuracy: 0.4955 - auc: 0.6970 - precision: 0.0988 - recall: 0.7685 - val_loss: 0.8400 - val_accuracy: 0.3745 - val_auc: 0.4558 - val_precision: 0.0644 - val_recall: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6125 - accuracy: 0.5350 - auc: 0.6790 - precision: 0.0972 - recall: 0.6847 - val_loss: 0.8219 - val_accuracy: 0.3800 - val_auc: 0.4594 - val_precision: 0.0668 - val_recall: 0.6200 - lr: 2.0000e-04\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.9122 - auc: 0.4768 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1829 sequences of length 1\n",
      "X shape: (1829, 1, 1968)\n",
      "y shape: (1829,)\n",
      "Epoch 1/25\n",
      "46/46 [==============================] - 8s 33ms/step - loss: 1.1072 - accuracy: 0.5243 - auc: 0.5426 - precision: 0.0843 - recall: 0.5175 - val_loss: 0.6577 - val_accuracy: 0.7322 - val_auc: 0.5787 - val_precision: 0.1134 - val_recall: 0.4783 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1060 - accuracy: 0.5229 - auc: 0.5440 - precision: 0.0852 - recall: 0.5263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 16ms/step - loss: 1.1060 - accuracy: 0.5229 - auc: 0.5440 - precision: 0.0852 - recall: 0.5263 - val_loss: 0.4176 - val_accuracy: 0.9372 - val_auc: 0.4994 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.9417 - accuracy: 0.5475 - auc: 0.6202 - precision: 0.1097 - recall: 0.6754 - val_loss: 0.5850 - val_accuracy: 0.9344 - val_auc: 0.4679 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8045 - accuracy: 0.5509 - auc: 0.6285 - precision: 0.1001 - recall: 0.5965 - val_loss: 0.6561 - val_accuracy: 0.5383 - val_auc: 0.5072 - val_precision: 0.0602 - val_recall: 0.4348 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6882 - accuracy: 0.5673 - auc: 0.6799 - precision: 0.1189 - recall: 0.7105 - val_loss: 0.7748 - val_accuracy: 0.4126 - val_auc: 0.4621 - val_precision: 0.0596 - val_recall: 0.5652 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6345 - accuracy: 0.5666 - auc: 0.7197 - precision: 0.1199 - recall: 0.7193 - val_loss: 0.4250 - val_accuracy: 0.9344 - val_auc: 0.4649 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.6070 - auc: 0.7139 - precision: 0.1177 - recall: 0.6228 - val_loss: 0.5563 - val_accuracy: 0.8579 - val_auc: 0.4108 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5478 - accuracy: 0.5721 - auc: 0.7778 - precision: 0.1343 - recall: 0.8246 - val_loss: 0.5890 - val_accuracy: 0.8115 - val_auc: 0.3974 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5588 - accuracy: 0.5762 - auc: 0.7740 - precision: 0.1375 - recall: 0.8421 - val_loss: 0.6331 - val_accuracy: 0.4399 - val_auc: 0.3773 - val_precision: 0.0450 - val_recall: 0.3913 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5093 - accuracy: 0.6206 - auc: 0.8204 - precision: 0.1483 - recall: 0.8158 - val_loss: 0.6669 - val_accuracy: 0.4481 - val_auc: 0.3925 - val_precision: 0.0503 - val_recall: 0.4348 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.6124 - auc: 0.7979 - precision: 0.1455 - recall: 0.8158 - val_loss: 0.6214 - val_accuracy: 0.4645 - val_auc: 0.3840 - val_precision: 0.0471 - val_recall: 0.3913 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4789 - accuracy: 0.6473 - auc: 0.8355 - precision: 0.1616 - recall: 0.8421 - val_loss: 0.6475 - val_accuracy: 0.4590 - val_auc: 0.3867 - val_precision: 0.0466 - val_recall: 0.3913 - lr: 2.0000e-04\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.9372 - auc: 0.4994 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1223 sequences of length 1\n",
      "X shape: (1223, 1, 1968)\n",
      "y shape: (1223,)\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 7s 45ms/step - loss: 1.3021 - accuracy: 0.4796 - auc: 0.4918 - precision: 0.0568 - recall: 0.5179 - val_loss: 0.7874 - val_accuracy: 0.0776 - val_auc: 0.4278 - val_precision: 0.0776 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1485 - accuracy: 0.4703 - auc: 0.5781 - precision: 0.0674 - recall: 0.6429 - val_loss: 0.7487 - val_accuracy: 0.1020 - val_auc: 0.4859 - val_precision: 0.0795 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9188 - accuracy: 0.4796 - auc: 0.6512 - precision: 0.0750 - recall: 0.7143 - val_loss: 0.4401 - val_accuracy: 0.9224 - val_auc: 0.5119 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8728 - accuracy: 0.5593 - auc: 0.6609 - precision: 0.0843 - recall: 0.6786 - val_loss: 0.4642 - val_accuracy: 0.9224 - val_auc: 0.6132 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.5562 - auc: 0.7186 - precision: 0.0927 - recall: 0.7679 - val_loss: 0.5415 - val_accuracy: 0.9143 - val_auc: 0.5721 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5851 - accuracy: 0.6043 - auc: 0.7937 - precision: 0.1087 - recall: 0.8214 - val_loss: 0.7252 - val_accuracy: 0.5061 - val_auc: 0.6134 - val_precision: 0.1077 - val_recall: 0.7368 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5511 - accuracy: 0.6135 - auc: 0.8071 - precision: 0.1073 - recall: 0.7857 - val_loss: 0.6331 - val_accuracy: 0.5429 - val_auc: 0.6161 - val_precision: 0.1026 - val_recall: 0.6316 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5669 - accuracy: 0.6299 - auc: 0.7931 - precision: 0.1016 - recall: 0.6964 - val_loss: 0.9163 - val_accuracy: 0.2735 - val_auc: 0.5766 - val_precision: 0.0794 - val_recall: 0.7895 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4753 - accuracy: 0.6329 - auc: 0.8356 - precision: 0.1241 - recall: 0.8929 - val_loss: 0.8288 - val_accuracy: 0.3633 - val_auc: 0.5658 - val_precision: 0.0798 - val_recall: 0.6842 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.6769 - auc: 0.8770 - precision: 0.1409 - recall: 0.9107 - val_loss: 0.8585 - val_accuracy: 0.3837 - val_auc: 0.5738 - val_precision: 0.0875 - val_recall: 0.7368 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.6881 - auc: 0.8821 - precision: 0.1433 - recall: 0.8929 - val_loss: 0.7281 - val_accuracy: 0.5061 - val_auc: 0.5771 - val_precision: 0.1016 - val_recall: 0.6842 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.6605 - auc: 0.8811 - precision: 0.1310 - recall: 0.8750 - val_loss: 0.7728 - val_accuracy: 0.5102 - val_auc: 0.5798 - val_precision: 0.1024 - val_recall: 0.6842 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.3834 - accuracy: 0.7065 - auc: 0.9066 - precision: 0.1532 - recall: 0.9107 - val_loss: 0.6740 - val_accuracy: 0.5469 - val_auc: 0.5821 - val_precision: 0.1102 - val_recall: 0.6842 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.9224 - auc: 0.5119 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 923 sequences of length 1\n",
      "X shape: (923, 1, 1968)\n",
      "y shape: (923,)\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 7s 58ms/step - loss: 1.3463 - accuracy: 0.4932 - auc: 0.4601 - precision: 0.0595 - recall: 0.4583 - val_loss: 0.7507 - val_accuracy: 0.4000 - val_auc: 0.5307 - val_precision: 0.0354 - val_recall: 0.6667 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9991 - accuracy: 0.5163 - auc: 0.6443 - precision: 0.0945 - recall: 0.7500 - val_loss: 1.0050 - val_accuracy: 0.0324 - val_auc: 0.4548 - val_precision: 0.0324 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9308 - accuracy: 0.5257 - auc: 0.6101 - precision: 0.0874 - recall: 0.6667 - val_loss: 1.0054 - val_accuracy: 0.0324 - val_auc: 0.3994 - val_precision: 0.0324 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6691 - accuracy: 0.5257 - auc: 0.7428 - precision: 0.0963 - recall: 0.7500 - val_loss: 0.8365 - val_accuracy: 0.0378 - val_auc: 0.4306 - val_precision: 0.0326 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7004 - accuracy: 0.5962 - auc: 0.7372 - precision: 0.1044 - recall: 0.6875 - val_loss: 0.8718 - val_accuracy: 0.0432 - val_auc: 0.5340 - val_precision: 0.0276 - val_recall: 0.8333 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7208 - accuracy: 0.5786 - auc: 0.7598 - precision: 0.1144 - recall: 0.8125 - val_loss: 0.8658 - val_accuracy: 0.1135 - val_auc: 0.4749 - val_precision: 0.0298 - val_recall: 0.8333 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5470 - accuracy: 0.5705 - auc: 0.8329 - precision: 0.1146 - recall: 0.8333 - val_loss: 0.8101 - val_accuracy: 0.2162 - val_auc: 0.5023 - val_precision: 0.0272 - val_recall: 0.6667 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4708 - accuracy: 0.6084 - auc: 0.8805 - precision: 0.1403 - recall: 0.9792 - val_loss: 0.7506 - val_accuracy: 0.3243 - val_auc: 0.4972 - val_precision: 0.0315 - val_recall: 0.6667 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4372 - accuracy: 0.6355 - auc: 0.8869 - precision: 0.1377 - recall: 0.8750 - val_loss: 0.6958 - val_accuracy: 0.4324 - val_auc: 0.4944 - val_precision: 0.0286 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4365 - accuracy: 0.6558 - auc: 0.8793 - precision: 0.1473 - recall: 0.8958 - val_loss: 0.6682 - val_accuracy: 0.4865 - val_auc: 0.4939 - val_precision: 0.0316 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.6409 - auc: 0.8864 - precision: 0.1466 - recall: 0.9375 - val_loss: 0.6612 - val_accuracy: 0.5297 - val_auc: 0.4493 - val_precision: 0.0345 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.6314 - auc: 0.8691 - precision: 0.1364 - recall: 0.8750 - val_loss: 0.5681 - val_accuracy: 0.5838 - val_auc: 0.4399 - val_precision: 0.0390 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4516 - accuracy: 0.6707 - auc: 0.8553 - precision: 0.1402 - recall: 0.7917 - val_loss: 0.5278 - val_accuracy: 0.5946 - val_auc: 0.4413 - val_precision: 0.0274 - val_recall: 0.3333 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4138 - accuracy: 0.6667 - auc: 0.9049 - precision: 0.1586 - recall: 0.9583 - val_loss: 0.4793 - val_accuracy: 0.6054 - val_auc: 0.4493 - val_precision: 0.0282 - val_recall: 0.3333 - lr: 2.0000e-04\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4128 - accuracy: 0.6612 - auc: 0.8885 - precision: 0.1469 - recall: 0.8750 - val_loss: 0.4577 - val_accuracy: 0.9297 - val_auc: 0.4199 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.6802 - auc: 0.8673 - precision: 0.1493 - recall: 0.8333 - val_loss: 0.5353 - val_accuracy: 0.5946 - val_auc: 0.4036 - val_precision: 0.0400 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4302 - accuracy: 0.6707 - auc: 0.8755 - precision: 0.1455 - recall: 0.8333 - val_loss: 0.5069 - val_accuracy: 0.5946 - val_auc: 0.3971 - val_precision: 0.0274 - val_recall: 0.3333 - lr: 2.0000e-04\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.6924 - auc: 0.8856 - precision: 0.1648 - recall: 0.9167 - val_loss: 0.4693 - val_accuracy: 0.9297 - val_auc: 0.4427 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4621 - accuracy: 0.6707 - auc: 0.8435 - precision: 0.1375 - recall: 0.7708 - val_loss: 0.5245 - val_accuracy: 0.5730 - val_auc: 0.4297 - val_precision: 0.0380 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4144 - accuracy: 0.6856 - auc: 0.8802 - precision: 0.1515 - recall: 0.8333 - val_loss: 0.5594 - val_accuracy: 0.5622 - val_auc: 0.4455 - val_precision: 0.0370 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4018 - accuracy: 0.7182 - auc: 0.8920 - precision: 0.1694 - recall: 0.8542 - val_loss: 0.5425 - val_accuracy: 0.5676 - val_auc: 0.4469 - val_precision: 0.0375 - val_recall: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.6829 - auc: 0.8735 - precision: 0.1530 - recall: 0.8542 - val_loss: 0.5757 - val_accuracy: 0.5676 - val_auc: 0.4539 - val_precision: 0.0375 - val_recall: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4261 - accuracy: 0.6870 - auc: 0.8604 - precision: 0.1383 - recall: 0.7292 - val_loss: 0.6042 - val_accuracy: 0.5568 - val_auc: 0.3948 - val_precision: 0.0366 - val_recall: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3999 - accuracy: 0.6626 - auc: 0.8902 - precision: 0.1546 - recall: 0.9375 - val_loss: 0.6246 - val_accuracy: 0.5568 - val_auc: 0.3948 - val_precision: 0.0366 - val_recall: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.7114 - auc: 0.8987 - precision: 0.1687 - recall: 0.8750 - val_loss: 0.5668 - val_accuracy: 0.5622 - val_auc: 0.3878 - val_precision: 0.0370 - val_recall: 0.5000 - lr: 1.0000e-04\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.9297 - auc: 0.4199 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3581 sequences of length 3\n",
      "X shape: (3581, 3, 1968)\n",
      "y shape: (3581,)\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 7s 21ms/step - loss: 1.2624 - accuracy: 0.4934 - auc: 0.4829 - precision: 0.0648 - recall: 0.4627 - val_loss: 0.7726 - val_accuracy: 0.1785 - val_auc: 0.4975 - val_precision: 0.0742 - val_recall: 0.9400 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.9226 - accuracy: 0.5126 - auc: 0.5744 - precision: 0.0848 - recall: 0.6070 - val_loss: 1.0497 - val_accuracy: 0.0767 - val_auc: 0.5281 - val_precision: 0.0702 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.8365 - accuracy: 0.5391 - auc: 0.5859 - precision: 0.0828 - recall: 0.5522 - val_loss: 0.5405 - val_accuracy: 0.8326 - val_auc: 0.5053 - val_precision: 0.1023 - val_recall: 0.1800 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7302 - accuracy: 0.5468 - auc: 0.6383 - precision: 0.0952 - recall: 0.6418 - val_loss: 0.6497 - val_accuracy: 0.5746 - val_auc: 0.5420 - val_precision: 0.0820 - val_recall: 0.5000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6688 - accuracy: 0.5925 - auc: 0.6743 - precision: 0.1041 - recall: 0.6318 - val_loss: 0.6251 - val_accuracy: 0.6904 - val_auc: 0.5203 - val_precision: 0.0784 - val_recall: 0.3200 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6534 - accuracy: 0.5981 - auc: 0.6888 - precision: 0.1074 - recall: 0.6468 - val_loss: 0.5867 - val_accuracy: 0.7727 - val_auc: 0.5810 - val_precision: 0.1049 - val_recall: 0.3000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.6062 - accuracy: 0.5901 - auc: 0.7328 - precision: 0.1099 - recall: 0.6816 - val_loss: 0.7350 - val_accuracy: 0.5927 - val_auc: 0.5432 - val_precision: 0.0828 - val_recall: 0.4800 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5767 - accuracy: 0.6376 - auc: 0.7647 - precision: 0.1300 - recall: 0.7313 - val_loss: 0.6869 - val_accuracy: 0.5830 - val_auc: 0.5397 - val_precision: 0.0836 - val_recall: 0.5000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5292 - accuracy: 0.6453 - auc: 0.8054 - precision: 0.1416 - recall: 0.8010 - val_loss: 0.7681 - val_accuracy: 0.5495 - val_auc: 0.5437 - val_precision: 0.0851 - val_recall: 0.5600 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5240 - accuracy: 0.6480 - auc: 0.8015 - precision: 0.1362 - recall: 0.7512 - val_loss: 0.7298 - val_accuracy: 0.5551 - val_auc: 0.5459 - val_precision: 0.0887 - val_recall: 0.5800 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5019 - accuracy: 0.6809 - auc: 0.8239 - precision: 0.1522 - recall: 0.7761 - val_loss: 0.7177 - val_accuracy: 0.5662 - val_auc: 0.5594 - val_precision: 0.0909 - val_recall: 0.5800 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4711 - accuracy: 0.6920 - auc: 0.8593 - precision: 0.1678 - recall: 0.8557 - val_loss: 0.7122 - val_accuracy: 0.5607 - val_auc: 0.5487 - val_precision: 0.0898 - val_recall: 0.5800 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4948 - accuracy: 0.6795 - auc: 0.8257 - precision: 0.1536 - recall: 0.7910 - val_loss: 0.7776 - val_accuracy: 0.5258 - val_auc: 0.5263 - val_precision: 0.0760 - val_recall: 0.5200 - lr: 2.0000e-04\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8326 - auc: 0.5053 - precision: 0.1023 - recall: 0.1800   \n",
      "Sampling from 31 games\n",
      "Created 1798 sequences of length 3\n",
      "X shape: (1798, 3, 1968)\n",
      "y shape: (1798,)\n",
      "Epoch 1/25\n",
      "45/45 [==============================] - 7s 33ms/step - loss: 1.2471 - accuracy: 0.4958 - auc: 0.5063 - precision: 0.0770 - recall: 0.5091 - val_loss: 0.5381 - val_accuracy: 0.9194 - val_auc: 0.4866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 1.1860 - accuracy: 0.5035 - auc: 0.5274 - precision: 0.0770 - recall: 0.5000 - val_loss: 0.8144 - val_accuracy: 0.0750 - val_auc: 0.5046 - val_precision: 0.0698 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.9511 - accuracy: 0.5271 - auc: 0.6012 - precision: 0.0917 - recall: 0.5818 - val_loss: 0.5543 - val_accuracy: 0.9222 - val_auc: 0.6296 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7068 - accuracy: 0.5807 - auc: 0.6967 - precision: 0.1154 - recall: 0.6727 - val_loss: 0.6152 - val_accuracy: 0.8528 - val_auc: 0.5515 - val_precision: 0.0882 - val_recall: 0.1200 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.6654 - accuracy: 0.6134 - auc: 0.7242 - precision: 0.1296 - recall: 0.7091 - val_loss: 0.6901 - val_accuracy: 0.4778 - val_auc: 0.4896 - val_precision: 0.0595 - val_recall: 0.4400 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.6051 - accuracy: 0.6120 - auc: 0.7815 - precision: 0.1399 - recall: 0.7909 - val_loss: 0.4699 - val_accuracy: 0.8722 - val_auc: 0.4945 - val_precision: 0.0435 - val_recall: 0.0400 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "43/45 [===========================>..] - ETA: 0s - loss: 0.6146 - accuracy: 0.6650 - auc: 0.7481 - precision: 0.1493 - recall: 0.7308       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6118 - accuracy: 0.6648 - auc: 0.7520 - precision: 0.1517 - recall: 0.7364 - val_loss: 0.3249 - val_accuracy: 0.9250 - val_auc: 0.5419 - val_precision: 0.3333 - val_recall: 0.0800 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5438 - accuracy: 0.6572 - auc: 0.8188 - precision: 0.1574 - recall: 0.8000 - val_loss: 0.7349 - val_accuracy: 0.4528 - val_auc: 0.4467 - val_precision: 0.0657 - val_recall: 0.5200 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5255 - accuracy: 0.6871 - auc: 0.8173 - precision: 0.1614 - recall: 0.7364 - val_loss: 0.7024 - val_accuracy: 0.5000 - val_auc: 0.4900 - val_precision: 0.0670 - val_recall: 0.4800 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5112 - accuracy: 0.6989 - auc: 0.8290 - precision: 0.1776 - recall: 0.8091 - val_loss: 0.6184 - val_accuracy: 0.6583 - val_auc: 0.5216 - val_precision: 0.0463 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4894 - accuracy: 0.6947 - auc: 0.8379 - precision: 0.1755 - recall: 0.8091 - val_loss: 0.5850 - val_accuracy: 0.7472 - val_auc: 0.5283 - val_precision: 0.0875 - val_recall: 0.2800 - lr: 0.0010\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.9194 - auc: 0.4866 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1204 sequences of length 3\n",
      "X shape: (1204, 3, 1968)\n",
      "y shape: (1204,)\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 7s 46ms/step - loss: 1.2698 - accuracy: 0.4901 - auc: 0.4880 - precision: 0.0802 - recall: 0.5556 - val_loss: 0.7799 - val_accuracy: 0.1245 - val_auc: 0.5506 - val_precision: 0.0826 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.1876 - accuracy: 0.5109 - auc: 0.5469 - precision: 0.0835 - recall: 0.5556 - val_loss: 0.7285 - val_accuracy: 0.2241 - val_auc: 0.4727 - val_precision: 0.0800 - val_recall: 0.8421 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8340 - accuracy: 0.5327 - auc: 0.6900 - precision: 0.1095 - recall: 0.7361 - val_loss: 0.6639 - val_accuracy: 0.7220 - val_auc: 0.4765 - val_precision: 0.0556 - val_recall: 0.1579 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7900 - accuracy: 0.5784 - auc: 0.6953 - precision: 0.1134 - recall: 0.6806 - val_loss: 0.5979 - val_accuracy: 0.9212 - val_auc: 0.5867 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6445 - accuracy: 0.6127 - auc: 0.7512 - precision: 0.1302 - recall: 0.7361 - val_loss: 1.2340 - val_accuracy: 0.0788 - val_auc: 0.3990 - val_precision: 0.0788 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6238 - accuracy: 0.6314 - auc: 0.7818 - precision: 0.1436 - recall: 0.7917 - val_loss: 0.8398 - val_accuracy: 0.1369 - val_auc: 0.4526 - val_precision: 0.0762 - val_recall: 0.8947 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6159 - accuracy: 0.6511 - auc: 0.7681 - precision: 0.1333 - recall: 0.6667 - val_loss: 0.9461 - val_accuracy: 0.1203 - val_auc: 0.4910 - val_precision: 0.0749 - val_recall: 0.8947 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 0.6449 - auc: 0.8221 - precision: 0.1521 - recall: 0.8194 - val_loss: 0.6155 - val_accuracy: 0.6929 - val_auc: 0.5354 - val_precision: 0.1127 - val_recall: 0.4211 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5697 - accuracy: 0.7009 - auc: 0.8046 - precision: 0.1687 - recall: 0.7639 - val_loss: 0.7821 - val_accuracy: 0.3859 - val_auc: 0.4817 - val_precision: 0.0784 - val_recall: 0.6316 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4893 - accuracy: 0.6989 - auc: 0.8382 - precision: 0.1677 - recall: 0.7639 - val_loss: 0.7872 - val_accuracy: 0.4357 - val_auc: 0.4873 - val_precision: 0.0851 - val_recall: 0.6316 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4391 - accuracy: 0.6885 - auc: 0.8845 - precision: 0.1798 - recall: 0.8889 - val_loss: 0.7099 - val_accuracy: 0.5353 - val_auc: 0.5034 - val_precision: 0.0885 - val_recall: 0.5263 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4811 - accuracy: 0.7134 - auc: 0.8424 - precision: 0.1813 - recall: 0.8056 - val_loss: 0.7105 - val_accuracy: 0.5062 - val_auc: 0.5122 - val_precision: 0.0833 - val_recall: 0.5263 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.7269 - auc: 0.8999 - precision: 0.1987 - recall: 0.8750 - val_loss: 0.7673 - val_accuracy: 0.4813 - val_auc: 0.5188 - val_precision: 0.0923 - val_recall: 0.6316 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4025 - accuracy: 0.7373 - auc: 0.8980 - precision: 0.2090 - recall: 0.9028 - val_loss: 0.6278 - val_accuracy: 0.6100 - val_auc: 0.4758 - val_precision: 0.0879 - val_recall: 0.4211 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.9212 - auc: 0.5867 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 906 sequences of length 3\n",
      "X shape: (906, 3, 1968)\n",
      "y shape: (906,)\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 6s 61ms/step - loss: 1.2201 - accuracy: 0.4641 - auc: 0.4424 - precision: 0.0862 - recall: 0.4648 - val_loss: 0.7818 - val_accuracy: 0.0989 - val_auc: 0.5694 - val_precision: 0.0682 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0625 - accuracy: 0.5124 - auc: 0.5752 - precision: 0.1105 - recall: 0.5634 - val_loss: 0.5377 - val_accuracy: 0.9231 - val_auc: 0.5520 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9353 - accuracy: 0.5401 - auc: 0.6763 - precision: 0.1421 - recall: 0.7324 - val_loss: 0.4885 - val_accuracy: 0.9341 - val_auc: 0.4801 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9064 - accuracy: 0.5691 - auc: 0.6809 - precision: 0.1360 - recall: 0.6338 - val_loss: 0.8836 - val_accuracy: 0.0714 - val_auc: 0.7108 - val_precision: 0.0663 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7125 - accuracy: 0.6077 - auc: 0.7400 - precision: 0.1682 - recall: 0.7606 - val_loss: 0.7932 - val_accuracy: 0.1209 - val_auc: 0.4475 - val_precision: 0.0647 - val_recall: 0.9167 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5794 - accuracy: 0.6492 - auc: 0.8018 - precision: 0.1856 - recall: 0.7606 - val_loss: 0.5660 - val_accuracy: 0.9011 - val_auc: 0.5642 - val_precision: 0.1250 - val_recall: 0.0833 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.6699 - auc: 0.8072 - precision: 0.1957 - recall: 0.7606 - val_loss: 0.3710 - val_accuracy: 0.9341 - val_auc: 0.5669 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5558 - accuracy: 0.6961 - auc: 0.8299 - precision: 0.2189 - recall: 0.8169 - val_loss: 0.6768 - val_accuracy: 0.5659 - val_auc: 0.5806 - val_precision: 0.0864 - val_recall: 0.5833 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4440 - accuracy: 0.7182 - auc: 0.8762 - precision: 0.2308 - recall: 0.8028 - val_loss: 0.7383 - val_accuracy: 0.3956 - val_auc: 0.6238 - val_precision: 0.0847 - val_recall: 0.8333 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4326 - accuracy: 0.7459 - auc: 0.8781 - precision: 0.2533 - recall: 0.8169 - val_loss: 0.5566 - val_accuracy: 0.7692 - val_auc: 0.6556 - val_precision: 0.1053 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4109 - accuracy: 0.7334 - auc: 0.8984 - precision: 0.2458 - recall: 0.8310 - val_loss: 0.8369 - val_accuracy: 0.2692 - val_auc: 0.6309 - val_precision: 0.0769 - val_recall: 0.9167 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.8052 - auc: 0.9275 - precision: 0.3196 - recall: 0.8732 - val_loss: 0.7530 - val_accuracy: 0.4231 - val_auc: 0.6272 - val_precision: 0.0811 - val_recall: 0.7500 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.9231 - auc: 0.5520 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3519 sequences of length 5\n",
      "X shape: (3519, 5, 1968)\n",
      "y shape: (3519,)\n",
      "Epoch 1/25\n",
      "88/88 [==============================] - 7s 21ms/step - loss: 1.2965 - accuracy: 0.4842 - auc: 0.5010 - precision: 0.0721 - recall: 0.5122 - val_loss: 0.5525 - val_accuracy: 0.9219 - val_auc: 0.4454 - val_precision: 0.0588 - val_recall: 0.0250 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.0356 - accuracy: 0.5172 - auc: 0.5364 - precision: 0.0788 - recall: 0.5268 - val_loss: 0.3901 - val_accuracy: 0.9347 - val_auc: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.8217 - accuracy: 0.5300 - auc: 0.5897 - precision: 0.0890 - recall: 0.5902 - val_loss: 1.3702 - val_accuracy: 0.0582 - val_auc: 0.4898 - val_precision: 0.0569 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7226 - accuracy: 0.5794 - auc: 0.6634 - precision: 0.1112 - recall: 0.6829 - val_loss: 0.4627 - val_accuracy: 0.8778 - val_auc: 0.5086 - val_precision: 0.1167 - val_recall: 0.1750 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.7154 - accuracy: 0.5936 - auc: 0.6604 - precision: 0.1110 - recall: 0.6537 - val_loss: 0.8916 - val_accuracy: 0.3636 - val_auc: 0.4726 - val_precision: 0.0526 - val_recall: 0.6000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5990 - accuracy: 0.6092 - auc: 0.7453 - precision: 0.1261 - recall: 0.7366 - val_loss: 0.5635 - val_accuracy: 0.7898 - val_auc: 0.4784 - val_precision: 0.0714 - val_recall: 0.2250 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5876 - accuracy: 0.6323 - auc: 0.7547 - precision: 0.1327 - recall: 0.7317 - val_loss: 0.5841 - val_accuracy: 0.7713 - val_auc: 0.4499 - val_precision: 0.0451 - val_recall: 0.1500 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5345 - accuracy: 0.6469 - auc: 0.8065 - precision: 0.1443 - recall: 0.7805 - val_loss: 0.6594 - val_accuracy: 0.6974 - val_auc: 0.4608 - val_precision: 0.0423 - val_recall: 0.2000 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4977 - accuracy: 0.6433 - auc: 0.8323 - precision: 0.1486 - recall: 0.8244 - val_loss: 0.6423 - val_accuracy: 0.7259 - val_auc: 0.4686 - val_precision: 0.0419 - val_recall: 0.1750 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4718 - accuracy: 0.6963 - auc: 0.8551 - precision: 0.1724 - recall: 0.8341 - val_loss: 0.6986 - val_accuracy: 0.6236 - val_auc: 0.4710 - val_precision: 0.0588 - val_recall: 0.3750 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4656 - accuracy: 0.6909 - auc: 0.8593 - precision: 0.1750 - recall: 0.8732 - val_loss: 0.7113 - val_accuracy: 0.6136 - val_auc: 0.4787 - val_precision: 0.0639 - val_recall: 0.4250 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.4763 - accuracy: 0.6828 - auc: 0.8501 - precision: 0.1660 - recall: 0.8341 - val_loss: 0.7872 - val_accuracy: 0.5710 - val_auc: 0.4828 - val_precision: 0.0544 - val_recall: 0.4000 - lr: 2.0000e-04\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.9347 - auc: 0.5312 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1767 sequences of length 5\n",
      "X shape: (1767, 5, 1968)\n",
      "y shape: (1767,)\n",
      "Epoch 1/25\n",
      "45/45 [==============================] - 7s 34ms/step - loss: 1.2969 - accuracy: 0.4933 - auc: 0.4884 - precision: 0.0806 - recall: 0.5179 - val_loss: 0.7061 - val_accuracy: 0.4096 - val_auc: 0.5587 - val_precision: 0.0724 - val_recall: 0.8000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 1.1260 - accuracy: 0.5088 - auc: 0.5485 - precision: 0.0878 - recall: 0.5536 - val_loss: 1.0376 - val_accuracy: 0.0565 - val_auc: 0.5450 - val_precision: 0.0565 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.8795 - accuracy: 0.5548 - auc: 0.6149 - precision: 0.1077 - recall: 0.6339 - val_loss: 0.5483 - val_accuracy: 0.8757 - val_auc: 0.4678 - val_precision: 0.0714 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.8947 - accuracy: 0.5648 - auc: 0.6211 - precision: 0.1101 - recall: 0.6339 - val_loss: 0.7822 - val_accuracy: 0.2090 - val_auc: 0.4664 - val_precision: 0.0517 - val_recall: 0.7500 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.7111 - accuracy: 0.5633 - auc: 0.6932 - precision: 0.1157 - recall: 0.6786 - val_loss: 0.6390 - val_accuracy: 0.7514 - val_auc: 0.5761 - val_precision: 0.1047 - val_recall: 0.4500 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.6102 - accuracy: 0.6327 - auc: 0.7619 - precision: 0.1461 - recall: 0.7500 - val_loss: 0.6209 - val_accuracy: 0.7260 - val_auc: 0.4382 - val_precision: 0.0247 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5969 - accuracy: 0.6483 - auc: 0.7766 - precision: 0.1506 - recall: 0.7411 - val_loss: 0.6231 - val_accuracy: 0.7006 - val_auc: 0.4069 - val_precision: 0.0114 - val_recall: 0.0500 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5747 - accuracy: 0.6447 - auc: 0.7784 - precision: 0.1467 - recall: 0.7232 - val_loss: 0.5271 - val_accuracy: 0.7853 - val_auc: 0.4344 - val_precision: 0.0172 - val_recall: 0.0500 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5160 - accuracy: 0.6596 - auc: 0.8229 - precision: 0.1664 - recall: 0.8214 - val_loss: 0.5717 - val_accuracy: 0.6977 - val_auc: 0.4621 - val_precision: 0.0421 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5323 - accuracy: 0.6929 - auc: 0.8172 - precision: 0.1701 - recall: 0.7411 - val_loss: 0.8724 - val_accuracy: 0.4237 - val_auc: 0.5257 - val_precision: 0.0660 - val_recall: 0.7000 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4945 - accuracy: 0.7148 - auc: 0.8397 - precision: 0.1884 - recall: 0.7857 - val_loss: 0.7028 - val_accuracy: 0.6045 - val_auc: 0.5031 - val_precision: 0.0714 - val_recall: 0.5000 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.3922 - accuracy: 0.7495 - auc: 0.9038 - precision: 0.2186 - recall: 0.8393 - val_loss: 0.6726 - val_accuracy: 0.5876 - val_auc: 0.4386 - val_precision: 0.0435 - val_recall: 0.3000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4482 - accuracy: 0.7629 - auc: 0.8695 - precision: 0.2134 - recall: 0.7411 - val_loss: 0.4926 - val_accuracy: 0.7938 - val_auc: 0.5042 - val_precision: 0.0182 - val_recall: 0.0500 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.7389 - auc: 0.8908 - precision: 0.2086 - recall: 0.8214 - val_loss: 0.5763 - val_accuracy: 0.7712 - val_auc: 0.4636 - val_precision: 0.0448 - val_recall: 0.1500 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.3686 - accuracy: 0.8040 - auc: 0.9144 - precision: 0.2676 - recall: 0.8482 - val_loss: 0.8394 - val_accuracy: 0.6158 - val_auc: 0.4981 - val_precision: 0.0672 - val_recall: 0.4500 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.7863 - auc: 0.8949 - precision: 0.2460 - recall: 0.8214 - val_loss: 0.6822 - val_accuracy: 0.6723 - val_auc: 0.5263 - val_precision: 0.0714 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4330 - accuracy: 0.7629 - auc: 0.8818 - precision: 0.2247 - recall: 0.8125 - val_loss: 0.6947 - val_accuracy: 0.7458 - val_auc: 0.4683 - val_precision: 0.0139 - val_recall: 0.0500 - lr: 0.0010\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.7006 - auc: 0.4069 - precision: 0.0114 - recall: 0.0500    \n",
      "Sampling from 31 games\n",
      "Created 1185 sequences of length 5\n",
      "X shape: (1185, 5, 1968)\n",
      "y shape: (1185,)\n",
      "Epoch 1/25\n",
      "30/30 [==============================] - 8s 103ms/step - loss: 1.2056 - accuracy: 0.4768 - auc: 0.5027 - precision: 0.0726 - recall: 0.5000 - val_loss: 0.4996 - val_accuracy: 0.9283 - val_auc: 0.5508 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.2616 - accuracy: 0.4895 - auc: 0.5523 - precision: 0.0863 - recall: 0.5972 - val_loss: 0.6288 - val_accuracy: 0.8228 - val_auc: 0.4234 - val_precision: 0.0345 - val_recall: 0.0667 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9056 - accuracy: 0.5464 - auc: 0.6573 - precision: 0.1092 - recall: 0.6944 - val_loss: 0.5824 - val_accuracy: 0.8987 - val_auc: 0.5578 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7633 - accuracy: 0.5696 - auc: 0.7118 - precision: 0.1199 - recall: 0.7361 - val_loss: 0.4365 - val_accuracy: 0.9367 - val_auc: 0.4820 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6266 - accuracy: 0.6255 - auc: 0.7689 - precision: 0.1418 - recall: 0.7778 - val_loss: 0.6462 - val_accuracy: 0.7511 - val_auc: 0.5066 - val_precision: 0.0600 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5790 - accuracy: 0.6540 - auc: 0.8030 - precision: 0.1578 - recall: 0.8194 - val_loss: 0.7683 - val_accuracy: 0.3122 - val_auc: 0.6008 - val_precision: 0.0843 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5865 - accuracy: 0.6867 - auc: 0.7911 - precision: 0.1601 - recall: 0.7361 - val_loss: 0.4602 - val_accuracy: 0.9198 - val_auc: 0.4806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5329 - accuracy: 0.6783 - auc: 0.8315 - precision: 0.1623 - recall: 0.7778 - val_loss: 0.8015 - val_accuracy: 0.2743 - val_auc: 0.4790 - val_precision: 0.0615 - val_recall: 0.7333 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4486 - accuracy: 0.7226 - auc: 0.8849 - precision: 0.1968 - recall: 0.8611 - val_loss: 0.7835 - val_accuracy: 0.3376 - val_auc: 0.5242 - val_precision: 0.0617 - val_recall: 0.6667 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.7711 - auc: 0.8934 - precision: 0.2264 - recall: 0.8333 - val_loss: 0.9016 - val_accuracy: 0.2954 - val_auc: 0.5626 - val_precision: 0.0682 - val_recall: 0.8000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.7732 - auc: 0.8963 - precision: 0.2302 - recall: 0.8472 - val_loss: 0.8805 - val_accuracy: 0.3629 - val_auc: 0.5266 - val_precision: 0.0641 - val_recall: 0.6667 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.9283 - auc: 0.5508 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 892 sequences of length 5\n",
      "X shape: (892, 5, 1968)\n",
      "y shape: (892,)\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 6s 58ms/step - loss: 1.1812 - accuracy: 0.5273 - auc: 0.5177 - precision: 0.0706 - recall: 0.5333 - val_loss: 0.4137 - val_accuracy: 0.9609 - val_auc: 0.5523 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.3435 - accuracy: 0.5231 - auc: 0.5323 - precision: 0.0725 - recall: 0.5556 - val_loss: 0.4475 - val_accuracy: 0.9609 - val_auc: 0.5997 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.3331 - accuracy: 0.5119 - auc: 0.5842 - precision: 0.0756 - recall: 0.6000 - val_loss: 0.7893 - val_accuracy: 0.0838 - val_auc: 0.5835 - val_precision: 0.0409 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9546 - accuracy: 0.5077 - auc: 0.6714 - precision: 0.0909 - recall: 0.7556 - val_loss: 0.8885 - val_accuracy: 0.0615 - val_auc: 0.5988 - val_precision: 0.0400 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6916 - accuracy: 0.5722 - auc: 0.7511 - precision: 0.1012 - recall: 0.7333 - val_loss: 0.7031 - val_accuracy: 0.4916 - val_auc: 0.6250 - val_precision: 0.0532 - val_recall: 0.7143 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5278 - accuracy: 0.6410 - auc: 0.8502 - precision: 0.1399 - recall: 0.9111 - val_loss: 0.4861 - val_accuracy: 0.9385 - val_auc: 0.5212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4877 - accuracy: 0.6606 - auc: 0.8796 - precision: 0.1470 - recall: 0.9111 - val_loss: 0.5261 - val_accuracy: 0.8994 - val_auc: 0.4556 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4388 - accuracy: 0.7083 - auc: 0.8988 - precision: 0.1700 - recall: 0.9333 - val_loss: 0.5472 - val_accuracy: 0.8436 - val_auc: 0.5166 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.6900 - auc: 0.9223 - precision: 0.1589 - recall: 0.9111 - val_loss: 0.5191 - val_accuracy: 0.8603 - val_auc: 0.5478 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4245 - accuracy: 0.7195 - auc: 0.9036 - precision: 0.1730 - recall: 0.9111 - val_loss: 0.6021 - val_accuracy: 0.7486 - val_auc: 0.5735 - val_precision: 0.0682 - val_recall: 0.4286 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4365 - accuracy: 0.7195 - auc: 0.8884 - precision: 0.1645 - recall: 0.8444 - val_loss: 0.7371 - val_accuracy: 0.4693 - val_auc: 0.5378 - val_precision: 0.0417 - val_recall: 0.5714 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.9609 - auc: 0.5523 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3457 sequences of length 7\n",
      "X shape: (3457, 7, 1968)\n",
      "y shape: (3457,)\n",
      "Epoch 1/25\n",
      "87/87 [==============================] - 7s 22ms/step - loss: 1.2260 - accuracy: 0.4872 - auc: 0.5163 - precision: 0.0674 - recall: 0.5189 - val_loss: 0.6087 - val_accuracy: 0.8728 - val_auc: 0.4118 - val_precision: 0.0286 - val_recall: 0.0182 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.9863 - accuracy: 0.5186 - auc: 0.5569 - precision: 0.0774 - recall: 0.5676 - val_loss: 0.7220 - val_accuracy: 0.4191 - val_auc: 0.5178 - val_precision: 0.0859 - val_recall: 0.6545 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.7796 - accuracy: 0.5783 - auc: 0.6359 - precision: 0.0983 - recall: 0.6486 - val_loss: 1.4721 - val_accuracy: 0.1069 - val_auc: 0.5668 - val_precision: 0.0817 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.6962 - accuracy: 0.5877 - auc: 0.6920 - precision: 0.1083 - recall: 0.7135 - val_loss: 1.4311 - val_accuracy: 0.1517 - val_auc: 0.5655 - val_precision: 0.0831 - val_recall: 0.9636 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.6562 - accuracy: 0.5855 - auc: 0.7141 - precision: 0.1058 - recall: 0.6973 - val_loss: 0.6202 - val_accuracy: 0.7023 - val_auc: 0.5619 - val_precision: 0.0963 - val_recall: 0.3273 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.5493 - accuracy: 0.6539 - auc: 0.7959 - precision: 0.1393 - recall: 0.8054 - val_loss: 0.5726 - val_accuracy: 0.7298 - val_auc: 0.5909 - val_precision: 0.1250 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.5469 - accuracy: 0.7009 - auc: 0.8034 - precision: 0.1511 - recall: 0.7514 - val_loss: 0.5300 - val_accuracy: 0.8237 - val_auc: 0.5885 - val_precision: 0.1319 - val_recall: 0.2182 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.5144 - accuracy: 0.6937 - auc: 0.8286 - precision: 0.1552 - recall: 0.8054 - val_loss: 0.4949 - val_accuracy: 0.8165 - val_auc: 0.5764 - val_precision: 0.1400 - val_recall: 0.2545 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4574 - accuracy: 0.7255 - auc: 0.8644 - precision: 0.1724 - recall: 0.8162 - val_loss: 0.6149 - val_accuracy: 0.7890 - val_auc: 0.5911 - val_precision: 0.1417 - val_recall: 0.3273 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4370 - accuracy: 0.7537 - auc: 0.8768 - precision: 0.1946 - recall: 0.8541 - val_loss: 0.7961 - val_accuracy: 0.6214 - val_auc: 0.5807 - val_precision: 0.1094 - val_recall: 0.5273 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.4102 - accuracy: 0.7714 - auc: 0.8903 - precision: 0.2016 - recall: 0.8162 - val_loss: 0.9954 - val_accuracy: 0.5795 - val_auc: 0.5863 - val_precision: 0.1067 - val_recall: 0.5818 - lr: 0.0010\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.8728 - auc: 0.4118 - precision: 0.0286 - recall: 0.0182   \n",
      "Sampling from 31 games\n",
      "Created 1736 sequences of length 7\n",
      "X shape: (1736, 7, 1968)\n",
      "y shape: (1736,)\n",
      "Epoch 1/25\n",
      "44/44 [==============================] - 7s 35ms/step - loss: 1.2383 - accuracy: 0.4942 - auc: 0.5215 - precision: 0.0806 - recall: 0.5229 - val_loss: 0.4838 - val_accuracy: 0.9368 - val_auc: 0.4601 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.1309 - accuracy: 0.5310 - auc: 0.5493 - precision: 0.0919 - recall: 0.5596 - val_loss: 1.0121 - val_accuracy: 0.0632 - val_auc: 0.5010 - val_precision: 0.0632 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.8451 - accuracy: 0.5598 - auc: 0.6605 - precision: 0.1102 - recall: 0.6514 - val_loss: 0.7566 - val_accuracy: 0.3276 - val_auc: 0.4435 - val_precision: 0.0656 - val_recall: 0.7273 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7188 - accuracy: 0.5965 - auc: 0.7065 - precision: 0.1333 - recall: 0.7523 - val_loss: 0.4634 - val_accuracy: 0.9253 - val_auc: 0.5427 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.6063 - accuracy: 0.6453 - auc: 0.7681 - precision: 0.1523 - recall: 0.7615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 17ms/step - loss: 0.6044 - accuracy: 0.6455 - auc: 0.7681 - precision: 0.1512 - recall: 0.7615 - val_loss: 0.2816 - val_accuracy: 0.9368 - val_auc: 0.4875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6462 - accuracy: 0.6938 - auc: 0.7675 - precision: 0.1595 - recall: 0.6789 - val_loss: 0.8716 - val_accuracy: 0.2845 - val_auc: 0.5681 - val_precision: 0.0651 - val_recall: 0.7727 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.5832 - accuracy: 0.6599 - auc: 0.7953 - precision: 0.1607 - recall: 0.7890 - val_loss: 0.3959 - val_accuracy: 0.8707 - val_auc: 0.5673 - val_precision: 0.1290 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.5031 - accuracy: 0.6960 - auc: 0.8466 - precision: 0.1838 - recall: 0.8349 - val_loss: 0.2945 - val_accuracy: 0.9023 - val_auc: 0.5815 - val_precision: 0.0714 - val_recall: 0.0455 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4501 - accuracy: 0.7493 - auc: 0.8726 - precision: 0.2188 - recall: 0.8532 - val_loss: 0.3705 - val_accuracy: 0.8592 - val_auc: 0.5661 - val_precision: 0.0909 - val_recall: 0.1364 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4972 - accuracy: 0.7543 - auc: 0.8467 - precision: 0.2143 - recall: 0.7982 - val_loss: 0.5196 - val_accuracy: 0.7672 - val_auc: 0.5006 - val_precision: 0.0597 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.7565 - auc: 0.8955 - precision: 0.2241 - recall: 0.8532 - val_loss: 0.5316 - val_accuracy: 0.7672 - val_auc: 0.4892 - val_precision: 0.0462 - val_recall: 0.1364 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.9368 - auc: 0.4601 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1161 sequences of length 7\n",
      "X shape: (1161, 7, 1968)\n",
      "y shape: (1161,)\n",
      "Epoch 1/25\n",
      "29/29 [==============================] - 6s 47ms/step - loss: 1.0655 - accuracy: 0.5356 - auc: 0.5804 - precision: 0.0743 - recall: 0.6226 - val_loss: 0.6078 - val_accuracy: 0.8498 - val_auc: 0.4229 - val_precision: 0.0500 - val_recall: 0.0588 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.0972 - accuracy: 0.5409 - auc: 0.6816 - precision: 0.0809 - recall: 0.6792 - val_loss: 0.9245 - val_accuracy: 0.0858 - val_auc: 0.5061 - val_precision: 0.0739 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.0765 - accuracy: 0.5550 - auc: 0.6608 - precision: 0.0853 - recall: 0.6981 - val_loss: 1.0471 - val_accuracy: 0.0730 - val_auc: 0.4210 - val_precision: 0.0730 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7076 - accuracy: 0.6185 - auc: 0.7710 - precision: 0.1050 - recall: 0.7547 - val_loss: 0.7085 - val_accuracy: 0.4034 - val_auc: 0.4357 - val_precision: 0.0643 - val_recall: 0.5294 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6001 - accuracy: 0.6821 - auc: 0.7932 - precision: 0.1265 - recall: 0.7736 - val_loss: 0.3695 - val_accuracy: 0.9270 - val_auc: 0.5366 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5884 - accuracy: 0.6595 - auc: 0.8186 - precision: 0.1275 - recall: 0.8491 - val_loss: 0.4876 - val_accuracy: 0.9270 - val_auc: 0.3761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5415 - accuracy: 0.6756 - auc: 0.8423 - precision: 0.1310 - recall: 0.8302 - val_loss: 0.4038 - val_accuracy: 0.9185 - val_auc: 0.4082 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4298 - accuracy: 0.7478 - auc: 0.8977 - precision: 0.1709 - recall: 0.8868 - val_loss: 0.3603 - val_accuracy: 0.9270 - val_auc: 0.4748 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.7683 - auc: 0.9277 - precision: 0.1885 - recall: 0.9245 - val_loss: 0.2937 - val_accuracy: 0.9270 - val_auc: 0.5471 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2845 - accuracy: 0.8190 - auc: 0.9602 - precision: 0.2275 - recall: 0.9057 - val_loss: 0.4683 - val_accuracy: 0.8712 - val_auc: 0.5417 - val_precision: 0.0667 - val_recall: 0.0588 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3068 - accuracy: 0.8136 - auc: 0.9489 - precision: 0.2222 - recall: 0.9057 - val_loss: 0.3644 - val_accuracy: 0.9227 - val_auc: 0.5682 - val_precision: 0.3333 - val_recall: 0.0588 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2408 - accuracy: 0.8998 - auc: 0.9673 - precision: 0.3529 - recall: 0.9057 - val_loss: 0.4112 - val_accuracy: 0.9056 - val_auc: 0.4808 - val_precision: 0.2222 - val_recall: 0.1176 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2551 - accuracy: 0.8373 - auc: 0.9661 - precision: 0.2525 - recall: 0.9434 - val_loss: 0.3482 - val_accuracy: 0.8970 - val_auc: 0.4902 - val_precision: 0.1111 - val_recall: 0.0588 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3441 - accuracy: 0.8502 - auc: 0.9281 - precision: 0.2500 - recall: 0.8113 - val_loss: 0.5723 - val_accuracy: 0.6867 - val_auc: 0.4797 - val_precision: 0.0882 - val_recall: 0.3529 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2520 - accuracy: 0.8405 - auc: 0.9675 - precision: 0.2564 - recall: 0.9434 - val_loss: 0.3839 - val_accuracy: 0.8970 - val_auc: 0.4722 - val_precision: 0.1818 - val_recall: 0.1176 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.9270 - auc: 0.5366 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 875 sequences of length 7\n",
      "X shape: (875, 7, 1968)\n",
      "y shape: (875,)\n",
      "Epoch 1/25\n",
      "22/22 [==============================] - 6s 62ms/step - loss: 1.0197 - accuracy: 0.5014 - auc: 0.5466 - precision: 0.1036 - recall: 0.5606 - val_loss: 0.5520 - val_accuracy: 0.9143 - val_auc: 0.5275 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0362 - accuracy: 0.5229 - auc: 0.5974 - precision: 0.1171 - recall: 0.6212 - val_loss: 0.4852 - val_accuracy: 0.9200 - val_auc: 0.4650 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9308 - accuracy: 0.5771 - auc: 0.6884 - precision: 0.1384 - recall: 0.6667 - val_loss: 0.4781 - val_accuracy: 0.9200 - val_auc: 0.5024 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7636 - accuracy: 0.6043 - auc: 0.7334 - precision: 0.1564 - recall: 0.7273 - val_loss: 0.5578 - val_accuracy: 0.9029 - val_auc: 0.5002 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5711 - accuracy: 0.6543 - auc: 0.8335 - precision: 0.1966 - recall: 0.8636 - val_loss: 0.4667 - val_accuracy: 0.9200 - val_auc: 0.5027 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6378 - accuracy: 0.6771 - auc: 0.8109 - precision: 0.1947 - recall: 0.7727 - val_loss: 0.4529 - val_accuracy: 0.9086 - val_auc: 0.5031 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6190 - accuracy: 0.6857 - auc: 0.8009 - precision: 0.1992 - recall: 0.7727 - val_loss: 0.4739 - val_accuracy: 0.9086 - val_auc: 0.5171 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5111 - accuracy: 0.7314 - auc: 0.8661 - precision: 0.2437 - recall: 0.8788 - val_loss: 0.6588 - val_accuracy: 0.5829 - val_auc: 0.5783 - val_precision: 0.0845 - val_recall: 0.4286 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4119 - accuracy: 0.7543 - auc: 0.9071 - precision: 0.2613 - recall: 0.8788 - val_loss: 0.5307 - val_accuracy: 0.7771 - val_auc: 0.5501 - val_precision: 0.0968 - val_recall: 0.2143 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4895 - accuracy: 0.7614 - auc: 0.8640 - precision: 0.2560 - recall: 0.8030 - val_loss: 0.5344 - val_accuracy: 0.8057 - val_auc: 0.5708 - val_precision: 0.0833 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3946 - accuracy: 0.7929 - auc: 0.9108 - precision: 0.3015 - recall: 0.9091 - val_loss: 0.4457 - val_accuracy: 0.8971 - val_auc: 0.5060 - val_precision: 0.1667 - val_recall: 0.0714 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.9143 - auc: 0.5275 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3395 sequences of length 9\n",
      "X shape: (3395, 9, 1968)\n",
      "y shape: (3395,)\n",
      "Epoch 1/25\n",
      "85/85 [==============================] - 7s 23ms/step - loss: 1.2644 - accuracy: 0.4919 - auc: 0.5023 - precision: 0.0722 - recall: 0.5155 - val_loss: 0.5090 - val_accuracy: 0.9352 - val_auc: 0.4124 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 1.0529 - accuracy: 0.5136 - auc: 0.5087 - precision: 0.0715 - recall: 0.4845 - val_loss: 0.7090 - val_accuracy: 0.4330 - val_auc: 0.4849 - val_precision: 0.0591 - val_recall: 0.5476 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.8193 - accuracy: 0.5140 - auc: 0.5935 - precision: 0.0854 - recall: 0.5979 - val_loss: 0.3515 - val_accuracy: 0.9219 - val_auc: 0.5007 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.7249 - accuracy: 0.5979 - auc: 0.6575 - precision: 0.1129 - recall: 0.6753 - val_loss: 0.6750 - val_accuracy: 0.5670 - val_auc: 0.5067 - val_precision: 0.0594 - val_recall: 0.4048 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.6393 - accuracy: 0.6046 - auc: 0.7236 - precision: 0.1226 - recall: 0.7371 - val_loss: 0.4402 - val_accuracy: 0.8645 - val_auc: 0.5047 - val_precision: 0.0833 - val_recall: 0.1190 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.6195 - accuracy: 0.6263 - auc: 0.7296 - precision: 0.1258 - recall: 0.7113 - val_loss: 0.7879 - val_accuracy: 0.5110 - val_auc: 0.5536 - val_precision: 0.0685 - val_recall: 0.5476 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.5643 - accuracy: 0.6598 - auc: 0.7903 - precision: 0.1456 - recall: 0.7732 - val_loss: 1.1810 - val_accuracy: 0.3976 - val_auc: 0.5544 - val_precision: 0.0662 - val_recall: 0.6667 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.5209 - accuracy: 0.6789 - auc: 0.8175 - precision: 0.1534 - recall: 0.7732 - val_loss: 0.8985 - val_accuracy: 0.5287 - val_auc: 0.5601 - val_precision: 0.0736 - val_recall: 0.5714 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.4546 - accuracy: 0.6970 - auc: 0.8721 - precision: 0.1734 - recall: 0.8608 - val_loss: 0.8233 - val_accuracy: 0.5493 - val_auc: 0.5751 - val_precision: 0.0769 - val_recall: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.4325 - accuracy: 0.7279 - auc: 0.8843 - precision: 0.1914 - recall: 0.8711 - val_loss: 0.8194 - val_accuracy: 0.5803 - val_auc: 0.5836 - val_precision: 0.0767 - val_recall: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "85/85 [==============================] - 1s 9ms/step - loss: 0.4038 - accuracy: 0.7474 - auc: 0.9085 - precision: 0.2099 - recall: 0.9175 - val_loss: 0.6633 - val_accuracy: 0.6907 - val_auc: 0.6024 - val_precision: 0.0882 - val_recall: 0.4286 - lr: 2.0000e-04\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.9352 - auc: 0.4124 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1705 sequences of length 9\n",
      "X shape: (1705, 9, 1968)\n",
      "y shape: (1705,)\n",
      "Epoch 1/25\n",
      "43/43 [==============================] - 7s 36ms/step - loss: 1.2910 - accuracy: 0.5161 - auc: 0.4963 - precision: 0.0669 - recall: 0.4889 - val_loss: 0.3824 - val_accuracy: 0.8856 - val_auc: 0.4075 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 1.1592 - accuracy: 0.5345 - auc: 0.5956 - precision: 0.0814 - recall: 0.5889 - val_loss: 0.4432 - val_accuracy: 0.8856 - val_auc: 0.4843 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.8445 - accuracy: 0.5748 - auc: 0.6763 - precision: 0.0970 - recall: 0.6556 - val_loss: 0.5724 - val_accuracy: 0.8710 - val_auc: 0.4673 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.6338 - accuracy: 0.6246 - auc: 0.7821 - precision: 0.1272 - recall: 0.8000 - val_loss: 0.5564 - val_accuracy: 0.8592 - val_auc: 0.4614 - val_precision: 0.0909 - val_recall: 0.0256 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.6664 - auc: 0.7508 - precision: 0.1283 - recall: 0.7000 - val_loss: 0.3888 - val_accuracy: 0.8856 - val_auc: 0.4620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.5563 - accuracy: 0.6745 - auc: 0.8273 - precision: 0.1446 - recall: 0.8000 - val_loss: 0.5853 - val_accuracy: 0.7537 - val_auc: 0.3906 - val_precision: 0.0755 - val_recall: 0.1026 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4766 - accuracy: 0.7177 - auc: 0.8607 - precision: 0.1685 - recall: 0.8333 - val_loss: 0.4865 - val_accuracy: 0.8592 - val_auc: 0.3972 - val_precision: 0.0909 - val_recall: 0.0256 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.7478 - auc: 0.9162 - precision: 0.1932 - recall: 0.8889 - val_loss: 0.5144 - val_accuracy: 0.8211 - val_auc: 0.4058 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3604 - accuracy: 0.7749 - auc: 0.9312 - precision: 0.2182 - recall: 0.9333 - val_loss: 0.5620 - val_accuracy: 0.7507 - val_auc: 0.3941 - val_precision: 0.0400 - val_recall: 0.0513 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3221 - accuracy: 0.7925 - auc: 0.9536 - precision: 0.2371 - recall: 0.9667 - val_loss: 0.5606 - val_accuracy: 0.7595 - val_auc: 0.3951 - val_precision: 0.0426 - val_recall: 0.0513 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.3375 - accuracy: 0.7933 - auc: 0.9415 - precision: 0.2318 - recall: 0.9222 - val_loss: 0.6025 - val_accuracy: 0.7361 - val_auc: 0.3826 - val_precision: 0.0678 - val_recall: 0.1026 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8856 - auc: 0.4075 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1142 sequences of length 9\n",
      "X shape: (1142, 9, 1968)\n",
      "y shape: (1142,)\n",
      "Epoch 1/25\n",
      "29/29 [==============================] - 6s 50ms/step - loss: 1.1189 - accuracy: 0.4852 - auc: 0.5273 - precision: 0.0795 - recall: 0.5588 - val_loss: 0.4726 - val_accuracy: 0.9301 - val_auc: 0.4294 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1791 - accuracy: 0.5225 - auc: 0.5875 - precision: 0.0929 - recall: 0.6176 - val_loss: 0.4540 - val_accuracy: 0.9301 - val_auc: 0.4227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9021 - accuracy: 0.5728 - auc: 0.6701 - precision: 0.1111 - recall: 0.6765 - val_loss: 0.5720 - val_accuracy: 0.8952 - val_auc: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7180 - accuracy: 0.5882 - auc: 0.7617 - precision: 0.1280 - recall: 0.7794 - val_loss: 0.7448 - val_accuracy: 0.2707 - val_auc: 0.5668 - val_precision: 0.0782 - val_recall: 0.8750 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6973 - accuracy: 0.6112 - auc: 0.7448 - precision: 0.1273 - recall: 0.7206 - val_loss: 0.5152 - val_accuracy: 0.9039 - val_auc: 0.5395 - val_precision: 0.2000 - val_recall: 0.1250 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5814 - accuracy: 0.6495 - auc: 0.8057 - precision: 0.1480 - recall: 0.7794 - val_loss: 0.4168 - val_accuracy: 0.9170 - val_auc: 0.5913 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4608 - accuracy: 0.7119 - auc: 0.8817 - precision: 0.1905 - recall: 0.8824 - val_loss: 0.4952 - val_accuracy: 0.8122 - val_auc: 0.5795 - val_precision: 0.1143 - val_recall: 0.2500 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5002 - accuracy: 0.7196 - auc: 0.8596 - precision: 0.1887 - recall: 0.8382 - val_loss: 0.3746 - val_accuracy: 0.9170 - val_auc: 0.5882 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4201 - accuracy: 0.7656 - auc: 0.8905 - precision: 0.2256 - recall: 0.8824 - val_loss: 0.3263 - val_accuracy: 0.9170 - val_auc: 0.5695 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.7558 - auc: 0.8968 - precision: 0.2161 - recall: 0.8676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 24ms/step - loss: 0.4263 - accuracy: 0.7558 - auc: 0.8968 - precision: 0.2161 - recall: 0.8676 - val_loss: 0.2794 - val_accuracy: 0.9301 - val_auc: 0.6184 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3842 - accuracy: 0.7689 - auc: 0.9143 - precision: 0.2261 - recall: 0.8676 - val_loss: 0.2984 - val_accuracy: 0.9170 - val_auc: 0.5970 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.9301 - auc: 0.4294 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 861 sequences of length 9\n",
      "X shape: (861, 9, 1968)\n",
      "y shape: (861,)\n",
      "Epoch 1/25\n",
      "22/22 [==============================] - 6s 62ms/step - loss: 1.0670 - accuracy: 0.4985 - auc: 0.5414 - precision: 0.0627 - recall: 0.5789 - val_loss: 0.4515 - val_accuracy: 0.9249 - val_auc: 0.4529 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0453 - accuracy: 0.5174 - auc: 0.6752 - precision: 0.0751 - recall: 0.6842 - val_loss: 1.1925 - val_accuracy: 0.0751 - val_auc: 0.4409 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1272 - accuracy: 0.5291 - auc: 0.6263 - precision: 0.0667 - recall: 0.5789 - val_loss: 1.5070 - val_accuracy: 0.0751 - val_auc: 0.5060 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8369 - accuracy: 0.5741 - auc: 0.7448 - precision: 0.0927 - recall: 0.7632 - val_loss: 1.1405 - val_accuracy: 0.0751 - val_auc: 0.5260 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6736 - accuracy: 0.6017 - auc: 0.7899 - precision: 0.1067 - recall: 0.8421 - val_loss: 0.7917 - val_accuracy: 0.1098 - val_auc: 0.5269 - val_precision: 0.0675 - val_recall: 0.8462 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7060 - accuracy: 0.6512 - auc: 0.7656 - precision: 0.1024 - recall: 0.6842 - val_loss: 1.1540 - val_accuracy: 0.0751 - val_auc: 0.3935 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5046 - accuracy: 0.6759 - auc: 0.8953 - precision: 0.1373 - recall: 0.9211 - val_loss: 1.3056 - val_accuracy: 0.0751 - val_auc: 0.3788 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.6919 - auc: 0.9091 - precision: 0.1434 - recall: 0.9211 - val_loss: 1.5420 - val_accuracy: 0.0751 - val_auc: 0.3788 - val_precision: 0.0751 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4334 - accuracy: 0.7064 - auc: 0.9003 - precision: 0.1435 - recall: 0.8684 - val_loss: 1.6464 - val_accuracy: 0.0867 - val_auc: 0.3661 - val_precision: 0.0760 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3236 - accuracy: 0.7456 - auc: 0.9667 - precision: 0.1784 - recall: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.0867 - val_auc: 0.4125 - val_precision: 0.0760 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3006 - accuracy: 0.7587 - auc: 0.9733 - precision: 0.1863 - recall: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.0925 - val_auc: 0.4036 - val_precision: 0.0765 - val_recall: 1.0000 - lr: 2.0000e-04\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.9249 - auc: 0.4529 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3333 sequences of length 11\n",
      "X shape: (3333, 11, 1968)\n",
      "y shape: (3333,)\n",
      "Epoch 1/25\n",
      "84/84 [==============================] - 7s 23ms/step - loss: 1.2766 - accuracy: 0.4831 - auc: 0.4866 - precision: 0.0667 - recall: 0.5027 - val_loss: 0.7122 - val_accuracy: 0.3688 - val_auc: 0.5231 - val_precision: 0.0650 - val_recall: 0.6087 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.0011 - accuracy: 0.5311 - auc: 0.5508 - precision: 0.0769 - recall: 0.5301 - val_loss: 0.4236 - val_accuracy: 0.9235 - val_auc: 0.5052 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.8668 - accuracy: 0.5454 - auc: 0.6005 - precision: 0.0861 - recall: 0.5847 - val_loss: 0.5975 - val_accuracy: 0.7601 - val_auc: 0.5637 - val_precision: 0.1096 - val_recall: 0.3478 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.6771 - accuracy: 0.6103 - auc: 0.6999 - precision: 0.1130 - recall: 0.6831 - val_loss: 0.7837 - val_accuracy: 0.4333 - val_auc: 0.5379 - val_precision: 0.0787 - val_recall: 0.6739 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.6437 - accuracy: 0.6365 - auc: 0.7326 - precision: 0.1250 - recall: 0.7158 - val_loss: 0.3725 - val_accuracy: 0.8666 - val_auc: 0.5141 - val_precision: 0.0426 - val_recall: 0.0435 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.5799 - accuracy: 0.6692 - auc: 0.7848 - precision: 0.1452 - recall: 0.7814 - val_loss: 0.6415 - val_accuracy: 0.7136 - val_auc: 0.5545 - val_precision: 0.0710 - val_recall: 0.2609 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.5143 - accuracy: 0.6958 - auc: 0.8317 - precision: 0.1631 - recall: 0.8306 - val_loss: 0.6158 - val_accuracy: 0.7316 - val_auc: 0.5542 - val_precision: 0.0654 - val_recall: 0.2174 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4938 - accuracy: 0.7258 - auc: 0.8463 - precision: 0.1730 - recall: 0.7923 - val_loss: 0.6072 - val_accuracy: 0.7526 - val_auc: 0.5215 - val_precision: 0.0780 - val_recall: 0.2391 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.7434 - auc: 0.8526 - precision: 0.1865 - recall: 0.8142 - val_loss: 0.8409 - val_accuracy: 0.6627 - val_auc: 0.5084 - val_precision: 0.0676 - val_recall: 0.3043 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4653 - accuracy: 0.7517 - auc: 0.8651 - precision: 0.1957 - recall: 0.8415 - val_loss: 0.5163 - val_accuracy: 0.8201 - val_auc: 0.5448 - val_precision: 0.0889 - val_recall: 0.1739 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3735 - accuracy: 0.7674 - auc: 0.9187 - precision: 0.2136 - recall: 0.8907 - val_loss: 0.6227 - val_accuracy: 0.7346 - val_auc: 0.5477 - val_precision: 0.0932 - val_recall: 0.3261 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3535 - accuracy: 0.7884 - auc: 0.9285 - precision: 0.2343 - recall: 0.9180 - val_loss: 0.6276 - val_accuracy: 0.7286 - val_auc: 0.5438 - val_precision: 0.0859 - val_recall: 0.3043 - lr: 2.0000e-04\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.9235 - auc: 0.5052 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1674 sequences of length 11\n",
      "X shape: (1674, 11, 1968)\n",
      "y shape: (1674,)\n",
      "Epoch 1/25\n",
      "42/42 [==============================] - 7s 37ms/step - loss: 1.2565 - accuracy: 0.5108 - auc: 0.5038 - precision: 0.0741 - recall: 0.5326 - val_loss: 0.6479 - val_accuracy: 0.7552 - val_auc: 0.5260 - val_precision: 0.0984 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.1173 - accuracy: 0.5250 - auc: 0.5735 - precision: 0.0841 - recall: 0.5978 - val_loss: 0.9192 - val_accuracy: 0.0955 - val_auc: 0.4221 - val_precision: 0.0958 - val_recall: 0.9697 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.9165 - accuracy: 0.5556 - auc: 0.6578 - precision: 0.1039 - recall: 0.7174 - val_loss: 0.5446 - val_accuracy: 0.8955 - val_auc: 0.4640 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.8071 - accuracy: 0.5922 - auc: 0.6885 - precision: 0.1045 - recall: 0.6522 - val_loss: 0.3417 - val_accuracy: 0.9015 - val_auc: 0.5878 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6122 - accuracy: 0.6303 - auc: 0.7766 - precision: 0.1262 - recall: 0.7391 - val_loss: 0.4842 - val_accuracy: 0.8746 - val_auc: 0.5593 - val_precision: 0.2000 - val_recall: 0.0909 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.6744 - auc: 0.8496 - precision: 0.1587 - recall: 0.8696 - val_loss: 0.3324 - val_accuracy: 0.9015 - val_auc: 0.5137 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.7476 - auc: 0.9056 - precision: 0.2015 - recall: 0.9022 - val_loss: 0.4124 - val_accuracy: 0.9015 - val_auc: 0.5307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3783 - accuracy: 0.7707 - auc: 0.9175 - precision: 0.2178 - recall: 0.9022 - val_loss: 0.3699 - val_accuracy: 0.8866 - val_auc: 0.5165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3448 - accuracy: 0.8058 - auc: 0.9291 - precision: 0.2407 - recall: 0.8478 - val_loss: 0.4153 - val_accuracy: 0.8866 - val_auc: 0.4826 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3118 - accuracy: 0.8402 - auc: 0.9436 - precision: 0.2882 - recall: 0.9022 - val_loss: 0.4331 - val_accuracy: 0.8478 - val_auc: 0.5231 - val_precision: 0.0500 - val_recall: 0.0303 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3019 - accuracy: 0.8536 - auc: 0.9466 - precision: 0.3102 - recall: 0.9239 - val_loss: 0.4288 - val_accuracy: 0.8687 - val_auc: 0.5424 - val_precision: 0.0769 - val_recall: 0.0303 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.2592 - accuracy: 0.8626 - auc: 0.9634 - precision: 0.3244 - recall: 0.9239 - val_loss: 0.5152 - val_accuracy: 0.8000 - val_auc: 0.5166 - val_precision: 0.0750 - val_recall: 0.0909 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.2534 - accuracy: 0.8693 - auc: 0.9632 - precision: 0.3360 - recall: 0.9239 - val_loss: 0.6408 - val_accuracy: 0.7164 - val_auc: 0.5169 - val_precision: 0.1026 - val_recall: 0.2424 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.8955 - auc: 0.4640 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1123 sequences of length 11\n",
      "X shape: (1123, 11, 1968)\n",
      "y shape: (1123,)\n",
      "Epoch 1/25\n",
      "29/29 [==============================] - 9s 49ms/step - loss: 1.1615 - accuracy: 0.5033 - auc: 0.5082 - precision: 0.0762 - recall: 0.5000 - val_loss: 0.9081 - val_accuracy: 0.0711 - val_auc: 0.6225 - val_precision: 0.0711 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.2896 - accuracy: 0.5267 - auc: 0.5593 - precision: 0.0820 - recall: 0.5147 - val_loss: 0.7847 - val_accuracy: 0.0978 - val_auc: 0.5600 - val_precision: 0.0731 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8980 - accuracy: 0.5134 - auc: 0.6623 - precision: 0.1032 - recall: 0.7059 - val_loss: 0.6388 - val_accuracy: 0.8044 - val_auc: 0.4708 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7990 - accuracy: 0.5802 - auc: 0.7260 - precision: 0.1241 - recall: 0.7500 - val_loss: 0.6458 - val_accuracy: 0.7644 - val_auc: 0.4862 - val_precision: 0.0698 - val_recall: 0.1875 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6603 - accuracy: 0.5690 - auc: 0.7572 - precision: 0.1211 - recall: 0.7500 - val_loss: 1.2693 - val_accuracy: 0.0711 - val_auc: 0.5392 - val_precision: 0.0711 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5281 - accuracy: 0.6169 - auc: 0.8549 - precision: 0.1515 - recall: 0.8824 - val_loss: 0.7719 - val_accuracy: 0.3067 - val_auc: 0.5052 - val_precision: 0.0625 - val_recall: 0.6250 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5644 - accuracy: 0.6693 - auc: 0.8246 - precision: 0.1700 - recall: 0.8676 - val_loss: 1.6936 - val_accuracy: 0.0711 - val_auc: 0.4752 - val_precision: 0.0711 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5216 - accuracy: 0.6771 - auc: 0.8615 - precision: 0.1716 - recall: 0.8529 - val_loss: 0.9922 - val_accuracy: 0.1467 - val_auc: 0.4438 - val_precision: 0.0686 - val_recall: 0.8750 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.7094 - auc: 0.9045 - precision: 0.1994 - recall: 0.9412 - val_loss: 0.9607 - val_accuracy: 0.2489 - val_auc: 0.4622 - val_precision: 0.0629 - val_recall: 0.6875 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.7439 - auc: 0.9081 - precision: 0.2148 - recall: 0.8971 - val_loss: 0.9897 - val_accuracy: 0.2756 - val_auc: 0.4773 - val_precision: 0.0599 - val_recall: 0.6250 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4211 - accuracy: 0.7038 - auc: 0.8987 - precision: 0.1944 - recall: 0.9265 - val_loss: 0.9474 - val_accuracy: 0.3822 - val_auc: 0.4907 - val_precision: 0.0699 - val_recall: 0.6250 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3885 - accuracy: 0.7461 - auc: 0.9163 - precision: 0.2241 - recall: 0.9559 - val_loss: 0.9117 - val_accuracy: 0.4267 - val_auc: 0.4830 - val_precision: 0.0752 - val_recall: 0.6250 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.3566 - accuracy: 0.7517 - auc: 0.9363 - precision: 0.2281 - recall: 0.9559 - val_loss: 1.0430 - val_accuracy: 0.3556 - val_auc: 0.4825 - val_precision: 0.0612 - val_recall: 0.5625 - lr: 2.0000e-04\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.8044 - auc: 0.4708 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 844 sequences of length 11\n",
      "X shape: (844, 11, 1968)\n",
      "y shape: (844,)\n",
      "Epoch 1/25\n",
      "22/22 [==============================] - 6s 63ms/step - loss: 1.2197 - accuracy: 0.4844 - auc: 0.4848 - precision: 0.0943 - recall: 0.5156 - val_loss: 0.7054 - val_accuracy: 0.4438 - val_auc: 0.4802 - val_precision: 0.0745 - val_recall: 0.5000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0848 - accuracy: 0.5215 - auc: 0.5900 - precision: 0.1157 - recall: 0.6094 - val_loss: 0.8737 - val_accuracy: 0.0828 - val_auc: 0.4387 - val_precision: 0.0828 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8919 - accuracy: 0.5719 - auc: 0.7251 - precision: 0.1495 - recall: 0.7500 - val_loss: 1.1071 - val_accuracy: 0.0828 - val_auc: 0.4071 - val_precision: 0.0828 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.6267 - auc: 0.7453 - precision: 0.1667 - recall: 0.7344 - val_loss: 1.0343 - val_accuracy: 0.0828 - val_auc: 0.5355 - val_precision: 0.0828 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6424 - accuracy: 0.6415 - auc: 0.7780 - precision: 0.1821 - recall: 0.7969 - val_loss: 0.7901 - val_accuracy: 0.0947 - val_auc: 0.4687 - val_precision: 0.0788 - val_recall: 0.9286 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5688 - accuracy: 0.6889 - auc: 0.8280 - precision: 0.2103 - recall: 0.8281 - val_loss: 0.8095 - val_accuracy: 0.1361 - val_auc: 0.5922 - val_precision: 0.0875 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4388 - accuracy: 0.7348 - auc: 0.9009 - precision: 0.2489 - recall: 0.8906 - val_loss: 0.6662 - val_accuracy: 0.6391 - val_auc: 0.5053 - val_precision: 0.0566 - val_recall: 0.2143 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4045 - accuracy: 0.7615 - auc: 0.9026 - precision: 0.2701 - recall: 0.8906 - val_loss: 0.6517 - val_accuracy: 0.6805 - val_auc: 0.5207 - val_precision: 0.0833 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3689 - accuracy: 0.7526 - auc: 0.9248 - precision: 0.2648 - recall: 0.9062 - val_loss: 0.6734 - val_accuracy: 0.5503 - val_auc: 0.4546 - val_precision: 0.0571 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3192 - accuracy: 0.7956 - auc: 0.9521 - precision: 0.3112 - recall: 0.9531 - val_loss: 0.6569 - val_accuracy: 0.6036 - val_auc: 0.4244 - val_precision: 0.0508 - val_recall: 0.2143 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3102 - accuracy: 0.7941 - auc: 0.9540 - precision: 0.3096 - recall: 0.9531 - val_loss: 0.6550 - val_accuracy: 0.5917 - val_auc: 0.4364 - val_precision: 0.0492 - val_recall: 0.2143 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3060 - accuracy: 0.7941 - auc: 0.9577 - precision: 0.3134 - recall: 0.9844 - val_loss: 0.6158 - val_accuracy: 0.6627 - val_auc: 0.4449 - val_precision: 0.0426 - val_recall: 0.1429 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2870 - accuracy: 0.8341 - auc: 0.9602 - precision: 0.3588 - recall: 0.9531 - val_loss: 0.7290 - val_accuracy: 0.5089 - val_auc: 0.4470 - val_precision: 0.0519 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2984 - accuracy: 0.8148 - auc: 0.9540 - precision: 0.3351 - recall: 0.9688 - val_loss: 0.7689 - val_accuracy: 0.4911 - val_auc: 0.4521 - val_precision: 0.0714 - val_recall: 0.4286 - lr: 2.0000e-04\n",
      "Epoch 15/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2580 - accuracy: 0.8341 - auc: 0.9715 - precision: 0.3588 - recall: 0.9531 - val_loss: 0.7888 - val_accuracy: 0.4852 - val_auc: 0.4459 - val_precision: 0.0706 - val_recall: 0.4286 - lr: 2.0000e-04\n",
      "Epoch 16/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2757 - accuracy: 0.8489 - auc: 0.9610 - precision: 0.3827 - recall: 0.9688 - val_loss: 0.8213 - val_accuracy: 0.4675 - val_auc: 0.4316 - val_precision: 0.0476 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 17/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2857 - accuracy: 0.8311 - auc: 0.9556 - precision: 0.3547 - recall: 0.9531 - val_loss: 0.8317 - val_accuracy: 0.4793 - val_auc: 0.4470 - val_precision: 0.0488 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "Epoch 18/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2632 - accuracy: 0.8489 - auc: 0.9645 - precision: 0.3827 - recall: 0.9688 - val_loss: 0.8158 - val_accuracy: 0.5089 - val_auc: 0.4730 - val_precision: 0.0633 - val_recall: 0.3571 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2591 - accuracy: 0.8607 - auc: 0.9661 - precision: 0.4000 - recall: 0.9375 - val_loss: 0.8199 - val_accuracy: 0.5621 - val_auc: 0.4882 - val_precision: 0.0588 - val_recall: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2603 - accuracy: 0.8326 - auc: 0.9650 - precision: 0.3533 - recall: 0.9219 - val_loss: 0.8300 - val_accuracy: 0.5562 - val_auc: 0.4954 - val_precision: 0.0580 - val_recall: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2334 - accuracy: 0.8504 - auc: 0.9762 - precision: 0.3836 - recall: 0.9531 - val_loss: 0.8416 - val_accuracy: 0.6095 - val_auc: 0.4959 - val_precision: 0.0667 - val_recall: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.2431 - accuracy: 0.8652 - auc: 0.9707 - precision: 0.4106 - recall: 0.9688 - val_loss: 0.8567 - val_accuracy: 0.5858 - val_auc: 0.5111 - val_precision: 0.0625 - val_recall: 0.2857 - lr: 1.0000e-04\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.6627 - auc: 0.4449 - precision: 0.0426 - recall: 0.1429    \n",
      "Sampling from 31 games\n",
      "Created 3271 sequences of length 13\n",
      "X shape: (3271, 13, 1968)\n",
      "y shape: (3271,)\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 7s 24ms/step - loss: 1.3389 - accuracy: 0.4897 - auc: 0.4871 - precision: 0.0660 - recall: 0.4972 - val_loss: 0.8257 - val_accuracy: 0.0748 - val_auc: 0.5033 - val_precision: 0.0691 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.9980 - accuracy: 0.5183 - auc: 0.5569 - precision: 0.0746 - recall: 0.5367 - val_loss: 1.0656 - val_accuracy: 0.0748 - val_auc: 0.5750 - val_precision: 0.0691 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.8177 - accuracy: 0.5386 - auc: 0.6120 - precision: 0.0880 - recall: 0.6215 - val_loss: 0.7122 - val_accuracy: 0.4962 - val_auc: 0.5833 - val_precision: 0.0893 - val_recall: 0.6889 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.7312 - accuracy: 0.5879 - auc: 0.6777 - precision: 0.1059 - recall: 0.6836 - val_loss: 0.4142 - val_accuracy: 0.8931 - val_auc: 0.6061 - val_precision: 0.1622 - val_recall: 0.1333 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5940 - accuracy: 0.6430 - auc: 0.7703 - precision: 0.1307 - recall: 0.7571 - val_loss: 0.4252 - val_accuracy: 0.8611 - val_auc: 0.4952 - val_precision: 0.1034 - val_recall: 0.1333 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5217 - accuracy: 0.6907 - auc: 0.8232 - precision: 0.1550 - recall: 0.8023 - val_loss: 0.3907 - val_accuracy: 0.8550 - val_auc: 0.6211 - val_precision: 0.1324 - val_recall: 0.2000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.5163 - accuracy: 0.6965 - auc: 0.8294 - precision: 0.1576 - recall: 0.8023 - val_loss: 0.6997 - val_accuracy: 0.6137 - val_auc: 0.4818 - val_precision: 0.0630 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4912 - accuracy: 0.7179 - auc: 0.8447 - precision: 0.1719 - recall: 0.8305 - val_loss: 0.8073 - val_accuracy: 0.5664 - val_auc: 0.6030 - val_precision: 0.0922 - val_recall: 0.6000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4459 - accuracy: 0.7668 - auc: 0.8770 - precision: 0.2038 - recall: 0.8418 - val_loss: 0.5550 - val_accuracy: 0.8351 - val_auc: 0.5511 - val_precision: 0.0800 - val_recall: 0.1333 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.4239 - accuracy: 0.7645 - auc: 0.8882 - precision: 0.1997 - recall: 0.8249 - val_loss: 0.5095 - val_accuracy: 0.8366 - val_auc: 0.5191 - val_precision: 0.1026 - val_recall: 0.1778 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3928 - accuracy: 0.7844 - auc: 0.9041 - precision: 0.2232 - recall: 0.8814 - val_loss: 0.5744 - val_accuracy: 0.7863 - val_auc: 0.5195 - val_precision: 0.1008 - val_recall: 0.2667 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3161 - accuracy: 0.8020 - auc: 0.9462 - precision: 0.2459 - recall: 0.9322 - val_loss: 0.5457 - val_accuracy: 0.7863 - val_auc: 0.5196 - val_precision: 0.0870 - val_recall: 0.2222 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3163 - accuracy: 0.8349 - auc: 0.9427 - precision: 0.2790 - recall: 0.9096 - val_loss: 0.6225 - val_accuracy: 0.7435 - val_auc: 0.5226 - val_precision: 0.0759 - val_recall: 0.2444 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.3323 - accuracy: 0.8165 - auc: 0.9336 - precision: 0.2553 - recall: 0.8927 - val_loss: 0.6049 - val_accuracy: 0.7527 - val_auc: 0.5262 - val_precision: 0.0730 - val_recall: 0.2222 - lr: 2.0000e-04\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8931 - auc: 0.6061 - precision: 0.1622 - recall: 0.1333   \n",
      "Sampling from 31 games\n",
      "Created 1643 sequences of length 13\n",
      "X shape: (1643, 13, 1968)\n",
      "y shape: (1643,)\n",
      "Epoch 1/25\n",
      "42/42 [==============================] - 7s 37ms/step - loss: 1.3877 - accuracy: 0.4673 - auc: 0.4548 - precision: 0.0566 - recall: 0.4382 - val_loss: 0.4752 - val_accuracy: 0.9088 - val_auc: 0.6101 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 1.2473 - accuracy: 0.4825 - auc: 0.5273 - precision: 0.0699 - recall: 0.5393 - val_loss: 0.8290 - val_accuracy: 0.0973 - val_auc: 0.4238 - val_precision: 0.0917 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.9182 - accuracy: 0.5145 - auc: 0.6736 - precision: 0.0945 - recall: 0.7191 - val_loss: 0.4894 - val_accuracy: 0.9058 - val_auc: 0.4614 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.7757 - accuracy: 0.5715 - auc: 0.6907 - precision: 0.1037 - recall: 0.6966 - val_loss: 0.4422 - val_accuracy: 0.9058 - val_auc: 0.4746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.6271 - auc: 0.7952 - precision: 0.1387 - recall: 0.8652 - val_loss: 0.3191 - val_accuracy: 0.9088 - val_auc: 0.4469 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6303 - accuracy: 0.6651 - auc: 0.7746 - precision: 0.1321 - recall: 0.7079 - val_loss: 0.3303 - val_accuracy: 0.9088 - val_auc: 0.4775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6548 - accuracy: 0.6309 - auc: 0.7648 - precision: 0.1250 - recall: 0.7416 - val_loss: 0.3301 - val_accuracy: 0.8906 - val_auc: 0.5773 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.6109 - accuracy: 0.6438 - auc: 0.7989 - precision: 0.1292 - recall: 0.7416 - val_loss: 0.3710 - val_accuracy: 0.8875 - val_auc: 0.5616 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4948 - accuracy: 0.7040 - auc: 0.8617 - precision: 0.1696 - recall: 0.8652 - val_loss: 0.4265 - val_accuracy: 0.8419 - val_auc: 0.5201 - val_precision: 0.0417 - val_recall: 0.0333 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4390 - accuracy: 0.7268 - auc: 0.8869 - precision: 0.1786 - recall: 0.8427 - val_loss: 0.7172 - val_accuracy: 0.6140 - val_auc: 0.4279 - val_precision: 0.0631 - val_recall: 0.2333 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.3515 - accuracy: 0.7610 - auc: 0.9388 - precision: 0.2123 - recall: 0.9326 - val_loss: 0.6213 - val_accuracy: 0.7052 - val_auc: 0.3933 - val_precision: 0.0533 - val_recall: 0.1333 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.9088 - auc: 0.6101 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1099 sequences of length 13\n",
      "X shape: (1099, 13, 1968)\n",
      "y shape: (1099,)\n",
      "Epoch 1/25\n",
      "28/28 [==============================] - 6s 51ms/step - loss: 1.1561 - accuracy: 0.4869 - auc: 0.5225 - precision: 0.0674 - recall: 0.5849 - val_loss: 0.7391 - val_accuracy: 0.2000 - val_auc: 0.3630 - val_precision: 0.0495 - val_recall: 0.7500 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.2783 - accuracy: 0.4926 - auc: 0.5909 - precision: 0.0719 - recall: 0.6226 - val_loss: 0.4808 - val_accuracy: 0.9455 - val_auc: 0.4854 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.9088 - accuracy: 0.5848 - auc: 0.6705 - precision: 0.0895 - recall: 0.6415 - val_loss: 0.7973 - val_accuracy: 0.0909 - val_auc: 0.5857 - val_precision: 0.0566 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.8417 - accuracy: 0.5916 - auc: 0.7294 - precision: 0.1016 - recall: 0.7358 - val_loss: 0.8118 - val_accuracy: 0.1409 - val_auc: 0.5008 - val_precision: 0.0553 - val_recall: 0.9167 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.5707 - accuracy: 0.6200 - auc: 0.8132 - precision: 0.1151 - recall: 0.7925 - val_loss: 0.8326 - val_accuracy: 0.1909 - val_auc: 0.5323 - val_precision: 0.0538 - val_recall: 0.8333 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.5699 - accuracy: 0.6724 - auc: 0.8369 - precision: 0.1385 - recall: 0.8491 - val_loss: 1.3161 - val_accuracy: 0.0545 - val_auc: 0.4223 - val_precision: 0.0505 - val_recall: 0.9167 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.5894 - accuracy: 0.6803 - auc: 0.8178 - precision: 0.1346 - recall: 0.7925 - val_loss: 0.7197 - val_accuracy: 0.4909 - val_auc: 0.4714 - val_precision: 0.0455 - val_recall: 0.4167 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.3900 - accuracy: 0.7338 - auc: 0.9212 - precision: 0.1779 - recall: 0.9434 - val_loss: 0.5598 - val_accuracy: 0.7955 - val_auc: 0.5052 - val_precision: 0.0769 - val_recall: 0.2500 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.7372 - auc: 0.9127 - precision: 0.1752 - recall: 0.9057 - val_loss: 0.7560 - val_accuracy: 0.4591 - val_auc: 0.5250 - val_precision: 0.0504 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.3319 - accuracy: 0.7725 - auc: 0.9494 - precision: 0.2048 - recall: 0.9623 - val_loss: 0.6817 - val_accuracy: 0.5955 - val_auc: 0.5497 - val_precision: 0.0674 - val_recall: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.3238 - accuracy: 0.7838 - auc: 0.9496 - precision: 0.2085 - recall: 0.9245 - val_loss: 0.6023 - val_accuracy: 0.6864 - val_auc: 0.5477 - val_precision: 0.0746 - val_recall: 0.4167 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.3389 - accuracy: 0.8089 - auc: 0.9392 - precision: 0.2300 - recall: 0.9245 - val_loss: 0.5460 - val_accuracy: 0.7818 - val_auc: 0.5561 - val_precision: 0.0909 - val_recall: 0.3333 - lr: 2.0000e-04\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.9455 - auc: 0.4854 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 830 sequences of length 13\n",
      "X shape: (830, 13, 1968)\n",
      "y shape: (830,)\n",
      "Epoch 1/25\n",
      "21/21 [==============================] - 6s 66ms/step - loss: 1.0590 - accuracy: 0.5136 - auc: 0.5524 - precision: 0.0691 - recall: 0.6389 - val_loss: 0.3886 - val_accuracy: 0.9337 - val_auc: 0.4956 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.3715 - accuracy: 0.5346 - auc: 0.5664 - precision: 0.0694 - recall: 0.6111 - val_loss: 0.6317 - val_accuracy: 0.7590 - val_auc: 0.4402 - val_precision: 0.0606 - val_recall: 0.1818 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0748 - accuracy: 0.5271 - auc: 0.6571 - precision: 0.0736 - recall: 0.6667 - val_loss: 0.9668 - val_accuracy: 0.0663 - val_auc: 0.5578 - val_precision: 0.0663 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9574 - accuracy: 0.5407 - auc: 0.7025 - precision: 0.0784 - recall: 0.6944 - val_loss: 0.4062 - val_accuracy: 0.9337 - val_auc: 0.6147 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7717 - accuracy: 0.6099 - auc: 0.8125 - precision: 0.1004 - recall: 0.7778 - val_loss: 0.3741 - val_accuracy: 0.9337 - val_auc: 0.3959 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4687 - accuracy: 0.6491 - auc: 0.9218 - precision: 0.1311 - recall: 0.9722 - val_loss: 0.3910 - val_accuracy: 0.9337 - val_auc: 0.4428 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4512 - accuracy: 0.7214 - auc: 0.8775 - precision: 0.1469 - recall: 0.8611 - val_loss: 0.3790 - val_accuracy: 0.9337 - val_auc: 0.4384 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.7410 - auc: 0.9500 - precision: 0.1699 - recall: 0.9722 - val_loss: 0.3662 - val_accuracy: 0.9337 - val_auc: 0.4147 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.7907 - auc: 0.9618 - precision: 0.1988 - recall: 0.9444 - val_loss: 0.3958 - val_accuracy: 0.9337 - val_auc: 0.4428 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.2839 - accuracy: 0.8250 - auc: 0.9635 - precision: 0.2329 - recall: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 29ms/step - loss: 0.2883 - accuracy: 0.8238 - auc: 0.9617 - precision: 0.2353 - recall: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9337 - val_auc: 0.5023 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2215 - accuracy: 0.8434 - auc: 0.9832 - precision: 0.2536 - recall: 0.9722 - val_loss: 0.4138 - val_accuracy: 0.9036 - val_auc: 0.4845 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.9337 - auc: 0.4956 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3209 sequences of length 15\n",
      "X shape: (3209, 15, 1968)\n",
      "y shape: (3209,)\n",
      "Epoch 1/25\n",
      "81/81 [==============================] - 7s 25ms/step - loss: 1.3423 - accuracy: 0.4842 - auc: 0.4900 - precision: 0.0627 - recall: 0.5000 - val_loss: 0.7098 - val_accuracy: 0.4174 - val_auc: 0.5079 - val_precision: 0.0805 - val_recall: 0.6078 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 1.0408 - accuracy: 0.5205 - auc: 0.5693 - precision: 0.0777 - recall: 0.5904 - val_loss: 0.4829 - val_accuracy: 0.9206 - val_auc: 0.5188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.8086 - accuracy: 0.5481 - auc: 0.6252 - precision: 0.0893 - recall: 0.6506 - val_loss: 0.4865 - val_accuracy: 0.9112 - val_auc: 0.4331 - val_precision: 0.2500 - val_recall: 0.0588 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.7636 - accuracy: 0.5742 - auc: 0.6596 - precision: 0.0945 - recall: 0.6506 - val_loss: 0.3635 - val_accuracy: 0.9097 - val_auc: 0.4976 - val_precision: 0.1111 - val_recall: 0.0196 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.6279 - accuracy: 0.5984 - auc: 0.7439 - precision: 0.1142 - recall: 0.7711 - val_loss: 0.4877 - val_accuracy: 0.8240 - val_auc: 0.5061 - val_precision: 0.0571 - val_recall: 0.0784 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.5325 - accuracy: 0.6568 - auc: 0.8135 - precision: 0.1385 - recall: 0.8253 - val_loss: 0.4044 - val_accuracy: 0.8645 - val_auc: 0.5261 - val_precision: 0.0909 - val_recall: 0.0784 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.5021 - accuracy: 0.7121 - auc: 0.8391 - precision: 0.1593 - recall: 0.8072 - val_loss: 0.7581 - val_accuracy: 0.5935 - val_auc: 0.5122 - val_precision: 0.0866 - val_recall: 0.4314 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.4690 - accuracy: 0.7168 - auc: 0.8592 - precision: 0.1657 - recall: 0.8373 - val_loss: 0.6194 - val_accuracy: 0.6994 - val_auc: 0.5404 - val_precision: 0.0824 - val_recall: 0.2745 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.4760 - accuracy: 0.7507 - auc: 0.8566 - precision: 0.1780 - recall: 0.7892 - val_loss: 1.0377 - val_accuracy: 0.5171 - val_auc: 0.5167 - val_precision: 0.0809 - val_recall: 0.4902 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3880 - accuracy: 0.7480 - auc: 0.9120 - precision: 0.1921 - recall: 0.9036 - val_loss: 0.6723 - val_accuracy: 0.7103 - val_auc: 0.5318 - val_precision: 0.0859 - val_recall: 0.2745 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3508 - accuracy: 0.7756 - auc: 0.9327 - precision: 0.2169 - recall: 0.9458 - val_loss: 0.6271 - val_accuracy: 0.7399 - val_auc: 0.5303 - val_precision: 0.0857 - val_recall: 0.2353 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.3456 - accuracy: 0.7928 - auc: 0.9326 - precision: 0.2269 - recall: 0.9157 - val_loss: 0.6569 - val_accuracy: 0.7087 - val_auc: 0.5303 - val_precision: 0.0802 - val_recall: 0.2549 - lr: 2.0000e-04\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.9206 - auc: 0.5188 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1612 sequences of length 15\n",
      "X shape: (1612, 15, 1968)\n",
      "y shape: (1612,)\n",
      "Epoch 1/25\n",
      "41/41 [==============================] - 7s 38ms/step - loss: 1.2819 - accuracy: 0.4717 - auc: 0.4931 - precision: 0.0677 - recall: 0.4894 - val_loss: 0.5346 - val_accuracy: 0.9319 - val_auc: 0.5286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.1570 - accuracy: 0.5206 - auc: 0.5707 - precision: 0.0868 - recall: 0.5851 - val_loss: 0.2791 - val_accuracy: 0.9319 - val_auc: 0.4635 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 1.0060 - accuracy: 0.5625 - auc: 0.6007 - precision: 0.1003 - recall: 0.6277 - val_loss: 0.4162 - val_accuracy: 0.9319 - val_auc: 0.3811 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "37/41 [==========================>...] - ETA: 0s - loss: 0.7837 - accuracy: 0.5971 - auc: 0.7078 - precision: 0.1176 - recall: 0.6897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 19ms/step - loss: 0.7745 - accuracy: 0.5989 - auc: 0.7095 - precision: 0.1175 - recall: 0.6915 - val_loss: 0.2655 - val_accuracy: 0.9319 - val_auc: 0.3859 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.6558 - accuracy: 0.6338 - auc: 0.7593 - precision: 0.1309 - recall: 0.7128 - val_loss: 0.3668 - val_accuracy: 0.9319 - val_auc: 0.4982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.5799 - accuracy: 0.6680 - auc: 0.8069 - precision: 0.1578 - recall: 0.8191 - val_loss: 0.3375 - val_accuracy: 0.9319 - val_auc: 0.3112 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.5545 - accuracy: 0.7036 - auc: 0.8270 - precision: 0.1742 - recall: 0.8191 - val_loss: 0.7175 - val_accuracy: 0.5573 - val_auc: 0.3775 - val_precision: 0.0451 - val_recall: 0.2727 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4852 - accuracy: 0.7401 - auc: 0.8617 - precision: 0.1980 - recall: 0.8404 - val_loss: 0.3996 - val_accuracy: 0.8669 - val_auc: 0.3688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.4596 - accuracy: 0.7611 - auc: 0.8760 - precision: 0.2108 - recall: 0.8298 - val_loss: 0.3320 - val_accuracy: 0.9133 - val_auc: 0.4117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.3678 - accuracy: 0.7828 - auc: 0.9253 - precision: 0.2373 - recall: 0.8936 - val_loss: 0.3290 - val_accuracy: 0.9009 - val_auc: 0.4496 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.3327 - accuracy: 0.7944 - auc: 0.9407 - precision: 0.2522 - recall: 0.9255 - val_loss: 0.3485 - val_accuracy: 0.8885 - val_auc: 0.4533 - val_precision: 0.0625 - val_recall: 0.0455 - lr: 2.0000e-04\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.9319 - auc: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1080 sequences of length 15\n",
      "X shape: (1080, 15, 1968)\n",
      "y shape: (1080,)\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 6s 53ms/step - loss: 1.1676 - accuracy: 0.5301 - auc: 0.4913 - precision: 0.0657 - recall: 0.4194 - val_loss: 0.4867 - val_accuracy: 0.9213 - val_auc: 0.3277 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9761 - accuracy: 0.5451 - auc: 0.6365 - precision: 0.0993 - recall: 0.6613 - val_loss: 0.5534 - val_accuracy: 0.9213 - val_auc: 0.5257 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9931 - accuracy: 0.5648 - auc: 0.6627 - precision: 0.1055 - recall: 0.6774 - val_loss: 0.8588 - val_accuracy: 0.0787 - val_auc: 0.4332 - val_precision: 0.0787 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.8345 - accuracy: 0.5845 - auc: 0.7064 - precision: 0.1163 - recall: 0.7258 - val_loss: 0.5162 - val_accuracy: 0.9213 - val_auc: 0.5257 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.7370 - accuracy: 0.6447 - auc: 0.7685 - precision: 0.1470 - recall: 0.8226 - val_loss: 0.3170 - val_accuracy: 0.9213 - val_auc: 0.4870 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.5586 - accuracy: 0.6759 - auc: 0.8362 - precision: 0.1572 - recall: 0.8065 - val_loss: 0.3967 - val_accuracy: 0.9213 - val_auc: 0.4447 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4910 - accuracy: 0.7315 - auc: 0.8671 - precision: 0.1942 - recall: 0.8710 - val_loss: 0.3480 - val_accuracy: 0.9213 - val_auc: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4460 - accuracy: 0.7465 - auc: 0.8954 - precision: 0.2038 - recall: 0.8710 - val_loss: 0.3360 - val_accuracy: 0.9213 - val_auc: 0.6593 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4790 - accuracy: 0.7766 - auc: 0.8768 - precision: 0.2259 - recall: 0.8710 - val_loss: 0.6496 - val_accuracy: 0.6019 - val_auc: 0.4650 - val_precision: 0.0519 - val_recall: 0.2353 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 0.7917 - auc: 0.9511 - precision: 0.2521 - recall: 0.9677 - val_loss: 0.5544 - val_accuracy: 0.7407 - val_auc: 0.5711 - val_precision: 0.0667 - val_recall: 0.1765 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.2754 - accuracy: 0.8391 - auc: 0.9615 - precision: 0.3026 - recall: 0.9516 - val_loss: 0.4557 - val_accuracy: 0.7917 - val_auc: 0.6296 - val_precision: 0.0625 - val_recall: 0.1176 - lr: 2.0000e-04\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.9213 - auc: 0.3277 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 813 sequences of length 15\n",
      "X shape: (813, 15, 1968)\n",
      "y shape: (813,)\n",
      "Epoch 1/25\n",
      "21/21 [==============================] - 6s 66ms/step - loss: 1.2282 - accuracy: 0.4892 - auc: 0.4870 - precision: 0.0923 - recall: 0.5345 - val_loss: 0.4769 - val_accuracy: 0.9141 - val_auc: 0.6014 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.1454 - accuracy: 0.5200 - auc: 0.6154 - precision: 0.1056 - recall: 0.5862 - val_loss: 0.6379 - val_accuracy: 0.7485 - val_auc: 0.6033 - val_precision: 0.1351 - val_recall: 0.3571 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9681 - accuracy: 0.5292 - auc: 0.6446 - precision: 0.1149 - recall: 0.6379 - val_loss: 0.5866 - val_accuracy: 0.9018 - val_auc: 0.6752 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8664 - accuracy: 0.5708 - auc: 0.6902 - precision: 0.1353 - recall: 0.7069 - val_loss: 0.7106 - val_accuracy: 0.3988 - val_auc: 0.5221 - val_precision: 0.0962 - val_recall: 0.7143 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6473 - accuracy: 0.6585 - auc: 0.7957 - precision: 0.1797 - recall: 0.7931 - val_loss: 0.5501 - val_accuracy: 0.9018 - val_auc: 0.4226 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4727 - accuracy: 0.6831 - auc: 0.8955 - precision: 0.2132 - recall: 0.9483 - val_loss: 0.4296 - val_accuracy: 0.9141 - val_auc: 0.4895 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5188 - accuracy: 0.7077 - auc: 0.8500 - precision: 0.2080 - recall: 0.8103 - val_loss: 0.4500 - val_accuracy: 0.9141 - val_auc: 0.4032 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4391 - accuracy: 0.7308 - auc: 0.8899 - precision: 0.2329 - recall: 0.8793 - val_loss: 0.4186 - val_accuracy: 0.9141 - val_auc: 0.5805 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3799 - accuracy: 0.7446 - auc: 0.9122 - precision: 0.2545 - recall: 0.9655 - val_loss: 0.3903 - val_accuracy: 0.9141 - val_auc: 0.5350 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3493 - accuracy: 0.8154 - auc: 0.9301 - precision: 0.3176 - recall: 0.9310 - val_loss: 0.3268 - val_accuracy: 0.9141 - val_auc: 0.6227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.3806 - accuracy: 0.7662 - auc: 0.9288 - precision: 0.2673 - recall: 0.9310 - val_loss: 0.5637 - val_accuracy: 0.7239 - val_auc: 0.6558 - val_precision: 0.1556 - val_recall: 0.5000 - lr: 0.0010\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.9141 - auc: 0.6014 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3147 sequences of length 17\n",
      "X shape: (3147, 17, 1968)\n",
      "y shape: (3147,)\n",
      "Epoch 1/25\n",
      "79/79 [==============================] - 7s 26ms/step - loss: 1.3518 - accuracy: 0.4744 - auc: 0.4655 - precision: 0.0548 - recall: 0.4176 - val_loss: 0.6017 - val_accuracy: 0.8556 - val_auc: 0.4272 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.9979 - accuracy: 0.5026 - auc: 0.5610 - precision: 0.0800 - recall: 0.6059 - val_loss: 0.4702 - val_accuracy: 0.8825 - val_auc: 0.5723 - val_precision: 0.0789 - val_recall: 0.0714 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.7803 - accuracy: 0.5737 - auc: 0.6389 - precision: 0.0921 - recall: 0.6000 - val_loss: 0.4014 - val_accuracy: 0.9270 - val_auc: 0.5847 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.7374 - accuracy: 0.5868 - auc: 0.6942 - precision: 0.1067 - recall: 0.6941 - val_loss: 0.2980 - val_accuracy: 0.9095 - val_auc: 0.5427 - val_precision: 0.0588 - val_recall: 0.0238 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5870 - accuracy: 0.6575 - auc: 0.7776 - precision: 0.1303 - recall: 0.7176 - val_loss: 0.5647 - val_accuracy: 0.7111 - val_auc: 0.5883 - val_precision: 0.0882 - val_recall: 0.3571 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5914 - accuracy: 0.6714 - auc: 0.7821 - precision: 0.1410 - recall: 0.7588 - val_loss: 0.3730 - val_accuracy: 0.8698 - val_auc: 0.5848 - val_precision: 0.0238 - val_recall: 0.0238 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5047 - accuracy: 0.7112 - auc: 0.8415 - precision: 0.1681 - recall: 0.8294 - val_loss: 0.7748 - val_accuracy: 0.6365 - val_auc: 0.5422 - val_precision: 0.0651 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4677 - accuracy: 0.7418 - auc: 0.8668 - precision: 0.1867 - recall: 0.8412 - val_loss: 0.4825 - val_accuracy: 0.8000 - val_auc: 0.5606 - val_precision: 0.0625 - val_recall: 0.1429 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4634 - accuracy: 0.7565 - auc: 0.8654 - precision: 0.1953 - recall: 0.8353 - val_loss: 0.5035 - val_accuracy: 0.8143 - val_auc: 0.5894 - val_precision: 0.0968 - val_recall: 0.2143 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4191 - accuracy: 0.7696 - auc: 0.8930 - precision: 0.2096 - recall: 0.8706 - val_loss: 0.6001 - val_accuracy: 0.7587 - val_auc: 0.5797 - val_precision: 0.1014 - val_recall: 0.3333 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.3514 - accuracy: 0.7870 - auc: 0.9305 - precision: 0.2309 - recall: 0.9235 - val_loss: 0.5646 - val_accuracy: 0.7698 - val_auc: 0.5787 - val_precision: 0.0945 - val_recall: 0.2857 - lr: 2.0000e-04\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.8556 - auc: 0.4272 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1581 sequences of length 17\n",
      "X shape: (1581, 17, 1968)\n",
      "y shape: (1581,)\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 7s 40ms/step - loss: 1.1695 - accuracy: 0.4834 - auc: 0.5084 - precision: 0.0721 - recall: 0.4947 - val_loss: 0.4625 - val_accuracy: 0.9369 - val_auc: 0.4583 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2235 - accuracy: 0.5206 - auc: 0.5455 - precision: 0.0832 - recall: 0.5368 - val_loss: 0.7658 - val_accuracy: 0.1987 - val_auc: 0.5104 - val_precision: 0.0699 - val_recall: 0.9500 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9868 - accuracy: 0.5396 - auc: 0.6241 - precision: 0.0988 - recall: 0.6316 - val_loss: 0.5977 - val_accuracy: 0.8265 - val_auc: 0.4951 - val_precision: 0.0513 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7415 - accuracy: 0.5657 - auc: 0.7272 - precision: 0.1229 - recall: 0.7789 - val_loss: 0.5717 - val_accuracy: 0.8297 - val_auc: 0.4716 - val_precision: 0.0526 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5985 - accuracy: 0.6313 - auc: 0.7889 - precision: 0.1453 - recall: 0.8000 - val_loss: 0.7949 - val_accuracy: 0.3123 - val_auc: 0.4770 - val_precision: 0.0619 - val_recall: 0.7000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5716 - accuracy: 0.6804 - auc: 0.8088 - precision: 0.1677 - recall: 0.8211 - val_loss: 0.6902 - val_accuracy: 0.5047 - val_auc: 0.5056 - val_precision: 0.0692 - val_recall: 0.5500 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.4395 - accuracy: 0.7128 - auc: 0.8885 - precision: 0.1898 - recall: 0.8632 - val_loss: 0.6713 - val_accuracy: 0.5678 - val_auc: 0.4747 - val_precision: 0.0534 - val_recall: 0.3500 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.4200 - accuracy: 0.7318 - auc: 0.8946 - precision: 0.2067 - recall: 0.9053 - val_loss: 0.6340 - val_accuracy: 0.6341 - val_auc: 0.4864 - val_precision: 0.0714 - val_recall: 0.4000 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.3630 - accuracy: 0.7642 - auc: 0.9301 - precision: 0.2350 - recall: 0.9474 - val_loss: 0.6215 - val_accuracy: 0.6593 - val_auc: 0.4959 - val_precision: 0.0849 - val_recall: 0.4500 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.3549 - accuracy: 0.7714 - auc: 0.9328 - precision: 0.2392 - recall: 0.9368 - val_loss: 0.6150 - val_accuracy: 0.6782 - val_auc: 0.4867 - val_precision: 0.0816 - val_recall: 0.4000 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.3418 - accuracy: 0.7896 - auc: 0.9382 - precision: 0.2564 - recall: 0.9474 - val_loss: 0.5625 - val_accuracy: 0.7287 - val_auc: 0.4355 - val_precision: 0.0541 - val_recall: 0.2000 - lr: 2.0000e-04\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.9369 - auc: 0.4583 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1061 sequences of length 17\n",
      "X shape: (1061, 17, 1968)\n",
      "y shape: (1061,)\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 6s 54ms/step - loss: 1.1243 - accuracy: 0.5012 - auc: 0.5256 - precision: 0.0729 - recall: 0.5167 - val_loss: 0.6185 - val_accuracy: 0.8920 - val_auc: 0.4862 - val_precision: 0.2308 - val_recall: 0.1875 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0934 - accuracy: 0.5472 - auc: 0.6378 - precision: 0.0950 - recall: 0.6333 - val_loss: 0.7983 - val_accuracy: 0.1737 - val_auc: 0.5395 - val_precision: 0.0745 - val_recall: 0.8750 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.9609 - accuracy: 0.5613 - auc: 0.6946 - precision: 0.1100 - recall: 0.7333 - val_loss: 0.5890 - val_accuracy: 0.8967 - val_auc: 0.5162 - val_precision: 0.1250 - val_recall: 0.0625 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.6563 - accuracy: 0.5991 - auc: 0.7919 - precision: 0.1354 - recall: 0.8667 - val_loss: 0.4015 - val_accuracy: 0.9249 - val_auc: 0.5317 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.6972 - accuracy: 0.6733 - auc: 0.7571 - precision: 0.1371 - recall: 0.6833 - val_loss: 0.7308 - val_accuracy: 0.3662 - val_auc: 0.5125 - val_precision: 0.0780 - val_recall: 0.6875 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5822 - accuracy: 0.6604 - auc: 0.8346 - precision: 0.1524 - recall: 0.8333 - val_loss: 0.8925 - val_accuracy: 0.1362 - val_auc: 0.5376 - val_precision: 0.0758 - val_recall: 0.9375 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4921 - accuracy: 0.6969 - auc: 0.8592 - precision: 0.1661 - recall: 0.8167 - val_loss: 0.9049 - val_accuracy: 0.2441 - val_auc: 0.5384 - val_precision: 0.0809 - val_recall: 0.8750 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5249 - accuracy: 0.7064 - auc: 0.8600 - precision: 0.1797 - recall: 0.8833 - val_loss: 1.4292 - val_accuracy: 0.0939 - val_auc: 0.4914 - val_precision: 0.0766 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4382 - accuracy: 0.7618 - auc: 0.8923 - precision: 0.2066 - recall: 0.8333 - val_loss: 1.2361 - val_accuracy: 0.1268 - val_auc: 0.4580 - val_precision: 0.0707 - val_recall: 0.8750 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3316 - accuracy: 0.7759 - auc: 0.9459 - precision: 0.2336 - recall: 0.9500 - val_loss: 1.0865 - val_accuracy: 0.1502 - val_auc: 0.4699 - val_precision: 0.0725 - val_recall: 0.8750 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3032 - accuracy: 0.8007 - auc: 0.9538 - precision: 0.2511 - recall: 0.9167 - val_loss: 0.8430 - val_accuracy: 0.3615 - val_auc: 0.4697 - val_precision: 0.0775 - val_recall: 0.6875 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2848 - accuracy: 0.8208 - auc: 0.9590 - precision: 0.2745 - recall: 0.9333 - val_loss: 0.8176 - val_accuracy: 0.4601 - val_auc: 0.4838 - val_precision: 0.0909 - val_recall: 0.6875 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2463 - accuracy: 0.8443 - auc: 0.9768 - precision: 0.3105 - recall: 0.9833 - val_loss: 0.7193 - val_accuracy: 0.5822 - val_auc: 0.4997 - val_precision: 0.0805 - val_recall: 0.4375 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2083 - accuracy: 0.8597 - auc: 0.9875 - precision: 0.3333 - recall: 0.9833 - val_loss: 0.6894 - val_accuracy: 0.6291 - val_auc: 0.4913 - val_precision: 0.0685 - val_recall: 0.3125 - lr: 2.0000e-04\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.9249 - auc: 0.5317 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 799 sequences of length 17\n",
      "X shape: (799, 17, 1968)\n",
      "y shape: (799,)\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 6s 69ms/step - loss: 1.3075 - accuracy: 0.5133 - auc: 0.4120 - precision: 0.0430 - recall: 0.3714 - val_loss: 0.6021 - val_accuracy: 0.9312 - val_auc: 0.4971 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.9242 - accuracy: 0.5023 - auc: 0.7059 - precision: 0.0776 - recall: 0.7429 - val_loss: 0.5534 - val_accuracy: 0.9438 - val_auc: 0.5968 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.1315 - accuracy: 0.5336 - auc: 0.6419 - precision: 0.0689 - recall: 0.6000 - val_loss: 0.7043 - val_accuracy: 0.4625 - val_auc: 0.6063 - val_precision: 0.0860 - val_recall: 0.8889 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.7971 - accuracy: 0.5837 - auc: 0.7260 - precision: 0.0976 - recall: 0.8000 - val_loss: 0.7179 - val_accuracy: 0.3938 - val_auc: 0.5541 - val_precision: 0.0686 - val_recall: 0.7778 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5902 - accuracy: 0.6228 - auc: 0.8670 - precision: 0.1157 - recall: 0.8857 - val_loss: 0.7505 - val_accuracy: 0.2375 - val_auc: 0.4625 - val_precision: 0.0551 - val_recall: 0.7778 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4753 - accuracy: 0.6682 - auc: 0.8888 - precision: 0.1328 - recall: 0.9143 - val_loss: 0.8994 - val_accuracy: 0.0875 - val_auc: 0.3576 - val_precision: 0.0581 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4429 - accuracy: 0.6948 - auc: 0.9079 - precision: 0.1429 - recall: 0.9143 - val_loss: 0.5352 - val_accuracy: 0.9062 - val_auc: 0.5195 - val_precision: 0.1250 - val_recall: 0.1111 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.7480 - auc: 0.9160 - precision: 0.1613 - recall: 0.8571 - val_loss: 0.8842 - val_accuracy: 0.2000 - val_auc: 0.3002 - val_precision: 0.0458 - val_recall: 0.6667 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3674 - accuracy: 0.7668 - auc: 0.9383 - precision: 0.1798 - recall: 0.9143 - val_loss: 0.3639 - val_accuracy: 0.9438 - val_auc: 0.5530 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3207 - accuracy: 0.8091 - auc: 0.9517 - precision: 0.2194 - recall: 0.9714 - val_loss: 0.5844 - val_accuracy: 0.6812 - val_auc: 0.4967 - val_precision: 0.0435 - val_recall: 0.2222 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2840 - accuracy: 0.8294 - auc: 0.9629 - precision: 0.2357 - recall: 0.9429 - val_loss: 0.6573 - val_accuracy: 0.5875 - val_auc: 0.5342 - val_precision: 0.0746 - val_recall: 0.5556 - lr: 0.0010\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.9312 - auc: 0.4971 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 3085 sequences of length 19\n",
      "X shape: (3085, 19, 1968)\n",
      "y shape: (3085,)\n",
      "Epoch 1/25\n",
      "78/78 [==============================] - 7s 26ms/step - loss: 1.3021 - accuracy: 0.4781 - auc: 0.4871 - precision: 0.0655 - recall: 0.4855 - val_loss: 0.7743 - val_accuracy: 0.2593 - val_auc: 0.5531 - val_precision: 0.0644 - val_recall: 0.8158 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9934 - accuracy: 0.5069 - auc: 0.5429 - precision: 0.0735 - recall: 0.5202 - val_loss: 0.9727 - val_accuracy: 0.0729 - val_auc: 0.4098 - val_precision: 0.0623 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9017 - accuracy: 0.5199 - auc: 0.5802 - precision: 0.0825 - recall: 0.5780 - val_loss: 1.0418 - val_accuracy: 0.0989 - val_auc: 0.4907 - val_precision: 0.0625 - val_recall: 0.9737 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.7403 - accuracy: 0.5571 - auc: 0.6652 - precision: 0.1021 - recall: 0.6821 - val_loss: 0.5082 - val_accuracy: 0.8104 - val_auc: 0.5398 - val_precision: 0.1089 - val_recall: 0.2895 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.7113 - accuracy: 0.5944 - auc: 0.6802 - precision: 0.1087 - recall: 0.6647 - val_loss: 0.4556 - val_accuracy: 0.8314 - val_auc: 0.5085 - val_precision: 0.0417 - val_recall: 0.0789 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6023 - accuracy: 0.5912 - auc: 0.7658 - precision: 0.1261 - recall: 0.8150 - val_loss: 0.4356 - val_accuracy: 0.8347 - val_auc: 0.5210 - val_precision: 0.1000 - val_recall: 0.2105 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4982 - accuracy: 0.6698 - auc: 0.8402 - precision: 0.1571 - recall: 0.8497 - val_loss: 0.4252 - val_accuracy: 0.8331 - val_auc: 0.5231 - val_precision: 0.0548 - val_recall: 0.1053 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4939 - accuracy: 0.7038 - auc: 0.8415 - precision: 0.1718 - recall: 0.8439 - val_loss: 0.7019 - val_accuracy: 0.6856 - val_auc: 0.5382 - val_precision: 0.0568 - val_recall: 0.2632 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4403 - accuracy: 0.7407 - auc: 0.8780 - precision: 0.1956 - recall: 0.8671 - val_loss: 0.6802 - val_accuracy: 0.6775 - val_auc: 0.5275 - val_precision: 0.0649 - val_recall: 0.3158 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.7528 - auc: 0.8915 - precision: 0.2035 - recall: 0.8671 - val_loss: 0.7866 - val_accuracy: 0.6548 - val_auc: 0.5356 - val_precision: 0.0732 - val_recall: 0.3947 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4870 - accuracy: 0.7496 - auc: 0.8521 - precision: 0.1905 - recall: 0.7919 - val_loss: 0.5410 - val_accuracy: 0.8023 - val_auc: 0.4875 - val_precision: 0.0800 - val_recall: 0.2105 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4066 - accuracy: 0.7589 - auc: 0.8986 - precision: 0.2133 - recall: 0.9075 - val_loss: 0.4108 - val_accuracy: 0.8574 - val_auc: 0.5097 - val_precision: 0.0833 - val_recall: 0.1316 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.7840 - auc: 0.8956 - precision: 0.2214 - recall: 0.8266 - val_loss: 0.5913 - val_accuracy: 0.7585 - val_auc: 0.5034 - val_precision: 0.0630 - val_recall: 0.2105 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3783 - accuracy: 0.7820 - auc: 0.9106 - precision: 0.2222 - recall: 0.8439 - val_loss: 0.6789 - val_accuracy: 0.7196 - val_auc: 0.5298 - val_precision: 0.0701 - val_recall: 0.2895 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3249 - accuracy: 0.8229 - auc: 0.9364 - precision: 0.2724 - recall: 0.9133 - val_loss: 0.5785 - val_accuracy: 0.7812 - val_auc: 0.5136 - val_precision: 0.0550 - val_recall: 0.1579 - lr: 0.0010\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8314 - auc: 0.5085 - precision: 0.0417 - recall: 0.0789       \n",
      "Sampling from 31 games\n",
      "Created 1550 sequences of length 19\n",
      "X shape: (1550, 19, 1968)\n",
      "y shape: (1550,)\n",
      "Epoch 1/25\n",
      "39/39 [==============================] - 7s 41ms/step - loss: 1.1758 - accuracy: 0.4806 - auc: 0.4864 - precision: 0.0745 - recall: 0.5000 - val_loss: 0.5833 - val_accuracy: 0.8935 - val_auc: 0.5023 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.0013 - accuracy: 0.5258 - auc: 0.5960 - precision: 0.0914 - recall: 0.5729 - val_loss: 0.8563 - val_accuracy: 0.0613 - val_auc: 0.5465 - val_precision: 0.0554 - val_recall: 0.9444 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.8799 - accuracy: 0.5613 - auc: 0.6622 - precision: 0.1151 - recall: 0.6979 - val_loss: 0.3500 - val_accuracy: 0.9419 - val_auc: 0.6213 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.7209 - accuracy: 0.6153 - auc: 0.7296 - precision: 0.1371 - recall: 0.7500 - val_loss: 0.6261 - val_accuracy: 0.6871 - val_auc: 0.4689 - val_precision: 0.0562 - val_recall: 0.2778 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5757 - accuracy: 0.6694 - auc: 0.8104 - precision: 0.1645 - recall: 0.8021 - val_loss: 1.5006 - val_accuracy: 0.0613 - val_auc: 0.5728 - val_precision: 0.0583 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6228 - accuracy: 0.6516 - auc: 0.7766 - precision: 0.1529 - recall: 0.7708 - val_loss: 0.6319 - val_accuracy: 0.6484 - val_auc: 0.5654 - val_precision: 0.0583 - val_recall: 0.3333 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4815 - accuracy: 0.7306 - auc: 0.8643 - precision: 0.2040 - recall: 0.8542 - val_loss: 0.5970 - val_accuracy: 0.7194 - val_auc: 0.4791 - val_precision: 0.0400 - val_recall: 0.1667 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4468 - accuracy: 0.7556 - auc: 0.8784 - precision: 0.2255 - recall: 0.8854 - val_loss: 0.3565 - val_accuracy: 0.9065 - val_auc: 0.4250 - val_precision: 0.1333 - val_recall: 0.1111 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.7887 - auc: 0.9305 - precision: 0.2573 - recall: 0.9167 - val_loss: 0.4731 - val_accuracy: 0.7871 - val_auc: 0.4152 - val_precision: 0.0385 - val_recall: 0.1111 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3511 - accuracy: 0.7782 - auc: 0.9305 - precision: 0.2507 - recall: 0.9375 - val_loss: 0.4625 - val_accuracy: 0.8161 - val_auc: 0.4143 - val_precision: 0.0465 - val_recall: 0.1111 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3299 - accuracy: 0.8040 - auc: 0.9406 - precision: 0.2779 - recall: 0.9583 - val_loss: 0.5051 - val_accuracy: 0.7903 - val_auc: 0.3892 - val_precision: 0.0204 - val_recall: 0.0556 - lr: 2.0000e-04\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.8935 - auc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 1037 sequences of length 19\n",
      "X shape: (1037, 19, 1968)\n",
      "y shape: (1037,)\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 7s 56ms/step - loss: 1.0993 - accuracy: 0.5320 - auc: 0.5487 - precision: 0.0663 - recall: 0.5417 - val_loss: 0.4489 - val_accuracy: 0.9519 - val_auc: 0.4927 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2607 - accuracy: 0.5127 - auc: 0.5813 - precision: 0.0659 - recall: 0.5625 - val_loss: 0.6684 - val_accuracy: 0.6538 - val_auc: 0.5283 - val_precision: 0.0571 - val_recall: 0.4000 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.1614 - accuracy: 0.5464 - auc: 0.6268 - precision: 0.0751 - recall: 0.6042 - val_loss: 0.6161 - val_accuracy: 0.7644 - val_auc: 0.3667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.7566 - accuracy: 0.5802 - auc: 0.7812 - precision: 0.1053 - recall: 0.8333 - val_loss: 0.4798 - val_accuracy: 0.9231 - val_auc: 0.4715 - val_precision: 0.1250 - val_recall: 0.1000 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6904 - accuracy: 0.6333 - auc: 0.7770 - precision: 0.1168 - recall: 0.8125 - val_loss: 0.3055 - val_accuracy: 0.9519 - val_auc: 0.3730 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5990 - accuracy: 0.6598 - auc: 0.8139 - precision: 0.1274 - recall: 0.8333 - val_loss: 0.4200 - val_accuracy: 0.9375 - val_auc: 0.4040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4966 - accuracy: 0.6671 - auc: 0.8550 - precision: 0.1250 - recall: 0.7917 - val_loss: 0.4006 - val_accuracy: 0.9519 - val_auc: 0.5293 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4799 - accuracy: 0.7443 - auc: 0.8910 - precision: 0.1720 - recall: 0.8958 - val_loss: 0.3461 - val_accuracy: 0.9375 - val_auc: 0.5687 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.3649 - accuracy: 0.7775 - auc: 0.9289 - precision: 0.1963 - recall: 0.9556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/courseSharedFolders/142601outer/142601/cs109b/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3584 - accuracy: 0.7805 - auc: 0.9340 - precision: 0.2035 - recall: 0.9583 - val_loss: 0.2573 - val_accuracy: 0.9519 - val_auc: 0.6717 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3565 - accuracy: 0.8070 - auc: 0.9344 - precision: 0.2255 - recall: 0.9583 - val_loss: 0.1967 - val_accuracy: 0.9519 - val_auc: 0.5773 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3342 - accuracy: 0.8227 - auc: 0.9396 - precision: 0.2353 - recall: 0.9167 - val_loss: 0.2033 - val_accuracy: 0.9519 - val_auc: 0.5533 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.9519 - auc: 0.4927 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Sampling from 31 games\n",
      "Created 782 sequences of length 19\n",
      "X shape: (782, 19, 1968)\n",
      "y shape: (782,)\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 6s 69ms/step - loss: 1.1460 - accuracy: 0.4960 - auc: 0.5097 - precision: 0.0921 - recall: 0.5000 - val_loss: 0.4765 - val_accuracy: 0.9172 - val_auc: 0.5104 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.0889 - accuracy: 0.5056 - auc: 0.6146 - precision: 0.1162 - recall: 0.6552 - val_loss: 0.4275 - val_accuracy: 0.9172 - val_auc: 0.4546 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.8900 - accuracy: 0.5456 - auc: 0.7198 - precision: 0.1378 - recall: 0.7414 - val_loss: 0.3746 - val_accuracy: 0.9172 - val_auc: 0.4714 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7307 - accuracy: 0.6160 - auc: 0.7588 - precision: 0.1579 - recall: 0.7241 - val_loss: 0.3147 - val_accuracy: 0.9172 - val_auc: 0.4511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7175 - accuracy: 0.6768 - auc: 0.7716 - precision: 0.1870 - recall: 0.7414 - val_loss: 0.3734 - val_accuracy: 0.9172 - val_auc: 0.5043 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6426 - accuracy: 0.6688 - auc: 0.7940 - precision: 0.1857 - recall: 0.7586 - val_loss: 0.2872 - val_accuracy: 0.9172 - val_auc: 0.5003 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5452 - accuracy: 0.7008 - auc: 0.8641 - precision: 0.2232 - recall: 0.8966 - val_loss: 0.2952 - val_accuracy: 0.9172 - val_auc: 0.5350 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4716 - accuracy: 0.7312 - auc: 0.8787 - precision: 0.2356 - recall: 0.8448 - val_loss: 0.2953 - val_accuracy: 0.9172 - val_auc: 0.4460 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4228 - accuracy: 0.7632 - auc: 0.8999 - precision: 0.2656 - recall: 0.8793 - val_loss: 0.3160 - val_accuracy: 0.9172 - val_auc: 0.4925 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.7728 - auc: 0.9064 - precision: 0.2742 - recall: 0.8793 - val_loss: 0.3153 - val_accuracy: 0.9172 - val_auc: 0.5307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3082 - accuracy: 0.8112 - auc: 0.9503 - precision: 0.3214 - recall: 0.9310 - val_loss: 0.3234 - val_accuracy: 0.9172 - val_auc: 0.5206 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.9172 - auc: 0.5104 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for n in range(1, 20, 2):\n",
    "    for step in range(1, 5):\n",
    "        # prepare your data\n",
    "        X, y, play_ids = create_sequences(\n",
    "            df,\n",
    "            n=n,\n",
    "            target_col='blitzOutcome',\n",
    "            step=step,\n",
    "            cutoff=None\n",
    "        )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # build & train\n",
    "        RNN_model = create_blitz_rnn_model(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            dropout_rate=0.2\n",
    "        )\n",
    "        cw = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        RNN_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=dict(enumerate(cw)),\n",
    "            epochs=25,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # evaluate + save\n",
    "        results = evaluate_and_save(\n",
    "            RNN_model,\n",
    "            X_test, y_test,\n",
    "            ('sequence_length', n),\n",
    "            trial=step,\n",
    "            results=results\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e656c756-6285-41de-b6f5-f8bf1b14e30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>loss_mean</th>\n",
       "      <th>loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.899080</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.532644</td>\n",
       "      <td>0.045289</td>\n",
       "      <td>0.553540</td>\n",
       "      <td>0.029632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.821557</td>\n",
       "      <td>0.117463</td>\n",
       "      <td>0.471229</td>\n",
       "      <td>0.025139</td>\n",
       "      <td>0.555699</td>\n",
       "      <td>0.096759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.920283</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.549283</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>0.439703</td>\n",
       "      <td>0.045510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.898528</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>0.503469</td>\n",
       "      <td>0.007989</td>\n",
       "      <td>0.491074</td>\n",
       "      <td>0.062615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.881097</td>\n",
       "      <td>0.121180</td>\n",
       "      <td>0.510284</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.481630</td>\n",
       "      <td>0.105415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.912735</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.484015</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>0.503509</td>\n",
       "      <td>0.102928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925386</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.477004</td>\n",
       "      <td>0.040719</td>\n",
       "      <td>0.474078</td>\n",
       "      <td>0.073107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.918954</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>0.425553</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0.453878</td>\n",
       "      <td>0.053282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921964</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.494122</td>\n",
       "      <td>0.116923</td>\n",
       "      <td>0.495291</td>\n",
       "      <td>0.026514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912149</td>\n",
       "      <td>0.038048</td>\n",
       "      <td>0.478568</td>\n",
       "      <td>0.045535</td>\n",
       "      <td>0.516945</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_length  recall_mean  recall_std  precision_mean  precision_std  \\\n",
       "1                3     0.045000    0.090000        0.025568       0.051136   \n",
       "5               11     0.035714    0.071429        0.010638       0.021277   \n",
       "6               13     0.033333    0.066667        0.040541       0.081081   \n",
       "9               19     0.019737    0.039474        0.010417       0.020833   \n",
       "2                5     0.012500    0.025000        0.002841       0.005682   \n",
       "3                7     0.004545    0.009091        0.007143       0.014286   \n",
       "0                1     0.000000    0.000000        0.000000       0.000000   \n",
       "4                9     0.000000    0.000000        0.000000       0.000000   \n",
       "7               15     0.000000    0.000000        0.000000       0.000000   \n",
       "8               17     0.000000    0.000000        0.000000       0.000000   \n",
       "\n",
       "   accuracy_mean  accuracy_std  auc_mean   auc_std  loss_mean  loss_std  \n",
       "1       0.899080      0.044321  0.532644  0.045289   0.553540  0.029632  \n",
       "5       0.821557      0.117463  0.471229  0.025139   0.555699  0.096759  \n",
       "6       0.920283      0.023688  0.549283  0.068038   0.439703  0.045510  \n",
       "9       0.898528      0.050744  0.503469  0.007989   0.491074  0.062615  \n",
       "2       0.881097      0.121180  0.510284  0.069600   0.481630  0.105415  \n",
       "3       0.912735      0.028151  0.484015  0.059006   0.503509  0.102928  \n",
       "0       0.925386      0.010642  0.477004  0.040719   0.474078  0.073107  \n",
       "4       0.918954      0.022613  0.425553  0.020506   0.453878  0.053282  \n",
       "7       0.921964      0.007362  0.494122  0.116923   0.495291  0.026514  \n",
       "8       0.912149      0.038048  0.478568  0.045535   0.516945  0.101182  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_results(results, tuning_param):\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if tuning_param not in results_df.columns:\n",
    "        raise ValueError(f\"'{tuning_param}' not found in results.\")\n",
    "\n",
    "    summary = results_df.groupby(tuning_param).agg({\n",
    "        'recall': ['mean', 'std'],\n",
    "        'precision': ['mean', 'std'],\n",
    "        'accuracy': ['mean', 'std'],\n",
    "        'auc': ['mean', 'std'],\n",
    "        'loss': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "\n",
    "    summary.columns = [tuning_param, 'recall_mean', 'recall_std',\n",
    "                       'precision_mean', 'precision_std',\n",
    "                       'accuracy_mean', 'accuracy_std',\n",
    "                       'auc_mean', 'auc_std',\n",
    "                       'loss_mean', 'loss_std']\n",
    "\n",
    "    return summary.sort_values(by='recall_mean', ascending=False)\n",
    "\n",
    "# show the results\n",
    "summary = summarize_results(results, tuning_param='sequence_length')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefbf73-0f87-41b8-bc4e-59c5ecef6ce7",
   "metadata": {},
   "source": [
    "### Dropout Rate and LSTM Units\n",
    "We tune dropout and LSTM units together to manage the trade-off between model capacity and overfitting in learning blitz patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8603f5c-b1a4-4eb8-99bd-d040897b362f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/3 â€” Dropout: 0.1, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.9045 - auc: 0.5112 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” Dropout: 0.1, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2998 - accuracy: 0.9172 - auc: 0.6170 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.1, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.9172 - auc: 0.4487 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” Dropout: 0.1, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.9172 - auc: 0.5564 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” Dropout: 0.1, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.9172 - auc: 0.3798 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.1, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5722 - accuracy: 0.0828 - auc: 0.5168 - precision: 0.0828 - recall: 1.0000\n",
      "Trial 1/3 â€” Dropout: 0.1, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.9172 - auc: 0.5678 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” Dropout: 0.1, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3141 - accuracy: 0.9172 - auc: 0.5716 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.1, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.9172 - auc: 0.5379 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” Dropout: 0.2, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2920 - accuracy: 0.9172 - auc: 0.5847 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” Dropout: 0.2, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.8280 - auc: 0.6162 - precision: 0.1111 - recall: 0.1538\n",
      "Trial 3/3 â€” Dropout: 0.2, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.9172 - auc: 0.5144 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” Dropout: 0.2, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.9108 - auc: 0.5438 - precision: 0.4000 - recall: 0.1538\n",
      "Trial 2/3 â€” Dropout: 0.2, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8726 - auc: 0.4599 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.2, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8981 - auc: 0.6592 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” Dropout: 0.2, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.5414 - auc: 0.5905 - precision: 0.1169 - recall: 0.6923\n",
      "Trial 2/3 â€” Dropout: 0.2, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.9172 - auc: 0.4338 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.2, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.9108 - auc: 0.5951 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” Dropout: 0.3, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.8153 - auc: 0.5350 - precision: 0.0556 - recall: 0.0769\n",
      "Trial 2/3 â€” Dropout: 0.3, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2857 - accuracy: 0.9172 - auc: 0.5462 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.3, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.9172 - auc: 0.6538 - precision: 0.5000 - recall: 0.0769    \n",
      "Trial 1/3 â€” Dropout: 0.3, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.6561 - auc: 0.5764 - precision: 0.1273 - recall: 0.5385\n",
      "Trial 2/3 â€” Dropout: 0.3, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.8981 - auc: 0.6688 - precision: 0.2857 - recall: 0.1538\n",
      "Trial 3/3 â€” Dropout: 0.3, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.8854 - auc: 0.5243 - precision: 0.2222 - recall: 0.1538    \n",
      "Trial 1/3 â€” Dropout: 0.3, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.4204 - auc: 0.5021 - precision: 0.0851 - recall: 0.6154\n",
      "Trial 2/3 â€” Dropout: 0.3, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.9045 - auc: 0.6806 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.3, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.9172 - auc: 0.4279 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” Dropout: 0.4, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5873 - accuracy: 0.0828 - auc: 0.5569 - precision: 0.0828 - recall: 1.0000\n",
      "Trial 2/3 â€” Dropout: 0.4, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8981 - auc: 0.4899 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” Dropout: 0.4, LSTM Units: 128\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5332 - accuracy: 0.8344 - auc: 0.4209 - precision: 0.0667 - recall: 0.0769\n",
      "Trial 1/3 â€” Dropout: 0.4, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.7452 - auc: 0.4597 - precision: 0.1143 - recall: 0.3077\n",
      "Trial 2/3 â€” Dropout: 0.4, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.8599 - auc: 0.5606 - precision: 0.2353 - recall: 0.3077\n",
      "Trial 3/3 â€” Dropout: 0.4, LSTM Units: 256\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.6688 - auc: 0.5983 - precision: 0.1176 - recall: 0.4615\n",
      "Trial 1/3 â€” Dropout: 0.4, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.9108 - auc: 0.6394 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” Dropout: 0.4, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5899 - accuracy: 0.7707 - auc: 0.3806 - precision: 0.0741 - recall: 0.1538\n",
      "Trial 3/3 â€” Dropout: 0.4, LSTM Units: 512\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8917 - auc: 0.4533 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# parameter grid\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4]\n",
    "lstm_units_list = [128, 256, 512]\n",
    "n_trials = 3\n",
    "\n",
    "# loop thru combos\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "    for lstm_units in lstm_units_list:\n",
    "        for i in range(n_trials):\n",
    "\n",
    "            print(f'Trial {i+1}/{n_trials} â€” Dropout: {dropout_rate}, LSTM Units: {lstm_units}')\n",
    "\n",
    "            # build model\n",
    "            model = create_blitz_rnn_model(\n",
    "                n_timesteps=X.shape[1],\n",
    "                n_features=X.shape[2],\n",
    "                dropout_rate=dropout_rate,\n",
    "                lstm_units=lstm_units\n",
    "            )\n",
    "\n",
    "            # compile\n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=0.001),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "            )\n",
    "\n",
    "            # class weights\n",
    "            class_weights = class_weight.compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.unique(y_train),\n",
    "                y=y_train\n",
    "            )\n",
    "            class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "            # train\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                class_weight=class_weights,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # save results\n",
    "            tag = f'dropout{dropout_rate}_lstm{lstm_units}'\n",
    "            results = evaluate_and_save(\n",
    "                model,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                var=('config', tag),\n",
    "                trial=trial,\n",
    "                results=results\n",
    "            )\n",
    "            trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1212256a-60f0-40f4-b8a1-c5d0edf0be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>loss_mean</th>\n",
       "      <th>loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dropout0.4_lstm256</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.155742</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.096176</td>\n",
       "      <td>0.539530</td>\n",
       "      <td>0.071679</td>\n",
       "      <td>0.588438</td>\n",
       "      <td>0.057716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dropout0.4_lstm128</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.556475</td>\n",
       "      <td>0.049823</td>\n",
       "      <td>0.043896</td>\n",
       "      <td>0.605096</td>\n",
       "      <td>0.453439</td>\n",
       "      <td>0.489227</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.677314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dropout0.1_lstm256</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.047806</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>0.481738</td>\n",
       "      <td>0.484330</td>\n",
       "      <td>0.092652</td>\n",
       "      <td>0.728917</td>\n",
       "      <td>0.730707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dropout0.3_lstm256</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.211736</td>\n",
       "      <td>0.079740</td>\n",
       "      <td>0.813163</td>\n",
       "      <td>0.136212</td>\n",
       "      <td>0.589833</td>\n",
       "      <td>0.073181</td>\n",
       "      <td>0.542923</td>\n",
       "      <td>0.105919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dropout0.2_lstm512</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.399704</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.067482</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>0.215151</td>\n",
       "      <td>0.539797</td>\n",
       "      <td>0.091858</td>\n",
       "      <td>0.472025</td>\n",
       "      <td>0.207738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dropout0.3_lstm512</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.355292</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>0.747346</td>\n",
       "      <td>0.283231</td>\n",
       "      <td>0.536859</td>\n",
       "      <td>0.129865</td>\n",
       "      <td>0.495165</td>\n",
       "      <td>0.219291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dropout0.2_lstm128</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.064150</td>\n",
       "      <td>0.887473</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>0.571759</td>\n",
       "      <td>0.052095</td>\n",
       "      <td>0.430995</td>\n",
       "      <td>0.127110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dropout0.2_lstm256</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.230940</td>\n",
       "      <td>0.893843</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.554309</td>\n",
       "      <td>0.100041</td>\n",
       "      <td>0.419178</td>\n",
       "      <td>0.002785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dropout0.3_lstm128</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.044412</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.274049</td>\n",
       "      <td>0.883227</td>\n",
       "      <td>0.058838</td>\n",
       "      <td>0.578348</td>\n",
       "      <td>0.065624</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.123405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dropout0.4_lstm512</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.042767</td>\n",
       "      <td>0.857749</td>\n",
       "      <td>0.075990</td>\n",
       "      <td>0.491097</td>\n",
       "      <td>0.133492</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>0.126221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dropout0.1_lstm128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912951</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.085057</td>\n",
       "      <td>0.320847</td>\n",
       "      <td>0.044284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropout0.1_lstm512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559117</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.313854</td>\n",
       "      <td>0.023951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                config  recall_mean  recall_std  precision_mean  \\\n",
       "10  dropout0.4_lstm256     0.358974    0.088823        0.155742   \n",
       "9   dropout0.4_lstm128     0.358974    0.556475        0.049823   \n",
       "1   dropout0.1_lstm256     0.333333    0.577350        0.027601   \n",
       "7   dropout0.3_lstm256     0.282051    0.222058        0.211736   \n",
       "5   dropout0.2_lstm512     0.230769    0.399704        0.038961   \n",
       "8   dropout0.3_lstm512     0.205128    0.355292        0.028369   \n",
       "3   dropout0.2_lstm128     0.051282    0.088823        0.037037   \n",
       "4   dropout0.2_lstm256     0.051282    0.088823        0.133333   \n",
       "6   dropout0.3_lstm128     0.051282    0.044412        0.185185   \n",
       "11  dropout0.4_lstm512     0.051282    0.088823        0.024691   \n",
       "0   dropout0.1_lstm128     0.000000    0.000000        0.000000   \n",
       "2   dropout0.1_lstm512     0.000000    0.000000        0.000000   \n",
       "\n",
       "    precision_std  accuracy_mean  accuracy_std  auc_mean   auc_std  loss_mean  \\\n",
       "10       0.068914       0.757962      0.096176  0.539530  0.071679   0.588438   \n",
       "9        0.043896       0.605096      0.453439  0.489227  0.067978   0.814634   \n",
       "1        0.047806       0.639066      0.481738  0.484330  0.092652   0.728917   \n",
       "7        0.079740       0.813163      0.136212  0.589833  0.073181   0.542923   \n",
       "5        0.067482       0.789809      0.215151  0.539797  0.091858   0.472025   \n",
       "8        0.049136       0.747346      0.283231  0.536859  0.129865   0.495165   \n",
       "3        0.064150       0.887473      0.051483  0.571759  0.052095   0.430995   \n",
       "4        0.230940       0.893843      0.019459  0.554309  0.100041   0.419178   \n",
       "6        0.274049       0.883227      0.058838  0.578348  0.065624   0.376777   \n",
       "11       0.042767       0.857749      0.075990  0.491097  0.133492   0.451036   \n",
       "0        0.000000       0.912951      0.007355  0.525641  0.085057   0.320847   \n",
       "2        0.000000       0.917197      0.000000  0.559117  0.018446   0.313854   \n",
       "\n",
       "    loss_std  \n",
       "10  0.057716  \n",
       "9   0.677314  \n",
       "1   0.730707  \n",
       "7   0.105919  \n",
       "5   0.207738  \n",
       "8   0.219291  \n",
       "3   0.127110  \n",
       "4   0.002785  \n",
       "6   0.123405  \n",
       "11  0.126221  \n",
       "0   0.044284  \n",
       "2   0.023951  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_results(results, tuning_param='config')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449540ae-2e05-4b87-bd25-2df527621796",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "We experiment with learning rates to find a balance between fast convergence and stable, accurate blitz predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c81269dd-f244-4581-8d80-517dfb2ea6bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/5 â€” Learning rate: 0.01\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.1630 - accuracy: 0.0828 - auc: 0.3213 - precision: 0.0828 - recall: 1.0000\n",
      "Trial 2/5 â€” Learning rate: 0.01\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.9172 - auc: 0.5203 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/5 â€” Learning rate: 0.01\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.9172 - auc: 0.4794 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 4/5 â€” Learning rate: 0.01\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.9172 - auc: 0.5841 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 5/5 â€” Learning rate: 0.01\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0483 - accuracy: 0.0828 - auc: 0.5497 - precision: 0.0828 - recall: 1.0000\n",
      "Trial 1/5 â€” Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.7261 - auc: 0.3729 - precision: 0.0312 - recall: 0.0769    \n",
      "Trial 2/5 â€” Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0251 - accuracy: 0.1274 - auc: 0.5008 - precision: 0.0753 - recall: 0.8462\n",
      "Trial 3/5 â€” Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9982 - accuracy: 0.1210 - auc: 0.5614 - precision: 0.0861 - recall: 1.0000\n",
      "Trial 4/5 â€” Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7707 - auc: 0.5604 - precision: 0.1034 - recall: 0.2308\n",
      "Trial 5/5 â€” Learning rate: 0.001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.7696 - accuracy: 0.0828 - auc: 0.4968 - precision: 0.0828 - recall: 1.0000\n",
      "Trial 1/5 â€” Learning rate: 0.0005\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7643 - auc: 0.6130 - precision: 0.1000 - recall: 0.2308\n",
      "Trial 2/5 â€” Learning rate: 0.0005\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0698 - accuracy: 0.1274 - auc: 0.6827 - precision: 0.0867 - recall: 1.0000\n",
      "Trial 3/5 â€” Learning rate: 0.0005\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.5669 - auc: 0.4813 - precision: 0.0492 - recall: 0.2308\n",
      "Trial 4/5 â€” Learning rate: 0.0005\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2809 - accuracy: 0.9172 - auc: 0.5849 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 5/5 â€” Learning rate: 0.0005\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8981 - auc: 0.5489 - precision: 0.2000 - recall: 0.0769\n",
      "Trial 1/5 â€” Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7333 - accuracy: 0.4713 - auc: 0.5713 - precision: 0.0833 - recall: 0.5385\n",
      "Trial 2/5 â€” Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9599 - accuracy: 0.2357 - auc: 0.5967 - precision: 0.0916 - recall: 0.9231\n",
      "Trial 3/5 â€” Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7332 - accuracy: 0.4904 - auc: 0.5345 - precision: 0.0864 - recall: 0.5385\n",
      "Trial 4/5 â€” Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9304 - accuracy: 0.2102 - auc: 0.6157 - precision: 0.0949 - recall: 1.0000\n",
      "Trial 5/5 â€” Learning rate: 0.0001\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8930 - accuracy: 0.2420 - auc: 0.5609 - precision: 0.0923 - recall: 0.9231\n"
     ]
    }
   ],
   "source": [
    "# lrs to test\n",
    "learning_rates = [0.01, 0.001, 0.0005, 0.0001]\n",
    "n_trials = 5\n",
    "\n",
    "# loop thru lrs\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for i in range(n_trials):\n",
    "        print(f'Trial {i+1}/{n_trials} â€” Learning rate: {lr}')\n",
    "\n",
    "        # create model\n",
    "        model = create_blitz_rnn_model(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            dropout_rate=0.3,\n",
    "            lstm_units=256\n",
    "        )\n",
    "\n",
    "        # compile\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "        )\n",
    "\n",
    "        # class weights\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        # train\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # log and save\n",
    "        tag = f'lr{lr}'\n",
    "        results = evaluate_and_save(\n",
    "            model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            var=('lr', tag),\n",
    "            trial=trial,\n",
    "            results=results\n",
    "        )\n",
    "        trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "183349ce-b43d-4db4-a9e5-a76d525808e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>loss_mean</th>\n",
       "      <th>loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr0.0001</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.226890</td>\n",
       "      <td>0.089711</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.329936</td>\n",
       "      <td>0.138482</td>\n",
       "      <td>0.575801</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.849960</td>\n",
       "      <td>0.109165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr0.001</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.443226</td>\n",
       "      <td>0.075787</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>0.365605</td>\n",
       "      <td>0.350220</td>\n",
       "      <td>0.498451</td>\n",
       "      <td>0.076779</td>\n",
       "      <td>0.988653</td>\n",
       "      <td>0.488628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr0.01</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.045353</td>\n",
       "      <td>0.583439</td>\n",
       "      <td>0.457017</td>\n",
       "      <td>0.490972</td>\n",
       "      <td>0.102351</td>\n",
       "      <td>0.671549</td>\n",
       "      <td>0.402103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr0.0005</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.399704</td>\n",
       "      <td>0.087169</td>\n",
       "      <td>0.074056</td>\n",
       "      <td>0.654777</td>\n",
       "      <td>0.326317</td>\n",
       "      <td>0.582158</td>\n",
       "      <td>0.074740</td>\n",
       "      <td>0.587517</td>\n",
       "      <td>0.306176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  recall_mean  recall_std  precision_mean  precision_std  \\\n",
       "0  lr0.0001     0.784615    0.226890        0.089711       0.004708   \n",
       "2   lr0.001     0.630769    0.443226        0.075787       0.026946   \n",
       "3    lr0.01     0.400000    0.547723        0.033121       0.045353   \n",
       "1  lr0.0005     0.307692    0.399704        0.087169       0.074056   \n",
       "\n",
       "   accuracy_mean  accuracy_std  auc_mean   auc_std  loss_mean  loss_std  \n",
       "0       0.329936      0.138482  0.575801  0.031528   0.849960  0.109165  \n",
       "2       0.365605      0.350220  0.498451  0.076779   0.988653  0.488628  \n",
       "3       0.583439      0.457017  0.490972  0.102351   0.671549  0.402103  \n",
       "1       0.654777      0.326317  0.582158  0.074740   0.587517  0.306176  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output results\n",
    "summary = summarize_results(results, tuning_param='lr')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c8bc7-d234-4bcf-8adc-bc88fef32825",
   "metadata": {},
   "source": [
    "## Binary Focal Loss\n",
    "We use binary focal loss to address class imbalance by making the model focus more on misclassified examples rather than defaulting to the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a2de72a-8cd9-44b7-9703-3a7ae2033cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/5 â€” Loss: bce\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7580 - auc: 0.5537 - precision: 0.0968 - recall: 0.2308\n",
      "Trial 2/5 â€” Loss: bce\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7341 - accuracy: 0.1975 - auc: 0.5513 - precision: 0.0815 - recall: 0.8462\n",
      "Trial 3/5 â€” Loss: bce\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8726 - auc: 0.4899 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 4/5 â€” Loss: bce\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.9045 - auc: 0.5064 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 5/5 â€” Loss: bce\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.4968 - auc: 0.5027 - precision: 0.0769 - recall: 0.4615\n",
      "Trial 1/5 â€” Loss: focal\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1662 - accuracy: 0.6178 - auc: 0.3486 - precision: 0.0392 - recall: 0.1538\n",
      "Trial 2/5 â€” Loss: focal\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.8917 - auc: 0.5772 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/5 â€” Loss: focal\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9172 - auc: 0.6186 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 4/5 â€” Loss: focal\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.4841 - auc: 0.4909 - precision: 0.0641 - recall: 0.3846\n",
      "Trial 5/5 â€” Loss: focal\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.5032 - auc: 0.6683 - precision: 0.1176 - recall: 0.7692\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy, BinaryFocalCrossentropy\n",
    "\n",
    "# loss fns to compare\n",
    "loss_types = {\n",
    "    'bce': BinaryCrossentropy(),\n",
    "    'focal': BinaryFocalCrossentropy(\n",
    "        gamma=2.0,\n",
    "        alpha=0.25,\n",
    "        from_logits=False,\n",
    "        name='binary_focal_crossentropy'\n",
    "    )\n",
    "}\n",
    "\n",
    "# loop thru loss fns\n",
    "n_trials = 5\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for loss_name, loss_fn in loss_types.items():\n",
    "    for i in range(n_trials):\n",
    "        print(f'Trial {i+1}/{n_trials} â€” Loss: {loss_name}')\n",
    "\n",
    "        model = create_blitz_rnn_model(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            dropout_rate=0.3,\n",
    "            lstm_units=256\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.0005),\n",
    "            loss=loss_fn,\n",
    "            metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "        )\n",
    "\n",
    "        # Compute class weights for imbalance\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_recall', patience=5, restore_best_weights=True)]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=40,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        results = evaluate_and_save(\n",
    "            model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            var=('loss_fn', loss_name),\n",
    "            trial=trial,\n",
    "            results=results\n",
    "        )\n",
    "\n",
    "        trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f20e6d92-6afd-4113-ad4c-2e30b2e6a018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_fn</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>loss_mean</th>\n",
       "      <th>loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bce</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.356678</td>\n",
       "      <td>0.051036</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>0.645860</td>\n",
       "      <td>0.297548</td>\n",
       "      <td>0.520780</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.601819</td>\n",
       "      <td>0.127549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.324539</td>\n",
       "      <td>0.044193</td>\n",
       "      <td>0.049302</td>\n",
       "      <td>0.682803</td>\n",
       "      <td>0.208904</td>\n",
       "      <td>0.540705</td>\n",
       "      <td>0.125568</td>\n",
       "      <td>0.154197</td>\n",
       "      <td>0.025693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loss_fn  recall_mean  recall_std  precision_mean  precision_std  \\\n",
       "0     bce     0.307692    0.356678        0.051036       0.047166   \n",
       "1   focal     0.261538    0.324539        0.044193       0.049302   \n",
       "\n",
       "   accuracy_mean  accuracy_std  auc_mean   auc_std  loss_mean  loss_std  \n",
       "0       0.645860      0.297548  0.520780  0.029598   0.601819  0.127549  \n",
       "1       0.682803      0.208904  0.540705  0.125568   0.154197  0.025693  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_results(results, tuning_param='loss_fn')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab2af3-2ed8-4070-9b5b-3c44a1b11597",
   "metadata": {},
   "source": [
    "## Model Architecture  \n",
    "We explore different model architectures to evaluate whether we can improve recall or achieve comparable performance with simpler, more efficient designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31ac1ad5-03b2-4053-9e37-ddc7d0e5fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_variant(n_timesteps, n_features, \n",
    "                       lstm_units=256, \n",
    "                       dropout_rate=0.3, \n",
    "                       bidirectional=True, \n",
    "                       num_lstm_layers=2, \n",
    "                       dense_width=512):\n",
    "    \n",
    "    def lstm_layer(return_sequences=False):\n",
    "        base = LSTM(lstm_units, return_sequences=return_sequences)\n",
    "        return Bidirectional(base) if bidirectional else base\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_timesteps, n_features)))\n",
    "    \n",
    "    model.add(lstm_layer(return_sequences=(num_lstm_layers == 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    if num_lstm_layers == 2:\n",
    "        model.add(lstm_layer(return_sequences=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(dense_width, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(dense_width, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8667f-62cf-4a39-9240-d812b9a3c796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/3 â€” lstm256_dense256_bi_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.5159 - auc: 0.4837 - precision: 0.0800 - recall: 0.4615\n",
      "Trial 2/3 â€” lstm256_dense256_bi_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.3567 - auc: 0.4784 - precision: 0.0686 - recall: 0.5385\n",
      "Trial 3/3 â€” lstm256_dense256_bi_1L\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6536 - accuracy: 0.5796 - auc: 0.5275 - precision: 0.0923 - recall: 0.4615\n",
      "Trial 1/3 â€” lstm256_dense256_bi_2L\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.9172 - auc: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” lstm256_dense256_bi_2L\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.9108 - auc: 0.5775 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” lstm256_dense256_bi_2L\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4112 - accuracy: 0.0828 - auc: 0.5649 - precision: 0.0828 - recall: 1.0000\n",
      "Trial 1/3 â€” lstm256_dense256_uni_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.8599 - auc: 0.4920 - precision: 0.0909 - recall: 0.0769    \n",
      "Trial 2/3 â€” lstm256_dense256_uni_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.7643 - auc: 0.4079 - precision: 0.0714 - recall: 0.1538\n",
      "Trial 3/3 â€” lstm256_dense256_uni_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7286 - accuracy: 0.3376 - auc: 0.4989 - precision: 0.0748 - recall: 0.6154\n",
      "Trial 1/3 â€” lstm256_dense256_uni_2L\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.9172 - auc: 0.3964 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” lstm256_dense256_uni_2L\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.9172 - auc: 0.6691 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 3/3 â€” lstm256_dense256_uni_2L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.9108 - auc: 0.5312 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 1/3 â€” lstm256_dense512_bi_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.9045 - auc: 0.3860 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Trial 2/3 â€” lstm256_dense512_bi_1L\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6777 - accuracy: 0.5223 - auc: 0.3547 - precision: 0.0441 - recall: 0.2308\n",
      "Trial 3/3 â€” lstm256_dense512_bi_1L\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.6624 - auc: 0.4781 - precision: 0.0455 - recall: 0.1538\n",
      "Trial 1/3 â€” lstm256_dense512_bi_2L\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# architecture grid\n",
    "lstm_units = 256\n",
    "\n",
    "architectures = list(itertools.product(\n",
    "    [256, 512],      # Dense width\n",
    "    [True, False],   # Bidirectional\n",
    "    [1, 2]           # LSTM layers\n",
    "))\n",
    "\n",
    "n_trials = 3\n",
    "results = None\n",
    "trial = 0\n",
    "\n",
    "for dense_width, bidirectional, num_lstm_layers in architectures:\n",
    "    for i in range(n_trials):\n",
    "        config_name = f\"lstm{lstm_units}_dense{dense_width}_{'bi' if bidirectional else 'uni'}_{num_lstm_layers}L\"\n",
    "        print(f\"Trial {i+1}/{n_trials} â€” {config_name}\")\n",
    "\n",
    "        model = create_rnn_variant(\n",
    "            n_timesteps=X.shape[1],\n",
    "            n_features=X.shape[2],\n",
    "            lstm_units=lstm_units,\n",
    "            dense_width=dense_width,\n",
    "            bidirectional=bidirectional,\n",
    "            num_lstm_layers=num_lstm_layers\n",
    "        )\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            class_weight=class_weights,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        results = evaluate_and_save(\n",
    "            model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            var=('architecture', config_name),\n",
    "            trial=trial,\n",
    "            results=results\n",
    "        )\n",
    "        trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fd430-9923-405f-b1c7-e3451cc64f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_results(results, tuning_param='architecture')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3434e6-834c-4802-8f3e-a1aebf8c72f7",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "Based on our experimentation, our final model architecture should be as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5499a52-52eb-498b-b821-767a98401e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug in final model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb04dff-c0ff-46cc-97bf-5bfe41e475e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model\n",
    "loss, accuracy, auc, precision, recall = final_model.evaluate(X_test, y_test)\n",
    "print(f\"Final Test Loss: {loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Final Test AUC: {auc:.4f}\")\n",
    "print(f\"Final Test Precision: {precision:.4f}\")\n",
    "print(f\"Final Test Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
